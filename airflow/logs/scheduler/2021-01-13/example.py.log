[2021-01-13 00:00:00,810] {scheduler_job.py:181} INFO - Started process (PID=62) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:00,820] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:00,825] {logging_mixin.py:103} INFO - [2021-01-13 00:00:00,824] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:00,869] {logging_mixin.py:103} INFO - [2021-01-13 00:00:00,863] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:00,884] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:01,431] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.628 seconds
[2021-01-13 00:00:01,479] {scheduler_job.py:181} INFO - Started process (PID=63) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:01,482] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:01,484] {logging_mixin.py:103} INFO - [2021-01-13 00:00:01,484] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:01,512] {logging_mixin.py:103} INFO - [2021-01-13 00:00:01,508] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:01,517] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:02,083] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.609 seconds
[2021-01-13 00:00:02,136] {scheduler_job.py:181} INFO - Started process (PID=64) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:02,141] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:02,144] {logging_mixin.py:103} INFO - [2021-01-13 00:00:02,144] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:02,173] {logging_mixin.py:103} INFO - [2021-01-13 00:00:02,169] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:02,180] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:02,766] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.640 seconds
[2021-01-13 00:00:02,825] {scheduler_job.py:181} INFO - Started process (PID=65) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:02,833] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:02,836] {logging_mixin.py:103} INFO - [2021-01-13 00:00:02,836] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:02,877] {logging_mixin.py:103} INFO - [2021-01-13 00:00:02,873] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:02,889] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:03,749] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.934 seconds
[2021-01-13 00:00:03,803] {scheduler_job.py:181} INFO - Started process (PID=66) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:03,807] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:03,810] {logging_mixin.py:103} INFO - [2021-01-13 00:00:03,810] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:03,839] {logging_mixin.py:103} INFO - [2021-01-13 00:00:03,836] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:03,845] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:04,400] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.610 seconds
[2021-01-13 00:00:04,445] {scheduler_job.py:181} INFO - Started process (PID=67) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:04,448] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:04,451] {logging_mixin.py:103} INFO - [2021-01-13 00:00:04,451] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:04,489] {logging_mixin.py:103} INFO - [2021-01-13 00:00:04,484] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:04,499] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:05,229] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.791 seconds
[2021-01-13 00:00:05,313] {scheduler_job.py:181} INFO - Started process (PID=68) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:05,346] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:05,354] {logging_mixin.py:103} INFO - [2021-01-13 00:00:05,353] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:05,393] {logging_mixin.py:103} INFO - [2021-01-13 00:00:05,387] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:05,398] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:05,919] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.622 seconds
[2021-01-13 00:00:05,963] {scheduler_job.py:181} INFO - Started process (PID=69) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:05,967] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:05,971] {logging_mixin.py:103} INFO - [2021-01-13 00:00:05,970] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:06,021] {logging_mixin.py:103} INFO - [2021-01-13 00:00:06,010] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:06,033] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:06,628] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.672 seconds
[2021-01-13 00:00:06,684] {scheduler_job.py:181} INFO - Started process (PID=70) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:06,689] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:06,693] {logging_mixin.py:103} INFO - [2021-01-13 00:00:06,693] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:06,720] {logging_mixin.py:103} INFO - [2021-01-13 00:00:06,717] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:06,728] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:07,316] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.646 seconds
[2021-01-13 00:00:07,366] {scheduler_job.py:181} INFO - Started process (PID=71) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:07,373] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:07,376] {logging_mixin.py:103} INFO - [2021-01-13 00:00:07,375] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:07,400] {logging_mixin.py:103} INFO - [2021-01-13 00:00:07,397] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:07,404] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:07,914] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.557 seconds
[2021-01-13 00:00:07,993] {scheduler_job.py:181} INFO - Started process (PID=72) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:08,001] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:08,004] {logging_mixin.py:103} INFO - [2021-01-13 00:00:08,003] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:08,045] {logging_mixin.py:103} INFO - [2021-01-13 00:00:08,042] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:08,054] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:08,586] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.635 seconds
[2021-01-13 00:00:08,621] {scheduler_job.py:181} INFO - Started process (PID=73) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:08,625] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:08,628] {logging_mixin.py:103} INFO - [2021-01-13 00:00:08,627] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:08,653] {logging_mixin.py:103} INFO - [2021-01-13 00:00:08,650] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:08,659] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:09,247] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.631 seconds
[2021-01-13 00:00:09,304] {scheduler_job.py:181} INFO - Started process (PID=74) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:09,311] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:09,315] {logging_mixin.py:103} INFO - [2021-01-13 00:00:09,314] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:09,361] {logging_mixin.py:103} INFO - [2021-01-13 00:00:09,357] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:09,367] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:09,973] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.681 seconds
[2021-01-13 00:00:10,030] {scheduler_job.py:181} INFO - Started process (PID=75) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:10,040] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:10,043] {logging_mixin.py:103} INFO - [2021-01-13 00:00:10,043] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:10,078] {logging_mixin.py:103} INFO - [2021-01-13 00:00:10,075] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:10,083] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:10,598] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.578 seconds
[2021-01-13 00:00:11,038] {scheduler_job.py:181} INFO - Started process (PID=76) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:11,044] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:11,046] {logging_mixin.py:103} INFO - [2021-01-13 00:00:11,046] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:11,071] {logging_mixin.py:103} INFO - [2021-01-13 00:00:11,068] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:11,080] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:11,692] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.659 seconds
[2021-01-13 00:00:11,747] {scheduler_job.py:181} INFO - Started process (PID=77) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:11,753] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:11,758] {logging_mixin.py:103} INFO - [2021-01-13 00:00:11,757] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:11,806] {logging_mixin.py:103} INFO - [2021-01-13 00:00:11,800] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:11,812] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:12,394] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.660 seconds
[2021-01-13 00:00:12,447] {scheduler_job.py:181} INFO - Started process (PID=78) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:12,452] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:12,455] {logging_mixin.py:103} INFO - [2021-01-13 00:00:12,455] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:12,495] {logging_mixin.py:103} INFO - [2021-01-13 00:00:12,491] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:12,500] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:13,043] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.604 seconds
[2021-01-13 00:00:13,095] {scheduler_job.py:181} INFO - Started process (PID=79) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:13,098] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:13,101] {logging_mixin.py:103} INFO - [2021-01-13 00:00:13,100] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:13,129] {logging_mixin.py:103} INFO - [2021-01-13 00:00:13,125] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:13,134] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:13,694] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.611 seconds
[2021-01-13 00:00:13,747] {scheduler_job.py:181} INFO - Started process (PID=80) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:13,751] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:13,754] {logging_mixin.py:103} INFO - [2021-01-13 00:00:13,753] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:13,778] {logging_mixin.py:103} INFO - [2021-01-13 00:00:13,775] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:13,782] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:14,339] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.602 seconds
[2021-01-13 00:00:14,398] {scheduler_job.py:181} INFO - Started process (PID=81) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:14,402] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:14,404] {logging_mixin.py:103} INFO - [2021-01-13 00:00:14,404] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:14,436] {logging_mixin.py:103} INFO - [2021-01-13 00:00:14,431] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:14,442] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:15,023] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.632 seconds
[2021-01-13 00:00:15,076] {scheduler_job.py:181} INFO - Started process (PID=82) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:15,084] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:15,092] {logging_mixin.py:103} INFO - [2021-01-13 00:00:15,092] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:15,134] {logging_mixin.py:103} INFO - [2021-01-13 00:00:15,129] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:15,141] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:15,687] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.623 seconds
[2021-01-13 00:00:15,740] {scheduler_job.py:181} INFO - Started process (PID=83) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:15,746] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:15,751] {logging_mixin.py:103} INFO - [2021-01-13 00:00:15,750] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:15,792] {logging_mixin.py:103} INFO - [2021-01-13 00:00:15,786] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:15,799] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:16,359] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.628 seconds
[2021-01-13 00:00:16,381] {scheduler_job.py:181} INFO - Started process (PID=84) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:16,392] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:16,397] {logging_mixin.py:103} INFO - [2021-01-13 00:00:16,396] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:16,428] {logging_mixin.py:103} INFO - [2021-01-13 00:00:16,420] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:16,431] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:16,992] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.626 seconds
[2021-01-13 00:00:17,054] {scheduler_job.py:181} INFO - Started process (PID=85) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:17,064] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:17,070] {logging_mixin.py:103} INFO - [2021-01-13 00:00:17,067] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:17,105] {logging_mixin.py:103} INFO - [2021-01-13 00:00:17,102] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:17,112] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:17,734] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.692 seconds
[2021-01-13 00:00:17,791] {scheduler_job.py:181} INFO - Started process (PID=86) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:17,797] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:17,800] {logging_mixin.py:103} INFO - [2021-01-13 00:00:17,800] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:17,835] {logging_mixin.py:103} INFO - [2021-01-13 00:00:17,831] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:17,838] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:18,390] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.605 seconds
[2021-01-13 00:00:18,443] {scheduler_job.py:181} INFO - Started process (PID=87) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:18,450] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:18,455] {logging_mixin.py:103} INFO - [2021-01-13 00:00:18,454] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:18,500] {logging_mixin.py:103} INFO - [2021-01-13 00:00:18,494] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:18,506] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:19,072] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.637 seconds
[2021-01-13 00:00:19,197] {scheduler_job.py:181} INFO - Started process (PID=88) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:19,204] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:19,209] {logging_mixin.py:103} INFO - [2021-01-13 00:00:19,208] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:19,254] {logging_mixin.py:103} INFO - [2021-01-13 00:00:19,249] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:19,260] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:19,811] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.624 seconds
[2021-01-13 00:00:19,876] {scheduler_job.py:181} INFO - Started process (PID=89) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:19,880] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:19,885] {logging_mixin.py:103} INFO - [2021-01-13 00:00:19,885] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:19,946] {logging_mixin.py:103} INFO - [2021-01-13 00:00:19,939] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:19,950] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:20,494] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.631 seconds
[2021-01-13 00:00:20,555] {scheduler_job.py:181} INFO - Started process (PID=90) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:20,565] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:20,572] {logging_mixin.py:103} INFO - [2021-01-13 00:00:20,571] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:20,621] {logging_mixin.py:103} INFO - [2021-01-13 00:00:20,614] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:20,628] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:21,228] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.686 seconds
[2021-01-13 00:00:21,294] {scheduler_job.py:181} INFO - Started process (PID=91) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:21,298] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:21,305] {logging_mixin.py:103} INFO - [2021-01-13 00:00:21,305] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:21,354] {logging_mixin.py:103} INFO - [2021-01-13 00:00:21,348] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:21,362] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:21,932] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.645 seconds
[2021-01-13 00:00:21,991] {scheduler_job.py:181} INFO - Started process (PID=92) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:21,997] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:22,007] {logging_mixin.py:103} INFO - [2021-01-13 00:00:22,004] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:22,055] {logging_mixin.py:103} INFO - [2021-01-13 00:00:22,044] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:22,063] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:22,579] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.603 seconds
[2021-01-13 00:00:22,642] {scheduler_job.py:181} INFO - Started process (PID=93) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:22,649] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:22,655] {logging_mixin.py:103} INFO - [2021-01-13 00:00:22,655] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:22,688] {logging_mixin.py:103} INFO - [2021-01-13 00:00:22,681] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:22,695] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:23,292] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.664 seconds
[2021-01-13 00:00:23,354] {scheduler_job.py:181} INFO - Started process (PID=94) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:23,361] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:23,372] {logging_mixin.py:103} INFO - [2021-01-13 00:00:23,372] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:23,427] {logging_mixin.py:103} INFO - [2021-01-13 00:00:23,421] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:23,438] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:24,003] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.664 seconds
[2021-01-13 00:00:24,049] {scheduler_job.py:181} INFO - Started process (PID=95) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:24,053] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:24,056] {logging_mixin.py:103} INFO - [2021-01-13 00:00:24,056] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:24,090] {logging_mixin.py:103} INFO - [2021-01-13 00:00:24,085] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:24,094] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:24,659] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.619 seconds
[2021-01-13 00:00:24,702] {scheduler_job.py:181} INFO - Started process (PID=96) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:24,711] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:24,714] {logging_mixin.py:103} INFO - [2021-01-13 00:00:24,714] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:24,756] {logging_mixin.py:103} INFO - [2021-01-13 00:00:24,749] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:24,762] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:25,262] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.567 seconds
[2021-01-13 00:00:25,312] {scheduler_job.py:181} INFO - Started process (PID=97) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:25,315] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:25,318] {logging_mixin.py:103} INFO - [2021-01-13 00:00:25,317] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:25,358] {logging_mixin.py:103} INFO - [2021-01-13 00:00:25,350] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:25,362] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:25,948] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.641 seconds
[2021-01-13 00:00:25,993] {scheduler_job.py:181} INFO - Started process (PID=98) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:25,996] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:26,001] {logging_mixin.py:103} INFO - [2021-01-13 00:00:26,000] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:26,032] {logging_mixin.py:103} INFO - [2021-01-13 00:00:26,028] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:26,035] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:26,544] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.557 seconds
[2021-01-13 00:00:26,596] {scheduler_job.py:181} INFO - Started process (PID=99) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:26,600] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:26,606] {logging_mixin.py:103} INFO - [2021-01-13 00:00:26,606] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:26,636] {logging_mixin.py:103} INFO - [2021-01-13 00:00:26,633] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:26,641] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:27,228] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.640 seconds
[2021-01-13 00:00:27,291] {scheduler_job.py:181} INFO - Started process (PID=100) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:27,304] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:27,312] {logging_mixin.py:103} INFO - [2021-01-13 00:00:27,311] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:27,351] {logging_mixin.py:103} INFO - [2021-01-13 00:00:27,348] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:27,357] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:27,944] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.664 seconds
[2021-01-13 00:00:27,996] {scheduler_job.py:181} INFO - Started process (PID=101) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:27,999] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:28,001] {logging_mixin.py:103} INFO - [2021-01-13 00:00:28,001] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:28,032] {logging_mixin.py:103} INFO - [2021-01-13 00:00:28,029] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:28,037] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:28,609] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.622 seconds
[2021-01-13 00:00:28,670] {scheduler_job.py:181} INFO - Started process (PID=102) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:28,673] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:28,676] {logging_mixin.py:103} INFO - [2021-01-13 00:00:28,675] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:28,711] {logging_mixin.py:103} INFO - [2021-01-13 00:00:28,704] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:28,715] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:29,254] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.598 seconds
[2021-01-13 00:00:29,334] {scheduler_job.py:181} INFO - Started process (PID=103) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:29,339] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:29,342] {logging_mixin.py:103} INFO - [2021-01-13 00:00:29,341] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:29,386] {logging_mixin.py:103} INFO - [2021-01-13 00:00:29,383] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:29,392] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:29,907] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.591 seconds
[2021-01-13 00:00:29,996] {scheduler_job.py:181} INFO - Started process (PID=104) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:30,002] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:30,006] {logging_mixin.py:103} INFO - [2021-01-13 00:00:30,006] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:30,059] {logging_mixin.py:103} INFO - [2021-01-13 00:00:30,054] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:30,067] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:30,714] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.732 seconds
[2021-01-13 00:00:30,806] {scheduler_job.py:181} INFO - Started process (PID=105) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:30,816] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:30,824] {logging_mixin.py:103} INFO - [2021-01-13 00:00:30,823] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:30,904] {logging_mixin.py:103} INFO - [2021-01-13 00:00:30,896] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:30,909] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:31,497] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.721 seconds
[2021-01-13 00:00:31,788] {scheduler_job.py:181} INFO - Started process (PID=106) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:31,791] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:31,793] {logging_mixin.py:103} INFO - [2021-01-13 00:00:31,793] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:31,839] {logging_mixin.py:103} INFO - [2021-01-13 00:00:31,832] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:31,843] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:32,372] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.589 seconds
[2021-01-13 00:00:32,437] {scheduler_job.py:181} INFO - Started process (PID=107) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:32,440] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:32,443] {logging_mixin.py:103} INFO - [2021-01-13 00:00:32,443] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:32,485] {logging_mixin.py:103} INFO - [2021-01-13 00:00:32,480] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:32,489] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:32,975] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.553 seconds
[2021-01-13 00:00:33,094] {scheduler_job.py:181} INFO - Started process (PID=108) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:33,107] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:33,117] {logging_mixin.py:103} INFO - [2021-01-13 00:00:33,113] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:33,190] {logging_mixin.py:103} INFO - [2021-01-13 00:00:33,186] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:33,203] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:33,738] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.661 seconds
[2021-01-13 00:00:33,798] {scheduler_job.py:181} INFO - Started process (PID=109) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:33,806] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:33,812] {logging_mixin.py:103} INFO - [2021-01-13 00:00:33,811] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:33,874] {logging_mixin.py:103} INFO - [2021-01-13 00:00:33,868] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:33,882] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:34,399] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.613 seconds
[2021-01-13 00:00:34,457] {scheduler_job.py:181} INFO - Started process (PID=110) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:34,464] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:34,470] {logging_mixin.py:103} INFO - [2021-01-13 00:00:34,469] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:34,506] {logging_mixin.py:103} INFO - [2021-01-13 00:00:34,503] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:34,513] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:35,122] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.678 seconds
[2021-01-13 00:00:35,166] {scheduler_job.py:181} INFO - Started process (PID=111) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:35,170] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:35,173] {logging_mixin.py:103} INFO - [2021-01-13 00:00:35,173] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:35,209] {logging_mixin.py:103} INFO - [2021-01-13 00:00:35,207] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:35,215] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:35,703] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.543 seconds
[2021-01-13 00:00:35,753] {scheduler_job.py:181} INFO - Started process (PID=112) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:35,757] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:35,762] {logging_mixin.py:103} INFO - [2021-01-13 00:00:35,761] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:35,796] {logging_mixin.py:103} INFO - [2021-01-13 00:00:35,793] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:35,802] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:36,359] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.612 seconds
[2021-01-13 00:00:36,411] {scheduler_job.py:181} INFO - Started process (PID=113) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:36,415] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:36,418] {logging_mixin.py:103} INFO - [2021-01-13 00:00:36,417] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:36,453] {logging_mixin.py:103} INFO - [2021-01-13 00:00:36,448] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:36,459] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:37,036] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.634 seconds
[2021-01-13 00:00:37,101] {scheduler_job.py:181} INFO - Started process (PID=114) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:37,113] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:37,120] {logging_mixin.py:103} INFO - [2021-01-13 00:00:37,118] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:37,172] {logging_mixin.py:103} INFO - [2021-01-13 00:00:37,166] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:37,181] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:37,737] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.649 seconds
[2021-01-13 00:00:37,809] {scheduler_job.py:181} INFO - Started process (PID=115) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:37,817] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:37,820] {logging_mixin.py:103} INFO - [2021-01-13 00:00:37,819] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:37,860] {logging_mixin.py:103} INFO - [2021-01-13 00:00:37,856] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:37,868] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:38,422] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.627 seconds
[2021-01-13 00:00:38,676] {scheduler_job.py:181} INFO - Started process (PID=116) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:38,680] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:38,699] {logging_mixin.py:103} INFO - [2021-01-13 00:00:38,699] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:38,726] {logging_mixin.py:103} INFO - [2021-01-13 00:00:38,722] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:38,730] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:39,273] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.612 seconds
[2021-01-13 00:00:39,328] {scheduler_job.py:181} INFO - Started process (PID=117) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:39,331] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:39,334] {logging_mixin.py:103} INFO - [2021-01-13 00:00:39,334] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:39,363] {logging_mixin.py:103} INFO - [2021-01-13 00:00:39,361] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:39,375] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:40,013] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.693 seconds
[2021-01-13 00:00:40,082] {scheduler_job.py:181} INFO - Started process (PID=118) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:40,093] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:40,104] {logging_mixin.py:103} INFO - [2021-01-13 00:00:40,102] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:40,154] {logging_mixin.py:103} INFO - [2021-01-13 00:00:40,150] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:40,160] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:40,724] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.659 seconds
[2021-01-13 00:00:40,787] {scheduler_job.py:181} INFO - Started process (PID=119) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:40,790] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:40,796] {logging_mixin.py:103} INFO - [2021-01-13 00:00:40,796] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:40,833] {logging_mixin.py:103} INFO - [2021-01-13 00:00:40,831] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:40,839] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:41,420] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.639 seconds
[2021-01-13 00:00:41,484] {scheduler_job.py:181} INFO - Started process (PID=120) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:41,494] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:41,499] {logging_mixin.py:103} INFO - [2021-01-13 00:00:41,499] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:41,540] {logging_mixin.py:103} INFO - [2021-01-13 00:00:41,535] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:41,544] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:42,082] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.604 seconds
[2021-01-13 00:00:42,127] {scheduler_job.py:181} INFO - Started process (PID=121) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:42,130] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:42,133] {logging_mixin.py:103} INFO - [2021-01-13 00:00:42,132] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:42,168] {logging_mixin.py:103} INFO - [2021-01-13 00:00:42,164] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:42,172] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:42,725] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.604 seconds
[2021-01-13 00:00:42,768] {scheduler_job.py:181} INFO - Started process (PID=122) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:42,772] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:42,775] {logging_mixin.py:103} INFO - [2021-01-13 00:00:42,774] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:42,805] {logging_mixin.py:103} INFO - [2021-01-13 00:00:42,801] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:42,808] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:43,334] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.571 seconds
[2021-01-13 00:00:43,408] {scheduler_job.py:181} INFO - Started process (PID=123) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:43,430] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:43,438] {logging_mixin.py:103} INFO - [2021-01-13 00:00:43,437] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:43,487] {logging_mixin.py:103} INFO - [2021-01-13 00:00:43,476] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:43,493] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:44,088] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.690 seconds
[2021-01-13 00:00:44,161] {scheduler_job.py:181} INFO - Started process (PID=124) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:44,167] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:44,176] {logging_mixin.py:103} INFO - [2021-01-13 00:00:44,174] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:44,227] {logging_mixin.py:103} INFO - [2021-01-13 00:00:44,223] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:44,233] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:44,829] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.680 seconds
[2021-01-13 00:00:44,902] {scheduler_job.py:181} INFO - Started process (PID=125) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:44,916] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:44,926] {logging_mixin.py:103} INFO - [2021-01-13 00:00:44,925] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:45,024] {logging_mixin.py:103} INFO - [2021-01-13 00:00:44,975] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:45,028] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:45,614] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.724 seconds
[2021-01-13 00:00:45,678] {scheduler_job.py:181} INFO - Started process (PID=126) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:45,684] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:45,687] {logging_mixin.py:103} INFO - [2021-01-13 00:00:45,687] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:45,715] {logging_mixin.py:103} INFO - [2021-01-13 00:00:45,711] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:45,722] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:46,327] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.665 seconds
[2021-01-13 00:00:46,349] {scheduler_job.py:181} INFO - Started process (PID=127) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:46,354] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:46,356] {logging_mixin.py:103} INFO - [2021-01-13 00:00:46,356] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:46,387] {logging_mixin.py:103} INFO - [2021-01-13 00:00:46,384] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:46,392] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:46,957] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.622 seconds
[2021-01-13 00:00:47,006] {scheduler_job.py:181} INFO - Started process (PID=128) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:47,013] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:47,016] {logging_mixin.py:103} INFO - [2021-01-13 00:00:47,016] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:47,048] {logging_mixin.py:103} INFO - [2021-01-13 00:00:47,045] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:47,053] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:47,622] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.623 seconds
[2021-01-13 00:00:47,712] {scheduler_job.py:181} INFO - Started process (PID=129) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:47,720] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:47,726] {logging_mixin.py:103} INFO - [2021-01-13 00:00:47,726] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:47,783] {logging_mixin.py:103} INFO - [2021-01-13 00:00:47,777] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:47,788] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:48,336] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.640 seconds
[2021-01-13 00:00:48,392] {scheduler_job.py:181} INFO - Started process (PID=130) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:48,398] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:48,405] {logging_mixin.py:103} INFO - [2021-01-13 00:00:48,404] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:48,453] {logging_mixin.py:103} INFO - [2021-01-13 00:00:48,448] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:48,463] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:48,968] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.589 seconds
[2021-01-13 00:00:49,023] {scheduler_job.py:181} INFO - Started process (PID=131) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:49,029] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:49,032] {logging_mixin.py:103} INFO - [2021-01-13 00:00:49,032] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:49,059] {logging_mixin.py:103} INFO - [2021-01-13 00:00:49,057] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:49,063] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:49,622] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.606 seconds
[2021-01-13 00:00:49,695] {scheduler_job.py:181} INFO - Started process (PID=132) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:49,698] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:49,702] {logging_mixin.py:103} INFO - [2021-01-13 00:00:49,701] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:49,753] {logging_mixin.py:103} INFO - [2021-01-13 00:00:49,747] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:49,766] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:50,278] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.598 seconds
[2021-01-13 00:00:50,338] {scheduler_job.py:181} INFO - Started process (PID=133) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:50,345] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:50,358] {logging_mixin.py:103} INFO - [2021-01-13 00:00:50,358] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:50,388] {logging_mixin.py:103} INFO - [2021-01-13 00:00:50,384] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:50,392] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:50,980] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.654 seconds
[2021-01-13 00:00:51,030] {scheduler_job.py:181} INFO - Started process (PID=134) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:51,034] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:51,038] {logging_mixin.py:103} INFO - [2021-01-13 00:00:51,038] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:51,070] {logging_mixin.py:103} INFO - [2021-01-13 00:00:51,067] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:51,078] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:51,626] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.603 seconds
[2021-01-13 00:00:51,679] {scheduler_job.py:181} INFO - Started process (PID=135) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:51,686] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:51,692] {logging_mixin.py:103} INFO - [2021-01-13 00:00:51,692] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:51,729] {logging_mixin.py:103} INFO - [2021-01-13 00:00:51,726] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:51,735] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:52,288] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.614 seconds
[2021-01-13 00:00:52,459] {scheduler_job.py:181} INFO - Started process (PID=136) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:52,463] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:52,469] {logging_mixin.py:103} INFO - [2021-01-13 00:00:52,469] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:52,516] {logging_mixin.py:103} INFO - [2021-01-13 00:00:52,508] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:52,525] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:53,055] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.611 seconds
[2021-01-13 00:00:53,116] {scheduler_job.py:181} INFO - Started process (PID=137) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:53,122] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:53,127] {logging_mixin.py:103} INFO - [2021-01-13 00:00:53,126] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:53,195] {logging_mixin.py:103} INFO - [2021-01-13 00:00:53,192] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:53,214] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:53,748] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.642 seconds
[2021-01-13 00:00:53,807] {scheduler_job.py:181} INFO - Started process (PID=138) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:53,810] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:53,821] {logging_mixin.py:103} INFO - [2021-01-13 00:00:53,821] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:53,855] {logging_mixin.py:103} INFO - [2021-01-13 00:00:53,848] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:53,859] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:54,382] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.582 seconds
[2021-01-13 00:00:54,428] {scheduler_job.py:181} INFO - Started process (PID=139) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:54,431] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:54,434] {logging_mixin.py:103} INFO - [2021-01-13 00:00:54,434] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:54,474] {logging_mixin.py:103} INFO - [2021-01-13 00:00:54,466] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:54,479] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:55,061] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.645 seconds
[2021-01-13 00:00:55,125] {scheduler_job.py:181} INFO - Started process (PID=140) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:55,131] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:55,137] {logging_mixin.py:103} INFO - [2021-01-13 00:00:55,134] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:55,180] {logging_mixin.py:103} INFO - [2021-01-13 00:00:55,177] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:55,183] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:55,720] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.606 seconds
[2021-01-13 00:00:55,782] {scheduler_job.py:181} INFO - Started process (PID=141) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:55,789] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:55,793] {logging_mixin.py:103} INFO - [2021-01-13 00:00:55,793] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:55,825] {logging_mixin.py:103} INFO - [2021-01-13 00:00:55,822] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:55,832] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:56,312] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.541 seconds
[2021-01-13 00:00:56,369] {scheduler_job.py:181} INFO - Started process (PID=142) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:56,378] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:56,383] {logging_mixin.py:103} INFO - [2021-01-13 00:00:56,382] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:56,414] {logging_mixin.py:103} INFO - [2021-01-13 00:00:56,411] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:56,421] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:57,090] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.727 seconds
[2021-01-13 00:00:57,148] {scheduler_job.py:181} INFO - Started process (PID=143) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:57,151] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:57,154] {logging_mixin.py:103} INFO - [2021-01-13 00:00:57,153] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:57,182] {logging_mixin.py:103} INFO - [2021-01-13 00:00:57,179] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:57,186] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:57,696] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.554 seconds
[2021-01-13 00:00:57,747] {scheduler_job.py:181} INFO - Started process (PID=144) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:57,751] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:57,753] {logging_mixin.py:103} INFO - [2021-01-13 00:00:57,753] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:57,800] {logging_mixin.py:103} INFO - [2021-01-13 00:00:57,793] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:57,804] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:58,378] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.641 seconds
[2021-01-13 00:00:58,431] {scheduler_job.py:181} INFO - Started process (PID=145) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:58,434] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:58,437] {logging_mixin.py:103} INFO - [2021-01-13 00:00:58,437] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:58,466] {logging_mixin.py:103} INFO - [2021-01-13 00:00:58,462] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:58,470] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:59,043] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.619 seconds
[2021-01-13 00:00:59,089] {scheduler_job.py:181} INFO - Started process (PID=146) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:59,092] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:59,101] {logging_mixin.py:103} INFO - [2021-01-13 00:00:59,100] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:59,133] {logging_mixin.py:103} INFO - [2021-01-13 00:00:59,130] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:59,136] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:00:59,692] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.608 seconds
[2021-01-13 00:00:59,748] {scheduler_job.py:181} INFO - Started process (PID=147) to work on /opt/airflow/dags/example.py
[2021-01-13 00:00:59,751] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:00:59,754] {logging_mixin.py:103} INFO - [2021-01-13 00:00:59,754] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:00:59,789] {logging_mixin.py:103} INFO - [2021-01-13 00:00:59,784] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:00:59,794] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:00,529] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.791 seconds
[2021-01-13 00:01:00,585] {scheduler_job.py:181} INFO - Started process (PID=148) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:00,588] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:00,590] {logging_mixin.py:103} INFO - [2021-01-13 00:01:00,590] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:00,617] {logging_mixin.py:103} INFO - [2021-01-13 00:01:00,614] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:00,624] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:01,274] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.699 seconds
[2021-01-13 00:01:01,324] {scheduler_job.py:181} INFO - Started process (PID=149) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:01,333] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:01,339] {logging_mixin.py:103} INFO - [2021-01-13 00:01:01,338] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:01,372] {logging_mixin.py:103} INFO - [2021-01-13 00:01:01,369] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:01,381] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:01,918] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.603 seconds
[2021-01-13 00:01:01,965] {scheduler_job.py:181} INFO - Started process (PID=150) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:01,971] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:01,974] {logging_mixin.py:103} INFO - [2021-01-13 00:01:01,974] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:02,034] {logging_mixin.py:103} INFO - [2021-01-13 00:01:02,031] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:02,039] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:02,624] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.668 seconds
[2021-01-13 00:01:03,014] {scheduler_job.py:181} INFO - Started process (PID=151) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:03,024] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:03,029] {logging_mixin.py:103} INFO - [2021-01-13 00:01:03,028] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:03,071] {logging_mixin.py:103} INFO - [2021-01-13 00:01:03,066] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:03,076] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:03,637] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.641 seconds
[2021-01-13 00:01:03,772] {scheduler_job.py:181} INFO - Started process (PID=152) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:03,782] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:03,794] {logging_mixin.py:103} INFO - [2021-01-13 00:01:03,787] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:03,894] {logging_mixin.py:103} INFO - [2021-01-13 00:01:03,887] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:03,901] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:04,435] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.677 seconds
[2021-01-13 00:01:04,493] {scheduler_job.py:181} INFO - Started process (PID=153) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:04,500] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:04,514] {logging_mixin.py:103} INFO - [2021-01-13 00:01:04,513] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:04,561] {logging_mixin.py:103} INFO - [2021-01-13 00:01:04,557] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:04,578] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:05,166] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.685 seconds
[2021-01-13 00:01:05,257] {scheduler_job.py:181} INFO - Started process (PID=154) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:05,275] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:05,290] {logging_mixin.py:103} INFO - [2021-01-13 00:01:05,290] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:05,358] {logging_mixin.py:103} INFO - [2021-01-13 00:01:05,349] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:05,364] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:06,037] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.792 seconds
[2021-01-13 00:01:06,234] {scheduler_job.py:181} INFO - Started process (PID=155) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:06,285] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:06,296] {logging_mixin.py:103} INFO - [2021-01-13 00:01:06,295] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:06,477] {logging_mixin.py:103} INFO - [2021-01-13 00:01:06,469] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:06,538] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:07,318] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.107 seconds
[2021-01-13 00:01:07,381] {scheduler_job.py:181} INFO - Started process (PID=156) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:07,384] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:07,387] {logging_mixin.py:103} INFO - [2021-01-13 00:01:07,387] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:07,441] {logging_mixin.py:103} INFO - [2021-01-13 00:01:07,434] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:07,451] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:08,051] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.681 seconds
[2021-01-13 00:01:08,137] {scheduler_job.py:181} INFO - Started process (PID=157) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:08,143] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:08,149] {logging_mixin.py:103} INFO - [2021-01-13 00:01:08,148] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:08,188] {logging_mixin.py:103} INFO - [2021-01-13 00:01:08,183] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:08,196] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:08,782] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.659 seconds
[2021-01-13 00:01:08,839] {scheduler_job.py:181} INFO - Started process (PID=158) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:08,843] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:08,847] {logging_mixin.py:103} INFO - [2021-01-13 00:01:08,846] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:08,885] {logging_mixin.py:103} INFO - [2021-01-13 00:01:08,882] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:08,889] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:09,537] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.706 seconds
[2021-01-13 00:01:09,676] {scheduler_job.py:181} INFO - Started process (PID=159) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:09,687] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:09,702] {logging_mixin.py:103} INFO - [2021-01-13 00:01:09,702] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:09,834] {logging_mixin.py:103} INFO - [2021-01-13 00:01:09,811] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:09,851] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:10,398] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.778 seconds
[2021-01-13 00:01:10,450] {scheduler_job.py:181} INFO - Started process (PID=160) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:10,460] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:10,464] {logging_mixin.py:103} INFO - [2021-01-13 00:01:10,463] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:10,520] {logging_mixin.py:103} INFO - [2021-01-13 00:01:10,511] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:10,524] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:11,041] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.603 seconds
[2021-01-13 00:01:11,165] {scheduler_job.py:181} INFO - Started process (PID=161) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:11,171] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:11,185] {logging_mixin.py:103} INFO - [2021-01-13 00:01:11,185] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:11,265] {logging_mixin.py:103} INFO - [2021-01-13 00:01:11,256] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:11,282] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:11,829] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.673 seconds
[2021-01-13 00:01:11,915] {scheduler_job.py:181} INFO - Started process (PID=162) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:11,944] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:11,949] {logging_mixin.py:103} INFO - [2021-01-13 00:01:11,949] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:11,993] {logging_mixin.py:103} INFO - [2021-01-13 00:01:11,989] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:12,002] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:12,533] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.642 seconds
[2021-01-13 00:01:12,648] {scheduler_job.py:181} INFO - Started process (PID=163) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:12,658] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:12,673] {logging_mixin.py:103} INFO - [2021-01-13 00:01:12,672] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:12,742] {logging_mixin.py:103} INFO - [2021-01-13 00:01:12,738] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:12,754] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:13,257] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.633 seconds
[2021-01-13 00:01:13,511] {scheduler_job.py:181} INFO - Started process (PID=164) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:13,520] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:13,533] {logging_mixin.py:103} INFO - [2021-01-13 00:01:13,532] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:13,596] {logging_mixin.py:103} INFO - [2021-01-13 00:01:13,588] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:13,606] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:14,113] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.619 seconds
[2021-01-13 00:01:14,181] {scheduler_job.py:181} INFO - Started process (PID=165) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:14,196] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:14,200] {logging_mixin.py:103} INFO - [2021-01-13 00:01:14,200] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:14,246] {logging_mixin.py:103} INFO - [2021-01-13 00:01:14,239] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:14,254] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:14,788] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.623 seconds
[2021-01-13 00:01:14,851] {scheduler_job.py:181} INFO - Started process (PID=166) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:14,859] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:14,863] {logging_mixin.py:103} INFO - [2021-01-13 00:01:14,862] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:14,904] {logging_mixin.py:103} INFO - [2021-01-13 00:01:14,896] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:14,916] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:15,543] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.707 seconds
[2021-01-13 00:01:15,620] {scheduler_job.py:181} INFO - Started process (PID=167) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:15,623] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:15,626] {logging_mixin.py:103} INFO - [2021-01-13 00:01:15,626] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:15,674] {logging_mixin.py:103} INFO - [2021-01-13 00:01:15,667] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:15,684] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:16,246] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.636 seconds
[2021-01-13 00:01:16,311] {scheduler_job.py:181} INFO - Started process (PID=168) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:16,315] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:16,319] {logging_mixin.py:103} INFO - [2021-01-13 00:01:16,318] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:16,325] {logging_mixin.py:103} INFO - [2021-01-13 00:01:16,318] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:16,339] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:16,984] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.716 seconds
[2021-01-13 00:01:17,066] {scheduler_job.py:181} INFO - Started process (PID=169) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:17,076] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:17,079] {logging_mixin.py:103} INFO - [2021-01-13 00:01:17,078] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:17,134] {logging_mixin.py:103} INFO - [2021-01-13 00:01:17,127] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:17,144] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:17,674] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.627 seconds
[2021-01-13 00:01:17,789] {scheduler_job.py:181} INFO - Started process (PID=170) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:17,795] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:17,799] {logging_mixin.py:103} INFO - [2021-01-13 00:01:17,798] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:18,026] {logging_mixin.py:103} INFO - [2021-01-13 00:01:17,981] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:18,050] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:18,780] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.005 seconds
[2021-01-13 00:01:18,975] {scheduler_job.py:181} INFO - Started process (PID=171) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:18,991] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:18,996] {logging_mixin.py:103} INFO - [2021-01-13 00:01:18,996] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:19,067] {logging_mixin.py:103} INFO - [2021-01-13 00:01:19,061] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:19,077] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:19,586] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.627 seconds
[2021-01-13 00:01:19,685] {scheduler_job.py:181} INFO - Started process (PID=172) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:19,693] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:19,698] {logging_mixin.py:103} INFO - [2021-01-13 00:01:19,697] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:19,738] {logging_mixin.py:103} INFO - [2021-01-13 00:01:19,732] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:19,748] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:20,541] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.868 seconds
[2021-01-13 00:01:20,597] {scheduler_job.py:181} INFO - Started process (PID=173) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:20,601] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:20,604] {logging_mixin.py:103} INFO - [2021-01-13 00:01:20,604] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:20,631] {logging_mixin.py:103} INFO - [2021-01-13 00:01:20,628] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:20,637] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:21,204] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.612 seconds
[2021-01-13 00:01:21,241] {scheduler_job.py:181} INFO - Started process (PID=174) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:21,244] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:21,247] {logging_mixin.py:103} INFO - [2021-01-13 00:01:21,246] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:21,272] {logging_mixin.py:103} INFO - [2021-01-13 00:01:21,269] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:21,276] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:21,797] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.562 seconds
[2021-01-13 00:01:21,910] {scheduler_job.py:181} INFO - Started process (PID=175) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:21,934] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:21,950] {logging_mixin.py:103} INFO - [2021-01-13 00:01:21,949] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:22,006] {logging_mixin.py:103} INFO - [2021-01-13 00:01:22,000] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:22,020] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:22,579] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.693 seconds
[2021-01-13 00:01:22,630] {scheduler_job.py:181} INFO - Started process (PID=176) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:22,633] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:22,638] {logging_mixin.py:103} INFO - [2021-01-13 00:01:22,637] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:22,673] {logging_mixin.py:103} INFO - [2021-01-13 00:01:22,669] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:22,679] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:23,217] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.596 seconds
[2021-01-13 00:01:23,279] {scheduler_job.py:181} INFO - Started process (PID=177) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:23,290] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:23,296] {logging_mixin.py:103} INFO - [2021-01-13 00:01:23,295] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:23,349] {logging_mixin.py:103} INFO - [2021-01-13 00:01:23,339] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:23,355] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:23,879] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.611 seconds
[2021-01-13 00:01:23,939] {scheduler_job.py:181} INFO - Started process (PID=178) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:23,947] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:23,952] {logging_mixin.py:103} INFO - [2021-01-13 00:01:23,951] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:23,993] {logging_mixin.py:103} INFO - [2021-01-13 00:01:23,987] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:23,999] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:24,556] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.628 seconds
[2021-01-13 00:01:24,668] {scheduler_job.py:181} INFO - Started process (PID=179) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:24,685] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:24,691] {logging_mixin.py:103} INFO - [2021-01-13 00:01:24,690] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:24,815] {logging_mixin.py:103} INFO - [2021-01-13 00:01:24,800] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:24,836] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:25,406] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.766 seconds
[2021-01-13 00:01:25,470] {scheduler_job.py:181} INFO - Started process (PID=180) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:25,479] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:25,483] {logging_mixin.py:103} INFO - [2021-01-13 00:01:25,483] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:25,561] {logging_mixin.py:103} INFO - [2021-01-13 00:01:25,542] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:25,578] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:26,154] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.701 seconds
[2021-01-13 00:01:26,221] {scheduler_job.py:181} INFO - Started process (PID=181) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:26,225] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:26,227] {logging_mixin.py:103} INFO - [2021-01-13 00:01:26,227] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:26,258] {logging_mixin.py:103} INFO - [2021-01-13 00:01:26,256] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:26,264] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:26,842] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.633 seconds
[2021-01-13 00:01:26,905] {scheduler_job.py:181} INFO - Started process (PID=182) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:26,909] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:26,914] {logging_mixin.py:103} INFO - [2021-01-13 00:01:26,914] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:26,949] {logging_mixin.py:103} INFO - [2021-01-13 00:01:26,944] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:26,957] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:27,558] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.671 seconds
[2021-01-13 00:01:27,668] {scheduler_job.py:181} INFO - Started process (PID=183) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:27,677] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:27,691] {logging_mixin.py:103} INFO - [2021-01-13 00:01:27,690] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:27,785] {logging_mixin.py:103} INFO - [2021-01-13 00:01:27,767] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:27,794] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:28,345] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.692 seconds
[2021-01-13 00:01:28,404] {scheduler_job.py:181} INFO - Started process (PID=184) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:28,412] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:28,417] {logging_mixin.py:103} INFO - [2021-01-13 00:01:28,417] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:28,459] {logging_mixin.py:103} INFO - [2021-01-13 00:01:28,454] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:28,465] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:29,097] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.706 seconds
[2021-01-13 00:01:29,193] {scheduler_job.py:181} INFO - Started process (PID=185) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:29,197] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:29,200] {logging_mixin.py:103} INFO - [2021-01-13 00:01:29,199] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:29,230] {logging_mixin.py:103} INFO - [2021-01-13 00:01:29,225] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:29,236] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:29,776] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.588 seconds
[2021-01-13 00:01:29,841] {scheduler_job.py:181} INFO - Started process (PID=186) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:29,850] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:29,860] {logging_mixin.py:103} INFO - [2021-01-13 00:01:29,859] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:29,928] {logging_mixin.py:103} INFO - [2021-01-13 00:01:29,924] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:29,937] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:30,664] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.828 seconds
[2021-01-13 00:01:30,816] {scheduler_job.py:181} INFO - Started process (PID=187) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:30,823] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:30,828] {logging_mixin.py:103} INFO - [2021-01-13 00:01:30,827] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:30,867] {logging_mixin.py:103} INFO - [2021-01-13 00:01:30,862] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:30,875] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:31,402] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.603 seconds
[2021-01-13 00:01:31,962] {scheduler_job.py:181} INFO - Started process (PID=188) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:32,021] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:32,027] {logging_mixin.py:103} INFO - [2021-01-13 00:01:32,027] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:32,141] {logging_mixin.py:103} INFO - [2021-01-13 00:01:32,125] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:32,174] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:32,778] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.841 seconds
[2021-01-13 00:01:32,852] {scheduler_job.py:181} INFO - Started process (PID=189) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:32,856] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:32,860] {logging_mixin.py:103} INFO - [2021-01-13 00:01:32,860] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:32,907] {logging_mixin.py:103} INFO - [2021-01-13 00:01:32,902] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:32,914] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:33,584] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.741 seconds
[2021-01-13 00:01:33,718] {scheduler_job.py:181} INFO - Started process (PID=190) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:33,723] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:33,726] {logging_mixin.py:103} INFO - [2021-01-13 00:01:33,726] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:33,782] {logging_mixin.py:103} INFO - [2021-01-13 00:01:33,777] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:33,790] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:34,371] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.671 seconds
[2021-01-13 00:01:34,747] {scheduler_job.py:181} INFO - Started process (PID=191) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:34,752] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:34,758] {logging_mixin.py:103} INFO - [2021-01-13 00:01:34,757] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:34,912] {logging_mixin.py:103} INFO - [2021-01-13 00:01:34,894] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:34,933] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:35,606] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.868 seconds
[2021-01-13 00:01:35,737] {scheduler_job.py:181} INFO - Started process (PID=192) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:35,752] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:35,767] {logging_mixin.py:103} INFO - [2021-01-13 00:01:35,767] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:35,903] {logging_mixin.py:103} INFO - [2021-01-13 00:01:35,898] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:35,948] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:37,156] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.440 seconds
[2021-01-13 00:01:37,324] {scheduler_job.py:181} INFO - Started process (PID=193) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:37,339] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:37,346] {logging_mixin.py:103} INFO - [2021-01-13 00:01:37,343] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:37,505] {logging_mixin.py:103} INFO - [2021-01-13 00:01:37,490] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:37,535] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:38,176] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.873 seconds
[2021-01-13 00:01:38,355] {scheduler_job.py:181} INFO - Started process (PID=194) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:38,359] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:38,372] {logging_mixin.py:103} INFO - [2021-01-13 00:01:38,372] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:38,428] {logging_mixin.py:103} INFO - [2021-01-13 00:01:38,423] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:38,437] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:39,131] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.793 seconds
[2021-01-13 00:01:39,199] {scheduler_job.py:181} INFO - Started process (PID=195) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:39,203] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:39,208] {logging_mixin.py:103} INFO - [2021-01-13 00:01:39,208] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:39,264] {logging_mixin.py:103} INFO - [2021-01-13 00:01:39,261] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:39,270] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:42,713] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 3.521 seconds
[2021-01-13 00:01:45,786] {scheduler_job.py:181} INFO - Started process (PID=196) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:45,807] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:45,817] {logging_mixin.py:103} INFO - [2021-01-13 00:01:45,816] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:46,557] {logging_mixin.py:103} INFO - [2021-01-13 00:01:46,498] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:46,721] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:49,330] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 4.819 seconds
[2021-01-13 00:01:50,598] {scheduler_job.py:181} INFO - Started process (PID=197) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:51,213] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:51,353] {logging_mixin.py:103} INFO - [2021-01-13 00:01:51,353] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:52,798] {logging_mixin.py:103} INFO - [2021-01-13 00:01:52,383] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:52,827] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:55,543] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 5.041 seconds
[2021-01-13 00:01:56,614] {scheduler_job.py:181} INFO - Started process (PID=198) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:56,630] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:56,634] {logging_mixin.py:103} INFO - [2021-01-13 00:01:56,633] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:57,027] {logging_mixin.py:103} INFO - [2021-01-13 00:01:57,017] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:57,048] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:01:58,572] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 2.159 seconds
[2021-01-13 00:01:58,881] {scheduler_job.py:181} INFO - Started process (PID=199) to work on /opt/airflow/dags/example.py
[2021-01-13 00:01:58,912] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:01:58,931] {logging_mixin.py:103} INFO - [2021-01-13 00:01:58,929] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:01:59,375] {logging_mixin.py:103} INFO - [2021-01-13 00:01:59,349] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:01:59,394] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:00,316] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.628 seconds
[2021-01-13 00:02:00,746] {scheduler_job.py:181} INFO - Started process (PID=200) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:00,760] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:00,765] {logging_mixin.py:103} INFO - [2021-01-13 00:02:00,763] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:00,890] {logging_mixin.py:103} INFO - [2021-01-13 00:02:00,884] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:00,948] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:02,241] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.580 seconds
[2021-01-13 00:02:02,406] {scheduler_job.py:181} INFO - Started process (PID=201) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:02,429] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:02,451] {logging_mixin.py:103} INFO - [2021-01-13 00:02:02,436] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:02,585] {logging_mixin.py:103} INFO - [2021-01-13 00:02:02,549] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:02,619] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:03,888] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.499 seconds
[2021-01-13 00:02:04,182] {scheduler_job.py:181} INFO - Started process (PID=202) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:04,188] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:04,193] {logging_mixin.py:103} INFO - [2021-01-13 00:02:04,192] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:04,389] {logging_mixin.py:103} INFO - [2021-01-13 00:02:04,382] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:04,403] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:05,169] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.001 seconds
[2021-01-13 00:02:05,451] {scheduler_job.py:181} INFO - Started process (PID=203) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:05,520] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:05,533] {logging_mixin.py:103} INFO - [2021-01-13 00:02:05,531] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:05,790] {logging_mixin.py:103} INFO - [2021-01-13 00:02:05,757] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:05,807] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:07,205] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.789 seconds
[2021-01-13 00:02:07,896] {scheduler_job.py:181} INFO - Started process (PID=204) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:07,913] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:07,921] {logging_mixin.py:103} INFO - [2021-01-13 00:02:07,920] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:09,054] {logging_mixin.py:103} INFO - [2021-01-13 00:02:08,902] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:09,102] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:09,901] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 2.020 seconds
[2021-01-13 00:02:09,977] {scheduler_job.py:181} INFO - Started process (PID=205) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:09,982] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:09,985] {logging_mixin.py:103} INFO - [2021-01-13 00:02:09,985] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:10,025] {logging_mixin.py:103} INFO - [2021-01-13 00:02:10,022] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:10,030] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:10,703] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.734 seconds
[2021-01-13 00:02:10,749] {scheduler_job.py:181} INFO - Started process (PID=206) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:10,753] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:10,755] {logging_mixin.py:103} INFO - [2021-01-13 00:02:10,755] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:10,781] {logging_mixin.py:103} INFO - [2021-01-13 00:02:10,778] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:10,788] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:11,333] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.590 seconds
[2021-01-13 00:02:11,380] {scheduler_job.py:181} INFO - Started process (PID=207) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:11,383] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:11,386] {logging_mixin.py:103} INFO - [2021-01-13 00:02:11,386] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:11,414] {logging_mixin.py:103} INFO - [2021-01-13 00:02:11,410] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:11,426] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:12,024] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.650 seconds
[2021-01-13 00:02:12,096] {scheduler_job.py:181} INFO - Started process (PID=208) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:12,101] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:12,107] {logging_mixin.py:103} INFO - [2021-01-13 00:02:12,106] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:12,141] {logging_mixin.py:103} INFO - [2021-01-13 00:02:12,136] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:12,146] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:12,676] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.593 seconds
[2021-01-13 00:02:12,756] {scheduler_job.py:181} INFO - Started process (PID=209) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:12,762] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:12,765] {logging_mixin.py:103} INFO - [2021-01-13 00:02:12,764] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:12,797] {logging_mixin.py:103} INFO - [2021-01-13 00:02:12,794] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:12,802] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:13,355] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.608 seconds
[2021-01-13 00:02:13,418] {scheduler_job.py:181} INFO - Started process (PID=210) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:13,426] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:13,431] {logging_mixin.py:103} INFO - [2021-01-13 00:02:13,430] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:13,475] {logging_mixin.py:103} INFO - [2021-01-13 00:02:13,469] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:13,483] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:14,129] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.721 seconds
[2021-01-13 00:02:14,190] {scheduler_job.py:181} INFO - Started process (PID=211) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:14,195] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:14,202] {logging_mixin.py:103} INFO - [2021-01-13 00:02:14,202] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:14,262] {logging_mixin.py:103} INFO - [2021-01-13 00:02:14,257] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:14,266] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:14,932] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.753 seconds
[2021-01-13 00:02:15,015] {scheduler_job.py:181} INFO - Started process (PID=212) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:15,019] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:15,022] {logging_mixin.py:103} INFO - [2021-01-13 00:02:15,021] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:15,060] {logging_mixin.py:103} INFO - [2021-01-13 00:02:15,057] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:15,064] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:15,701] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.695 seconds
[2021-01-13 00:02:15,824] {scheduler_job.py:181} INFO - Started process (PID=213) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:15,833] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:15,838] {logging_mixin.py:103} INFO - [2021-01-13 00:02:15,838] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:15,890] {logging_mixin.py:103} INFO - [2021-01-13 00:02:15,882] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:15,903] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:16,447] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.670 seconds
[2021-01-13 00:02:16,502] {scheduler_job.py:181} INFO - Started process (PID=214) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:16,521] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:16,527] {logging_mixin.py:103} INFO - [2021-01-13 00:02:16,527] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:16,604] {logging_mixin.py:103} INFO - [2021-01-13 00:02:16,597] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:16,631] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:17,346] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.852 seconds
[2021-01-13 00:02:17,444] {scheduler_job.py:181} INFO - Started process (PID=215) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:17,462] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:17,465] {logging_mixin.py:103} INFO - [2021-01-13 00:02:17,464] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:17,529] {logging_mixin.py:103} INFO - [2021-01-13 00:02:17,520] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:17,537] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:18,104] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.676 seconds
[2021-01-13 00:02:18,164] {scheduler_job.py:181} INFO - Started process (PID=216) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:18,173] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:18,177] {logging_mixin.py:103} INFO - [2021-01-13 00:02:18,177] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:18,205] {logging_mixin.py:103} INFO - [2021-01-13 00:02:18,202] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:18,213] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:18,964] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.808 seconds
[2021-01-13 00:02:19,167] {scheduler_job.py:181} INFO - Started process (PID=217) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:19,173] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:19,176] {logging_mixin.py:103} INFO - [2021-01-13 00:02:19,175] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:19,225] {logging_mixin.py:103} INFO - [2021-01-13 00:02:19,221] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:19,235] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:19,785] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.627 seconds
[2021-01-13 00:02:19,861] {scheduler_job.py:181} INFO - Started process (PID=218) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:19,867] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:19,871] {logging_mixin.py:103} INFO - [2021-01-13 00:02:19,870] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:19,900] {logging_mixin.py:103} INFO - [2021-01-13 00:02:19,896] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:19,904] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:20,466] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.613 seconds
[2021-01-13 00:02:20,525] {scheduler_job.py:181} INFO - Started process (PID=219) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:20,533] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:20,536] {logging_mixin.py:103} INFO - [2021-01-13 00:02:20,536] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:20,571] {logging_mixin.py:103} INFO - [2021-01-13 00:02:20,567] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:20,576] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:21,315] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.796 seconds
[2021-01-13 00:02:21,393] {scheduler_job.py:181} INFO - Started process (PID=220) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:21,417] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:21,422] {logging_mixin.py:103} INFO - [2021-01-13 00:02:21,422] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:21,463] {logging_mixin.py:103} INFO - [2021-01-13 00:02:21,457] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:21,468] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:22,140] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.763 seconds
[2021-01-13 00:02:22,194] {scheduler_job.py:181} INFO - Started process (PID=221) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:22,203] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:22,206] {logging_mixin.py:103} INFO - [2021-01-13 00:02:22,206] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:22,233] {logging_mixin.py:103} INFO - [2021-01-13 00:02:22,229] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:22,237] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:22,983] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.805 seconds
[2021-01-13 00:02:23,295] {scheduler_job.py:181} INFO - Started process (PID=222) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:23,344] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:23,523] {logging_mixin.py:103} INFO - [2021-01-13 00:02:23,523] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:23,597] {logging_mixin.py:103} INFO - [2021-01-13 00:02:23,588] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:23,609] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:24,365] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.107 seconds
[2021-01-13 00:02:24,417] {scheduler_job.py:181} INFO - Started process (PID=223) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:24,421] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:24,427] {logging_mixin.py:103} INFO - [2021-01-13 00:02:24,426] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:24,458] {logging_mixin.py:103} INFO - [2021-01-13 00:02:24,455] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:24,464] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:25,066] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.657 seconds
[2021-01-13 00:02:25,132] {scheduler_job.py:181} INFO - Started process (PID=224) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:25,137] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:25,141] {logging_mixin.py:103} INFO - [2021-01-13 00:02:25,140] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:25,188] {logging_mixin.py:103} INFO - [2021-01-13 00:02:25,178] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:25,193] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:25,809] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.686 seconds
[2021-01-13 00:02:25,911] {scheduler_job.py:181} INFO - Started process (PID=225) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:25,926] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:25,942] {logging_mixin.py:103} INFO - [2021-01-13 00:02:25,941] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:25,983] {logging_mixin.py:103} INFO - [2021-01-13 00:02:25,979] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:25,992] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:26,512] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.617 seconds
[2021-01-13 00:02:26,551] {scheduler_job.py:181} INFO - Started process (PID=226) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:26,554] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:26,557] {logging_mixin.py:103} INFO - [2021-01-13 00:02:26,557] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:26,583] {logging_mixin.py:103} INFO - [2021-01-13 00:02:26,580] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:26,589] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:27,117] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.571 seconds
[2021-01-13 00:02:27,172] {scheduler_job.py:181} INFO - Started process (PID=227) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:27,177] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:27,180] {logging_mixin.py:103} INFO - [2021-01-13 00:02:27,179] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:27,209] {logging_mixin.py:103} INFO - [2021-01-13 00:02:27,203] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:27,213] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:27,765] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.599 seconds
[2021-01-13 00:02:27,809] {scheduler_job.py:181} INFO - Started process (PID=228) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:27,813] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:27,816] {logging_mixin.py:103} INFO - [2021-01-13 00:02:27,815] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:27,853] {logging_mixin.py:103} INFO - [2021-01-13 00:02:27,847] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:27,889] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:28,417] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.616 seconds
[2021-01-13 00:02:28,459] {scheduler_job.py:181} INFO - Started process (PID=229) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:28,463] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:28,467] {logging_mixin.py:103} INFO - [2021-01-13 00:02:28,467] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:28,497] {logging_mixin.py:103} INFO - [2021-01-13 00:02:28,493] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:28,501] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:29,462] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.008 seconds
[2021-01-13 00:02:29,834] {scheduler_job.py:181} INFO - Started process (PID=230) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:29,848] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:29,855] {logging_mixin.py:103} INFO - [2021-01-13 00:02:29,855] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:29,937] {logging_mixin.py:103} INFO - [2021-01-13 00:02:29,934] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:29,943] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:30,655] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.833 seconds
[2021-01-13 00:02:30,721] {scheduler_job.py:181} INFO - Started process (PID=231) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:30,727] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:30,736] {logging_mixin.py:103} INFO - [2021-01-13 00:02:30,735] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:30,817] {logging_mixin.py:103} INFO - [2021-01-13 00:02:30,789] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:30,825] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:31,374] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.668 seconds
[2021-01-13 00:02:31,432] {scheduler_job.py:181} INFO - Started process (PID=232) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:31,438] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:31,445] {logging_mixin.py:103} INFO - [2021-01-13 00:02:31,444] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:31,480] {logging_mixin.py:103} INFO - [2021-01-13 00:02:31,476] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:31,485] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:32,077] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.657 seconds
[2021-01-13 00:02:32,128] {scheduler_job.py:181} INFO - Started process (PID=233) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:32,131] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:32,138] {logging_mixin.py:103} INFO - [2021-01-13 00:02:32,137] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:32,181] {logging_mixin.py:103} INFO - [2021-01-13 00:02:32,176] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:32,187] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:32,763] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.646 seconds
[2021-01-13 00:02:32,812] {scheduler_job.py:181} INFO - Started process (PID=234) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:32,817] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:32,820] {logging_mixin.py:103} INFO - [2021-01-13 00:02:32,820] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:32,855] {logging_mixin.py:103} INFO - [2021-01-13 00:02:32,851] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:32,860] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:33,470] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.666 seconds
[2021-01-13 00:02:33,522] {scheduler_job.py:181} INFO - Started process (PID=235) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:33,526] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:33,529] {logging_mixin.py:103} INFO - [2021-01-13 00:02:33,528] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:33,561] {logging_mixin.py:103} INFO - [2021-01-13 00:02:33,557] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:33,566] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:34,092] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.579 seconds
[2021-01-13 00:02:34,145] {scheduler_job.py:181} INFO - Started process (PID=236) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:34,148] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:34,151] {logging_mixin.py:103} INFO - [2021-01-13 00:02:34,150] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:34,184] {logging_mixin.py:103} INFO - [2021-01-13 00:02:34,181] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:34,189] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:34,742] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.603 seconds
[2021-01-13 00:02:34,791] {scheduler_job.py:181} INFO - Started process (PID=237) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:34,794] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:34,797] {logging_mixin.py:103} INFO - [2021-01-13 00:02:34,797] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:34,837] {logging_mixin.py:103} INFO - [2021-01-13 00:02:34,828] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:34,847] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:35,458] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.671 seconds
[2021-01-13 00:02:35,507] {scheduler_job.py:181} INFO - Started process (PID=238) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:35,509] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:35,511] {logging_mixin.py:103} INFO - [2021-01-13 00:02:35,511] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:35,540] {logging_mixin.py:103} INFO - [2021-01-13 00:02:35,537] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:35,545] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:36,105] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.605 seconds
[2021-01-13 00:02:36,147] {scheduler_job.py:181} INFO - Started process (PID=239) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:36,151] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:36,153] {logging_mixin.py:103} INFO - [2021-01-13 00:02:36,153] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:36,180] {logging_mixin.py:103} INFO - [2021-01-13 00:02:36,177] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:36,186] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:36,661] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.520 seconds
[2021-01-13 00:02:36,714] {scheduler_job.py:181} INFO - Started process (PID=240) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:36,718] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:36,720] {logging_mixin.py:103} INFO - [2021-01-13 00:02:36,720] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:36,752] {logging_mixin.py:103} INFO - [2021-01-13 00:02:36,746] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:36,759] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:37,561] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.855 seconds
[2021-01-13 00:02:37,611] {scheduler_job.py:181} INFO - Started process (PID=241) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:37,614] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:37,618] {logging_mixin.py:103} INFO - [2021-01-13 00:02:37,617] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:37,648] {logging_mixin.py:103} INFO - [2021-01-13 00:02:37,645] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:37,654] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:38,218] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.615 seconds
[2021-01-13 00:02:38,260] {scheduler_job.py:181} INFO - Started process (PID=242) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:38,263] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:38,266] {logging_mixin.py:103} INFO - [2021-01-13 00:02:38,265] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:38,294] {logging_mixin.py:103} INFO - [2021-01-13 00:02:38,288] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:38,298] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:38,814] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.559 seconds
[2021-01-13 00:02:38,879] {scheduler_job.py:181} INFO - Started process (PID=243) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:38,884] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:38,887] {logging_mixin.py:103} INFO - [2021-01-13 00:02:38,887] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:38,956] {logging_mixin.py:103} INFO - [2021-01-13 00:02:38,947] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:38,965] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:39,479] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.607 seconds
[2021-01-13 00:02:39,554] {scheduler_job.py:181} INFO - Started process (PID=244) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:39,559] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:39,564] {logging_mixin.py:103} INFO - [2021-01-13 00:02:39,563] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:39,625] {logging_mixin.py:103} INFO - [2021-01-13 00:02:39,610] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:39,630] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:40,274] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.733 seconds
[2021-01-13 00:02:40,341] {scheduler_job.py:181} INFO - Started process (PID=245) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:40,346] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:40,355] {logging_mixin.py:103} INFO - [2021-01-13 00:02:40,354] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:40,393] {logging_mixin.py:103} INFO - [2021-01-13 00:02:40,390] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:40,398] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:40,978] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.646 seconds
[2021-01-13 00:02:41,036] {scheduler_job.py:181} INFO - Started process (PID=246) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:41,041] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:41,045] {logging_mixin.py:103} INFO - [2021-01-13 00:02:41,045] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:41,090] {logging_mixin.py:103} INFO - [2021-01-13 00:02:41,087] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:41,096] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:42,036] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.007 seconds
[2021-01-13 00:02:42,281] {scheduler_job.py:181} INFO - Started process (PID=247) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:42,285] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:42,453] {logging_mixin.py:103} INFO - [2021-01-13 00:02:42,453] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:42,607] {logging_mixin.py:103} INFO - [2021-01-13 00:02:42,591] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:42,614] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:43,226] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.964 seconds
[2021-01-13 00:02:43,267] {scheduler_job.py:181} INFO - Started process (PID=248) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:43,270] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:43,273] {logging_mixin.py:103} INFO - [2021-01-13 00:02:43,273] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:43,301] {logging_mixin.py:103} INFO - [2021-01-13 00:02:43,298] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:43,306] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:43,848] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.586 seconds
[2021-01-13 00:02:43,927] {scheduler_job.py:181} INFO - Started process (PID=249) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:43,936] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:43,943] {logging_mixin.py:103} INFO - [2021-01-13 00:02:43,942] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:44,053] {logging_mixin.py:103} INFO - [2021-01-13 00:02:44,046] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:44,067] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:44,616] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.709 seconds
[2021-01-13 00:02:44,668] {scheduler_job.py:181} INFO - Started process (PID=250) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:44,674] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:44,679] {logging_mixin.py:103} INFO - [2021-01-13 00:02:44,678] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:44,719] {logging_mixin.py:103} INFO - [2021-01-13 00:02:44,715] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:44,732] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:45,355] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.698 seconds
[2021-01-13 00:02:45,416] {scheduler_job.py:181} INFO - Started process (PID=251) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:45,422] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:45,428] {logging_mixin.py:103} INFO - [2021-01-13 00:02:45,427] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:45,474] {logging_mixin.py:103} INFO - [2021-01-13 00:02:45,469] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:45,481] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:45,987] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.583 seconds
[2021-01-13 00:02:46,049] {scheduler_job.py:181} INFO - Started process (PID=252) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:46,055] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:46,061] {logging_mixin.py:103} INFO - [2021-01-13 00:02:46,060] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:46,101] {logging_mixin.py:103} INFO - [2021-01-13 00:02:46,097] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:46,107] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:46,554] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.551 seconds
[2021-01-13 00:02:46,614] {scheduler_job.py:181} INFO - Started process (PID=253) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:46,621] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:46,626] {logging_mixin.py:103} INFO - [2021-01-13 00:02:46,625] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:46,668] {logging_mixin.py:103} INFO - [2021-01-13 00:02:46,661] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:46,674] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:47,231] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.627 seconds
[2021-01-13 00:02:47,287] {scheduler_job.py:181} INFO - Started process (PID=254) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:47,295] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:47,303] {logging_mixin.py:103} INFO - [2021-01-13 00:02:47,302] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:47,339] {logging_mixin.py:103} INFO - [2021-01-13 00:02:47,333] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:47,346] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:47,946] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.672 seconds
[2021-01-13 00:02:48,005] {scheduler_job.py:181} INFO - Started process (PID=255) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:48,014] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:48,019] {logging_mixin.py:103} INFO - [2021-01-13 00:02:48,018] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:48,079] {logging_mixin.py:103} INFO - [2021-01-13 00:02:48,069] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:48,087] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:48,622] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.625 seconds
[2021-01-13 00:02:48,680] {scheduler_job.py:181} INFO - Started process (PID=256) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:48,684] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:48,688] {logging_mixin.py:103} INFO - [2021-01-13 00:02:48,687] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:48,718] {logging_mixin.py:103} INFO - [2021-01-13 00:02:48,715] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:48,722] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:49,266] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.595 seconds
[2021-01-13 00:02:49,318] {scheduler_job.py:181} INFO - Started process (PID=257) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:49,321] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:49,324] {logging_mixin.py:103} INFO - [2021-01-13 00:02:49,323] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:49,354] {logging_mixin.py:103} INFO - [2021-01-13 00:02:49,351] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:49,358] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:49,881] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.571 seconds
[2021-01-13 00:02:49,969] {scheduler_job.py:181} INFO - Started process (PID=258) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:49,975] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:49,980] {logging_mixin.py:103} INFO - [2021-01-13 00:02:49,979] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:50,022] {logging_mixin.py:103} INFO - [2021-01-13 00:02:50,018] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:50,028] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:50,638] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.679 seconds
[2021-01-13 00:02:50,855] {scheduler_job.py:181} INFO - Started process (PID=259) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:50,858] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:50,863] {logging_mixin.py:103} INFO - [2021-01-13 00:02:50,862] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:50,926] {logging_mixin.py:103} INFO - [2021-01-13 00:02:50,921] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:50,931] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:51,497] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.648 seconds
[2021-01-13 00:02:51,557] {scheduler_job.py:181} INFO - Started process (PID=260) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:51,561] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:51,563] {logging_mixin.py:103} INFO - [2021-01-13 00:02:51,563] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:51,592] {logging_mixin.py:103} INFO - [2021-01-13 00:02:51,589] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:51,595] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:52,119] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.568 seconds
[2021-01-13 00:02:52,188] {scheduler_job.py:181} INFO - Started process (PID=261) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:52,191] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:52,194] {logging_mixin.py:103} INFO - [2021-01-13 00:02:52,194] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:52,247] {logging_mixin.py:103} INFO - [2021-01-13 00:02:52,244] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:52,256] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:52,826] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.644 seconds
[2021-01-13 00:02:52,971] {scheduler_job.py:181} INFO - Started process (PID=262) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:52,982] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:52,991] {logging_mixin.py:103} INFO - [2021-01-13 00:02:52,991] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:53,038] {logging_mixin.py:103} INFO - [2021-01-13 00:02:53,030] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:53,049] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:53,612] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.653 seconds
[2021-01-13 00:02:53,729] {scheduler_job.py:181} INFO - Started process (PID=263) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:53,733] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:53,736] {logging_mixin.py:103} INFO - [2021-01-13 00:02:53,736] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:53,762] {logging_mixin.py:103} INFO - [2021-01-13 00:02:53,760] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:53,766] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:54,301] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.576 seconds
[2021-01-13 00:02:54,354] {scheduler_job.py:181} INFO - Started process (PID=264) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:54,359] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:54,362] {logging_mixin.py:103} INFO - [2021-01-13 00:02:54,362] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:54,403] {logging_mixin.py:103} INFO - [2021-01-13 00:02:54,396] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:54,407] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:54,908] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.562 seconds
[2021-01-13 00:02:54,997] {scheduler_job.py:181} INFO - Started process (PID=265) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:55,000] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:55,002] {logging_mixin.py:103} INFO - [2021-01-13 00:02:55,002] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:55,031] {logging_mixin.py:103} INFO - [2021-01-13 00:02:55,028] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:55,036] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:55,600] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.638 seconds
[2021-01-13 00:02:55,662] {scheduler_job.py:181} INFO - Started process (PID=266) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:55,669] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:55,676] {logging_mixin.py:103} INFO - [2021-01-13 00:02:55,675] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:55,717] {logging_mixin.py:103} INFO - [2021-01-13 00:02:55,713] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:55,726] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:56,278] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.628 seconds
[2021-01-13 00:02:56,329] {scheduler_job.py:181} INFO - Started process (PID=267) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:56,332] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:56,334] {logging_mixin.py:103} INFO - [2021-01-13 00:02:56,334] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:56,375] {logging_mixin.py:103} INFO - [2021-01-13 00:02:56,364] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:56,381] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:56,888] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.565 seconds
[2021-01-13 00:02:56,943] {scheduler_job.py:181} INFO - Started process (PID=268) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:56,947] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:56,950] {logging_mixin.py:103} INFO - [2021-01-13 00:02:56,949] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:57,017] {logging_mixin.py:103} INFO - [2021-01-13 00:02:57,012] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:57,022] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:57,570] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.639 seconds
[2021-01-13 00:02:57,615] {scheduler_job.py:181} INFO - Started process (PID=269) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:57,618] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:57,621] {logging_mixin.py:103} INFO - [2021-01-13 00:02:57,621] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:57,645] {logging_mixin.py:103} INFO - [2021-01-13 00:02:57,643] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:57,652] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:58,234] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.624 seconds
[2021-01-13 00:02:58,338] {scheduler_job.py:181} INFO - Started process (PID=270) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:58,346] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:58,364] {logging_mixin.py:103} INFO - [2021-01-13 00:02:58,364] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:58,456] {logging_mixin.py:103} INFO - [2021-01-13 00:02:58,450] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:58,464] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:59,167] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.838 seconds
[2021-01-13 00:02:59,230] {scheduler_job.py:181} INFO - Started process (PID=271) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:59,237] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:59,240] {logging_mixin.py:103} INFO - [2021-01-13 00:02:59,240] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:02:59,311] {logging_mixin.py:103} INFO - [2021-01-13 00:02:59,300] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:02:59,324] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:02:59,853] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.636 seconds
[2021-01-13 00:02:59,963] {scheduler_job.py:181} INFO - Started process (PID=272) to work on /opt/airflow/dags/example.py
[2021-01-13 00:02:59,968] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:02:59,972] {logging_mixin.py:103} INFO - [2021-01-13 00:02:59,971] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:00,198] {logging_mixin.py:103} INFO - [2021-01-13 00:03:00,190] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:00,207] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:00,847] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.899 seconds
[2021-01-13 00:03:01,046] {scheduler_job.py:181} INFO - Started process (PID=273) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:01,050] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:01,059] {logging_mixin.py:103} INFO - [2021-01-13 00:03:01,059] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:01,104] {logging_mixin.py:103} INFO - [2021-01-13 00:03:01,100] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:01,116] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:01,704] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.669 seconds
[2021-01-13 00:03:01,923] {scheduler_job.py:181} INFO - Started process (PID=274) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:01,929] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:01,933] {logging_mixin.py:103} INFO - [2021-01-13 00:03:01,933] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:01,979] {logging_mixin.py:103} INFO - [2021-01-13 00:03:01,970] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:02,009] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:02,502] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.620 seconds
[2021-01-13 00:03:02,799] {scheduler_job.py:181} INFO - Started process (PID=275) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:02,815] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:02,828] {logging_mixin.py:103} INFO - [2021-01-13 00:03:02,827] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:02,954] {logging_mixin.py:103} INFO - [2021-01-13 00:03:02,951] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:03,012] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:03,599] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.829 seconds
[2021-01-13 00:03:03,701] {scheduler_job.py:181} INFO - Started process (PID=276) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:03,708] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:03,715] {logging_mixin.py:103} INFO - [2021-01-13 00:03:03,711] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:03,771] {logging_mixin.py:103} INFO - [2021-01-13 00:03:03,758] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:03,810] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:04,938] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.255 seconds
[2021-01-13 00:03:05,035] {scheduler_job.py:181} INFO - Started process (PID=277) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:05,043] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:05,049] {logging_mixin.py:103} INFO - [2021-01-13 00:03:05,048] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:05,100] {logging_mixin.py:103} INFO - [2021-01-13 00:03:05,090] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:05,113] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:05,694] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.670 seconds
[2021-01-13 00:03:06,037] {scheduler_job.py:181} INFO - Started process (PID=278) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:06,043] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:06,048] {logging_mixin.py:103} INFO - [2021-01-13 00:03:06,047] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:06,089] {logging_mixin.py:103} INFO - [2021-01-13 00:03:06,084] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:06,096] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:06,764] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.739 seconds
[2021-01-13 00:03:06,870] {scheduler_job.py:181} INFO - Started process (PID=279) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:06,873] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:06,876] {logging_mixin.py:103} INFO - [2021-01-13 00:03:06,876] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:06,917] {logging_mixin.py:103} INFO - [2021-01-13 00:03:06,912] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:06,924] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:07,491] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.635 seconds
[2021-01-13 00:03:07,552] {scheduler_job.py:181} INFO - Started process (PID=280) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:07,555] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:07,558] {logging_mixin.py:103} INFO - [2021-01-13 00:03:07,558] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:07,592] {logging_mixin.py:103} INFO - [2021-01-13 00:03:07,589] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:07,600] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:08,208] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.664 seconds
[2021-01-13 00:03:08,267] {scheduler_job.py:181} INFO - Started process (PID=281) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:08,270] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:08,273] {logging_mixin.py:103} INFO - [2021-01-13 00:03:08,273] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:08,306] {logging_mixin.py:103} INFO - [2021-01-13 00:03:08,301] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:08,333] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:08,936] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.674 seconds
[2021-01-13 00:03:09,492] {scheduler_job.py:181} INFO - Started process (PID=282) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:09,498] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:09,502] {logging_mixin.py:103} INFO - [2021-01-13 00:03:09,502] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:09,546] {logging_mixin.py:103} INFO - [2021-01-13 00:03:09,538] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:09,550] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:10,160] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.703 seconds
[2021-01-13 00:03:10,263] {scheduler_job.py:181} INFO - Started process (PID=283) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:10,269] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:10,274] {logging_mixin.py:103} INFO - [2021-01-13 00:03:10,274] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:10,328] {logging_mixin.py:103} INFO - [2021-01-13 00:03:10,324] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:10,333] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:10,885] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.635 seconds
[2021-01-13 00:03:10,969] {scheduler_job.py:181} INFO - Started process (PID=284) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:10,979] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:10,994] {logging_mixin.py:103} INFO - [2021-01-13 00:03:10,994] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:11,284] {logging_mixin.py:103} INFO - [2021-01-13 00:03:11,270] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:11,294] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:11,937] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.981 seconds
[2021-01-13 00:03:12,103] {scheduler_job.py:181} INFO - Started process (PID=285) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:12,137] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:12,142] {logging_mixin.py:103} INFO - [2021-01-13 00:03:12,142] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:12,230] {logging_mixin.py:103} INFO - [2021-01-13 00:03:12,198] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:12,251] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:12,827] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.746 seconds
[2021-01-13 00:03:12,899] {scheduler_job.py:181} INFO - Started process (PID=286) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:12,902] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:12,906] {logging_mixin.py:103} INFO - [2021-01-13 00:03:12,905] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:12,939] {logging_mixin.py:103} INFO - [2021-01-13 00:03:12,934] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:12,942] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:13,648] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.765 seconds
[2021-01-13 00:03:13,727] {scheduler_job.py:181} INFO - Started process (PID=287) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:13,730] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:13,732] {logging_mixin.py:103} INFO - [2021-01-13 00:03:13,732] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:13,763] {logging_mixin.py:103} INFO - [2021-01-13 00:03:13,760] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:13,767] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:14,281] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.560 seconds
[2021-01-13 00:03:14,337] {scheduler_job.py:181} INFO - Started process (PID=288) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:14,341] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:14,343] {logging_mixin.py:103} INFO - [2021-01-13 00:03:14,343] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:14,378] {logging_mixin.py:103} INFO - [2021-01-13 00:03:14,373] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:14,389] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:14,928] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.601 seconds
[2021-01-13 00:03:14,991] {scheduler_job.py:181} INFO - Started process (PID=289) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:14,995] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:14,999] {logging_mixin.py:103} INFO - [2021-01-13 00:03:14,998] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:15,029] {logging_mixin.py:103} INFO - [2021-01-13 00:03:15,025] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:15,037] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:15,588] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.609 seconds
[2021-01-13 00:03:15,634] {scheduler_job.py:181} INFO - Started process (PID=290) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:15,637] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:15,640] {logging_mixin.py:103} INFO - [2021-01-13 00:03:15,640] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:15,669] {logging_mixin.py:103} INFO - [2021-01-13 00:03:15,664] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:15,673] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:16,249] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.624 seconds
[2021-01-13 00:03:16,302] {scheduler_job.py:181} INFO - Started process (PID=291) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:16,306] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:16,310] {logging_mixin.py:103} INFO - [2021-01-13 00:03:16,310] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:16,344] {logging_mixin.py:103} INFO - [2021-01-13 00:03:16,341] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:16,348] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:16,897] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.639 seconds
[2021-01-13 00:03:16,985] {scheduler_job.py:181} INFO - Started process (PID=292) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:16,990] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:16,993] {logging_mixin.py:103} INFO - [2021-01-13 00:03:16,993] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:17,086] {logging_mixin.py:103} INFO - [2021-01-13 00:03:17,080] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:17,093] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:17,610] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.643 seconds
[2021-01-13 00:03:17,727] {scheduler_job.py:181} INFO - Started process (PID=293) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:17,731] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:17,741] {logging_mixin.py:103} INFO - [2021-01-13 00:03:17,741] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:17,906] {logging_mixin.py:103} INFO - [2021-01-13 00:03:17,878] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:17,917] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:18,562] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.855 seconds
[2021-01-13 00:03:18,778] {scheduler_job.py:181} INFO - Started process (PID=294) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:18,793] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:18,802] {logging_mixin.py:103} INFO - [2021-01-13 00:03:18,798] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:18,938] {logging_mixin.py:103} INFO - [2021-01-13 00:03:18,913] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:18,948] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:19,979] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.223 seconds
[2021-01-13 00:03:20,867] {scheduler_job.py:181} INFO - Started process (PID=295) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:20,925] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:20,951] {logging_mixin.py:103} INFO - [2021-01-13 00:03:20,951] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:21,006] {logging_mixin.py:103} INFO - [2021-01-13 00:03:20,992] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:21,013] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:21,574] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.856 seconds
[2021-01-13 00:03:21,813] {scheduler_job.py:181} INFO - Started process (PID=296) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:21,816] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:21,822] {logging_mixin.py:103} INFO - [2021-01-13 00:03:21,822] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:21,862] {logging_mixin.py:103} INFO - [2021-01-13 00:03:21,858] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:21,868] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:22,462] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.658 seconds
[2021-01-13 00:03:22,520] {scheduler_job.py:181} INFO - Started process (PID=297) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:22,522] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:22,525] {logging_mixin.py:103} INFO - [2021-01-13 00:03:22,525] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:22,553] {logging_mixin.py:103} INFO - [2021-01-13 00:03:22,551] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:22,558] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:23,162] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.649 seconds
[2021-01-13 00:03:23,267] {scheduler_job.py:181} INFO - Started process (PID=298) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:23,280] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:23,292] {logging_mixin.py:103} INFO - [2021-01-13 00:03:23,291] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:23,354] {logging_mixin.py:103} INFO - [2021-01-13 00:03:23,350] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:23,378] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:24,171] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.917 seconds
[2021-01-13 00:03:24,285] {scheduler_job.py:181} INFO - Started process (PID=299) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:24,290] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:24,293] {logging_mixin.py:103} INFO - [2021-01-13 00:03:24,293] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:24,376] {logging_mixin.py:103} INFO - [2021-01-13 00:03:24,371] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:24,502] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:25,114] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.835 seconds
[2021-01-13 00:03:25,191] {scheduler_job.py:181} INFO - Started process (PID=300) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:25,196] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:25,200] {logging_mixin.py:103} INFO - [2021-01-13 00:03:25,200] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:25,251] {logging_mixin.py:103} INFO - [2021-01-13 00:03:25,246] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:25,261] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:25,881] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.701 seconds
[2021-01-13 00:03:25,938] {scheduler_job.py:181} INFO - Started process (PID=301) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:25,943] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:25,948] {logging_mixin.py:103} INFO - [2021-01-13 00:03:25,947] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:25,983] {logging_mixin.py:103} INFO - [2021-01-13 00:03:25,978] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:25,987] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:26,490] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.558 seconds
[2021-01-13 00:03:26,573] {scheduler_job.py:181} INFO - Started process (PID=302) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:26,577] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:26,580] {logging_mixin.py:103} INFO - [2021-01-13 00:03:26,580] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:26,660] {logging_mixin.py:103} INFO - [2021-01-13 00:03:26,619] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:26,666] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:27,194] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.627 seconds
[2021-01-13 00:03:27,386] {scheduler_job.py:181} INFO - Started process (PID=303) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:27,393] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:27,398] {logging_mixin.py:103} INFO - [2021-01-13 00:03:27,397] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:27,469] {logging_mixin.py:103} INFO - [2021-01-13 00:03:27,457] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:27,482] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:28,094] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.725 seconds
[2021-01-13 00:03:28,142] {scheduler_job.py:181} INFO - Started process (PID=304) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:28,144] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:28,148] {logging_mixin.py:103} INFO - [2021-01-13 00:03:28,148] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:28,175] {logging_mixin.py:103} INFO - [2021-01-13 00:03:28,173] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:28,179] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:28,789] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.653 seconds
[2021-01-13 00:03:28,968] {scheduler_job.py:181} INFO - Started process (PID=305) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:28,972] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:28,976] {logging_mixin.py:103} INFO - [2021-01-13 00:03:28,975] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:29,148] {logging_mixin.py:103} INFO - [2021-01-13 00:03:29,106] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:29,162] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:29,724] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.782 seconds
[2021-01-13 00:03:29,821] {scheduler_job.py:181} INFO - Started process (PID=306) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:29,826] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:29,831] {logging_mixin.py:103} INFO - [2021-01-13 00:03:29,831] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:29,955] {logging_mixin.py:103} INFO - [2021-01-13 00:03:29,925] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:29,990] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:30,641] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.831 seconds
[2021-01-13 00:03:30,741] {scheduler_job.py:181} INFO - Started process (PID=307) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:30,749] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:30,756] {logging_mixin.py:103} INFO - [2021-01-13 00:03:30,755] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:30,822] {logging_mixin.py:103} INFO - [2021-01-13 00:03:30,817] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:30,829] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:31,487] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.758 seconds
[2021-01-13 00:03:31,535] {scheduler_job.py:181} INFO - Started process (PID=308) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:31,540] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:31,543] {logging_mixin.py:103} INFO - [2021-01-13 00:03:31,543] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:31,570] {logging_mixin.py:103} INFO - [2021-01-13 00:03:31,566] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:31,575] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:32,124] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.594 seconds
[2021-01-13 00:03:32,349] {scheduler_job.py:181} INFO - Started process (PID=309) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:32,354] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:32,357] {logging_mixin.py:103} INFO - [2021-01-13 00:03:32,357] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:32,388] {logging_mixin.py:103} INFO - [2021-01-13 00:03:32,383] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:32,401] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:32,997] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.660 seconds
[2021-01-13 00:03:33,149] {scheduler_job.py:181} INFO - Started process (PID=310) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:33,167] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:33,175] {logging_mixin.py:103} INFO - [2021-01-13 00:03:33,175] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:33,252] {logging_mixin.py:103} INFO - [2021-01-13 00:03:33,243] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:33,268] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:33,839] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.745 seconds
[2021-01-13 00:03:33,997] {scheduler_job.py:181} INFO - Started process (PID=311) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:34,002] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:34,009] {logging_mixin.py:103} INFO - [2021-01-13 00:03:34,009] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:34,118] {logging_mixin.py:103} INFO - [2021-01-13 00:03:34,106] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:34,129] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:34,747] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.755 seconds
[2021-01-13 00:03:34,814] {scheduler_job.py:181} INFO - Started process (PID=312) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:34,956] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:34,980] {logging_mixin.py:103} INFO - [2021-01-13 00:03:34,980] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:35,111] {logging_mixin.py:103} INFO - [2021-01-13 00:03:35,107] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:35,119] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:35,889] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.094 seconds
[2021-01-13 00:03:35,998] {scheduler_job.py:181} INFO - Started process (PID=313) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:36,007] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:36,012] {logging_mixin.py:103} INFO - [2021-01-13 00:03:36,012] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:36,143] {logging_mixin.py:103} INFO - [2021-01-13 00:03:36,128] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:36,155] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:36,828] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.845 seconds
[2021-01-13 00:03:36,944] {scheduler_job.py:181} INFO - Started process (PID=314) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:36,948] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:36,953] {logging_mixin.py:103} INFO - [2021-01-13 00:03:36,952] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:37,003] {logging_mixin.py:103} INFO - [2021-01-13 00:03:36,996] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:37,013] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:37,595] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.668 seconds
[2021-01-13 00:03:37,816] {scheduler_job.py:181} INFO - Started process (PID=315) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:37,826] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:37,835] {logging_mixin.py:103} INFO - [2021-01-13 00:03:37,835] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:37,888] {logging_mixin.py:103} INFO - [2021-01-13 00:03:37,880] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:37,896] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:38,530] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.867 seconds
[2021-01-13 00:03:38,594] {scheduler_job.py:181} INFO - Started process (PID=316) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:38,603] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:38,607] {logging_mixin.py:103} INFO - [2021-01-13 00:03:38,606] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:38,815] {logging_mixin.py:103} INFO - [2021-01-13 00:03:38,811] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:38,822] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:39,380] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.800 seconds
[2021-01-13 00:03:39,438] {scheduler_job.py:181} INFO - Started process (PID=317) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:39,448] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:39,453] {logging_mixin.py:103} INFO - [2021-01-13 00:03:39,452] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:39,505] {logging_mixin.py:103} INFO - [2021-01-13 00:03:39,499] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:39,512] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:40,152] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.727 seconds
[2021-01-13 00:03:40,244] {scheduler_job.py:181} INFO - Started process (PID=318) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:40,250] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:40,252] {logging_mixin.py:103} INFO - [2021-01-13 00:03:40,252] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:40,279] {logging_mixin.py:103} INFO - [2021-01-13 00:03:40,276] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:40,283] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:40,886] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.648 seconds
[2021-01-13 00:03:41,076] {scheduler_job.py:181} INFO - Started process (PID=319) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:41,121] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:41,141] {logging_mixin.py:103} INFO - [2021-01-13 00:03:41,140] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:41,250] {logging_mixin.py:103} INFO - [2021-01-13 00:03:41,240] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:41,258] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:42,200] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.142 seconds
[2021-01-13 00:03:42,522] {scheduler_job.py:181} INFO - Started process (PID=320) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:42,527] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:42,539] {logging_mixin.py:103} INFO - [2021-01-13 00:03:42,538] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:42,785] {logging_mixin.py:103} INFO - [2021-01-13 00:03:42,757] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:42,794] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:43,394] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.889 seconds
[2021-01-13 00:03:43,466] {scheduler_job.py:181} INFO - Started process (PID=321) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:43,474] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:43,479] {logging_mixin.py:103} INFO - [2021-01-13 00:03:43,479] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:43,522] {logging_mixin.py:103} INFO - [2021-01-13 00:03:43,517] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:43,530] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:44,278] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.826 seconds
[2021-01-13 00:03:44,387] {scheduler_job.py:181} INFO - Started process (PID=322) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:44,395] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:44,412] {logging_mixin.py:103} INFO - [2021-01-13 00:03:44,412] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:44,480] {logging_mixin.py:103} INFO - [2021-01-13 00:03:44,469] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:44,492] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:45,265] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.903 seconds
[2021-01-13 00:03:45,419] {scheduler_job.py:181} INFO - Started process (PID=323) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:45,432] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:45,435] {logging_mixin.py:103} INFO - [2021-01-13 00:03:45,435] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:45,500] {logging_mixin.py:103} INFO - [2021-01-13 00:03:45,494] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:45,510] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:46,090] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.704 seconds
[2021-01-13 00:03:46,170] {scheduler_job.py:181} INFO - Started process (PID=324) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:46,180] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:46,194] {logging_mixin.py:103} INFO - [2021-01-13 00:03:46,191] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:46,313] {logging_mixin.py:103} INFO - [2021-01-13 00:03:46,290] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:46,324] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:47,166] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.039 seconds
[2021-01-13 00:03:47,409] {scheduler_job.py:181} INFO - Started process (PID=325) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:47,436] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:47,460] {logging_mixin.py:103} INFO - [2021-01-13 00:03:47,460] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:47,566] {logging_mixin.py:103} INFO - [2021-01-13 00:03:47,539] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:47,575] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:48,475] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.077 seconds
[2021-01-13 00:03:48,877] {scheduler_job.py:181} INFO - Started process (PID=326) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:48,949] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:48,969] {logging_mixin.py:103} INFO - [2021-01-13 00:03:48,968] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:49,186] {logging_mixin.py:103} INFO - [2021-01-13 00:03:49,182] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:49,197] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:50,176] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.342 seconds
[2021-01-13 00:03:50,410] {scheduler_job.py:181} INFO - Started process (PID=327) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:50,417] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:50,422] {logging_mixin.py:103} INFO - [2021-01-13 00:03:50,421] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:50,535] {logging_mixin.py:103} INFO - [2021-01-13 00:03:50,508] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:50,650] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:54,818] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 4.488 seconds
[2021-01-13 00:03:54,902] {scheduler_job.py:181} INFO - Started process (PID=328) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:54,906] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:54,910] {logging_mixin.py:103} INFO - [2021-01-13 00:03:54,909] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:54,944] {logging_mixin.py:103} INFO - [2021-01-13 00:03:54,941] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:54,957] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:55,597] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.702 seconds
[2021-01-13 00:03:55,683] {scheduler_job.py:181} INFO - Started process (PID=329) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:55,694] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:55,697] {logging_mixin.py:103} INFO - [2021-01-13 00:03:55,697] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:55,779] {logging_mixin.py:103} INFO - [2021-01-13 00:03:55,752] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:55,799] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:56,429] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.760 seconds
[2021-01-13 00:03:56,479] {scheduler_job.py:181} INFO - Started process (PID=330) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:56,485] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:56,491] {logging_mixin.py:103} INFO - [2021-01-13 00:03:56,490] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:56,530] {logging_mixin.py:103} INFO - [2021-01-13 00:03:56,527] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:56,536] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:57,152] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.679 seconds
[2021-01-13 00:03:57,193] {scheduler_job.py:181} INFO - Started process (PID=331) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:57,197] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:57,200] {logging_mixin.py:103} INFO - [2021-01-13 00:03:57,200] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:57,232] {logging_mixin.py:103} INFO - [2021-01-13 00:03:57,229] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:57,236] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:57,906] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.722 seconds
[2021-01-13 00:03:58,332] {scheduler_job.py:181} INFO - Started process (PID=332) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:58,341] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:58,345] {logging_mixin.py:103} INFO - [2021-01-13 00:03:58,344] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:58,575] {logging_mixin.py:103} INFO - [2021-01-13 00:03:58,564] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:58,593] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:03:59,301] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.979 seconds
[2021-01-13 00:03:59,369] {scheduler_job.py:181} INFO - Started process (PID=333) to work on /opt/airflow/dags/example.py
[2021-01-13 00:03:59,377] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:03:59,381] {logging_mixin.py:103} INFO - [2021-01-13 00:03:59,381] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:03:59,445] {logging_mixin.py:103} INFO - [2021-01-13 00:03:59,442] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:03:59,450] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:00,177] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.818 seconds
[2021-01-13 00:04:00,242] {scheduler_job.py:181} INFO - Started process (PID=334) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:00,245] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:00,248] {logging_mixin.py:103} INFO - [2021-01-13 00:04:00,248] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:00,297] {logging_mixin.py:103} INFO - [2021-01-13 00:04:00,293] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:00,310] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:00,825] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.595 seconds
[2021-01-13 00:04:00,882] {scheduler_job.py:181} INFO - Started process (PID=335) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:00,887] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:00,977] {logging_mixin.py:103} INFO - [2021-01-13 00:04:00,935] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:01,048] {logging_mixin.py:103} INFO - [2021-01-13 00:04:01,042] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:01,059] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:01,722] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.846 seconds
[2021-01-13 00:04:01,778] {scheduler_job.py:181} INFO - Started process (PID=336) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:01,782] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:01,786] {logging_mixin.py:103} INFO - [2021-01-13 00:04:01,786] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:01,822] {logging_mixin.py:103} INFO - [2021-01-13 00:04:01,817] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:01,830] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:02,504] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.739 seconds
[2021-01-13 00:04:02,558] {scheduler_job.py:181} INFO - Started process (PID=337) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:02,562] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:02,565] {logging_mixin.py:103} INFO - [2021-01-13 00:04:02,565] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:02,607] {logging_mixin.py:103} INFO - [2021-01-13 00:04:02,602] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:02,612] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:03,203] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.652 seconds
[2021-01-13 00:04:03,250] {scheduler_job.py:181} INFO - Started process (PID=338) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:03,254] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:03,258] {logging_mixin.py:103} INFO - [2021-01-13 00:04:03,257] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:03,293] {logging_mixin.py:103} INFO - [2021-01-13 00:04:03,289] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:03,300] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:03,895] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.654 seconds
[2021-01-13 00:04:04,055] {scheduler_job.py:181} INFO - Started process (PID=339) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:04,064] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:04,072] {logging_mixin.py:103} INFO - [2021-01-13 00:04:04,072] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:04,124] {logging_mixin.py:103} INFO - [2021-01-13 00:04:04,119] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:04,132] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:04,633] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.584 seconds
[2021-01-13 00:04:05,080] {scheduler_job.py:181} INFO - Started process (PID=340) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:05,084] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:05,088] {logging_mixin.py:103} INFO - [2021-01-13 00:04:05,087] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:05,126] {logging_mixin.py:103} INFO - [2021-01-13 00:04:05,122] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:05,130] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:05,668] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.597 seconds
[2021-01-13 00:04:05,714] {scheduler_job.py:181} INFO - Started process (PID=341) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:05,717] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:05,720] {logging_mixin.py:103} INFO - [2021-01-13 00:04:05,719] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:05,747] {logging_mixin.py:103} INFO - [2021-01-13 00:04:05,742] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:05,751] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:06,448] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.739 seconds
[2021-01-13 00:04:06,488] {scheduler_job.py:181} INFO - Started process (PID=342) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:06,492] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:06,494] {logging_mixin.py:103} INFO - [2021-01-13 00:04:06,494] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:06,523] {logging_mixin.py:103} INFO - [2021-01-13 00:04:06,520] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:06,528] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:07,184] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.702 seconds
[2021-01-13 00:04:07,236] {scheduler_job.py:181} INFO - Started process (PID=343) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:07,239] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:07,242] {logging_mixin.py:103} INFO - [2021-01-13 00:04:07,242] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:07,305] {logging_mixin.py:103} INFO - [2021-01-13 00:04:07,295] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:07,310] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:07,845] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.615 seconds
[2021-01-13 00:04:07,892] {scheduler_job.py:181} INFO - Started process (PID=344) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:07,896] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:07,898] {logging_mixin.py:103} INFO - [2021-01-13 00:04:07,898] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:07,941] {logging_mixin.py:103} INFO - [2021-01-13 00:04:07,937] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:07,953] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:08,590] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.703 seconds
[2021-01-13 00:04:08,645] {scheduler_job.py:181} INFO - Started process (PID=345) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:08,648] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:08,651] {logging_mixin.py:103} INFO - [2021-01-13 00:04:08,650] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:08,703] {logging_mixin.py:103} INFO - [2021-01-13 00:04:08,700] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:08,708] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:09,345] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.708 seconds
[2021-01-13 00:04:09,396] {scheduler_job.py:181} INFO - Started process (PID=346) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:09,400] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:09,403] {logging_mixin.py:103} INFO - [2021-01-13 00:04:09,403] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:09,441] {logging_mixin.py:103} INFO - [2021-01-13 00:04:09,436] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:09,448] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:10,121] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.736 seconds
[2021-01-13 00:04:10,158] {scheduler_job.py:181} INFO - Started process (PID=347) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:10,162] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:10,164] {logging_mixin.py:103} INFO - [2021-01-13 00:04:10,164] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:10,193] {logging_mixin.py:103} INFO - [2021-01-13 00:04:10,188] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:10,205] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:10,783] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.632 seconds
[2021-01-13 00:04:11,000] {scheduler_job.py:181} INFO - Started process (PID=348) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:11,009] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:11,022] {logging_mixin.py:103} INFO - [2021-01-13 00:04:11,018] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:11,604] {logging_mixin.py:103} INFO - [2021-01-13 00:04:11,281] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:11,624] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:12,287] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.310 seconds
[2021-01-13 00:04:12,338] {scheduler_job.py:181} INFO - Started process (PID=349) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:12,341] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:12,344] {logging_mixin.py:103} INFO - [2021-01-13 00:04:12,344] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:12,377] {logging_mixin.py:103} INFO - [2021-01-13 00:04:12,374] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:12,383] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:13,041] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.710 seconds
[2021-01-13 00:04:13,114] {scheduler_job.py:181} INFO - Started process (PID=350) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:13,118] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:13,130] {logging_mixin.py:103} INFO - [2021-01-13 00:04:13,130] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:13,172] {logging_mixin.py:103} INFO - [2021-01-13 00:04:13,164] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:13,181] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:14,012] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.910 seconds
[2021-01-13 00:04:14,060] {scheduler_job.py:181} INFO - Started process (PID=351) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:14,064] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:14,067] {logging_mixin.py:103} INFO - [2021-01-13 00:04:14,067] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:14,114] {logging_mixin.py:103} INFO - [2021-01-13 00:04:14,110] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:14,119] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:14,663] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.609 seconds
[2021-01-13 00:04:15,175] {scheduler_job.py:181} INFO - Started process (PID=352) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:15,184] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:15,189] {logging_mixin.py:103} INFO - [2021-01-13 00:04:15,189] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:15,288] {logging_mixin.py:103} INFO - [2021-01-13 00:04:15,270] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:15,301] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:15,940] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.773 seconds
[2021-01-13 00:04:16,013] {scheduler_job.py:181} INFO - Started process (PID=353) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:16,020] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:16,025] {logging_mixin.py:103} INFO - [2021-01-13 00:04:16,024] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:16,078] {logging_mixin.py:103} INFO - [2021-01-13 00:04:16,074] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:16,084] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:16,811] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.834 seconds
[2021-01-13 00:04:17,262] {scheduler_job.py:181} INFO - Started process (PID=354) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:17,299] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:17,320] {logging_mixin.py:103} INFO - [2021-01-13 00:04:17,318] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:17,463] {logging_mixin.py:103} INFO - [2021-01-13 00:04:17,444] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:17,470] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:18,224] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.987 seconds
[2021-01-13 00:04:18,285] {scheduler_job.py:181} INFO - Started process (PID=355) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:18,291] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:18,302] {logging_mixin.py:103} INFO - [2021-01-13 00:04:18,301] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:18,346] {logging_mixin.py:103} INFO - [2021-01-13 00:04:18,342] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:18,368] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:18,937] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.659 seconds
[2021-01-13 00:04:18,995] {scheduler_job.py:181} INFO - Started process (PID=356) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:18,998] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:19,003] {logging_mixin.py:103} INFO - [2021-01-13 00:04:19,002] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:19,048] {logging_mixin.py:103} INFO - [2021-01-13 00:04:19,040] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:19,054] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:19,680] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.697 seconds
[2021-01-13 00:04:19,735] {scheduler_job.py:181} INFO - Started process (PID=357) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:19,740] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:19,745] {logging_mixin.py:103} INFO - [2021-01-13 00:04:19,744] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:19,786] {logging_mixin.py:103} INFO - [2021-01-13 00:04:19,781] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:19,793] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:20,342] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.617 seconds
[2021-01-13 00:04:20,392] {scheduler_job.py:181} INFO - Started process (PID=358) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:20,396] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:20,399] {logging_mixin.py:103} INFO - [2021-01-13 00:04:20,399] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:20,435] {logging_mixin.py:103} INFO - [2021-01-13 00:04:20,429] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:20,439] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:21,034] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.654 seconds
[2021-01-13 00:04:21,162] {scheduler_job.py:181} INFO - Started process (PID=359) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:21,169] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:21,175] {logging_mixin.py:103} INFO - [2021-01-13 00:04:21,175] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:21,211] {logging_mixin.py:103} INFO - [2021-01-13 00:04:21,208] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:21,218] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:21,804] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.653 seconds
[2021-01-13 00:04:21,909] {scheduler_job.py:181} INFO - Started process (PID=360) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:21,914] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:21,917] {logging_mixin.py:103} INFO - [2021-01-13 00:04:21,917] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:21,966] {logging_mixin.py:103} INFO - [2021-01-13 00:04:21,963] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:21,970] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:22,565] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.672 seconds
[2021-01-13 00:04:22,605] {scheduler_job.py:181} INFO - Started process (PID=361) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:22,609] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:22,611] {logging_mixin.py:103} INFO - [2021-01-13 00:04:22,611] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:22,640] {logging_mixin.py:103} INFO - [2021-01-13 00:04:22,637] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:22,645] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:23,322] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.723 seconds
[2021-01-13 00:04:23,411] {scheduler_job.py:181} INFO - Started process (PID=362) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:23,416] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:23,419] {logging_mixin.py:103} INFO - [2021-01-13 00:04:23,418] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:23,453] {logging_mixin.py:103} INFO - [2021-01-13 00:04:23,449] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:23,460] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:24,084] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.686 seconds
[2021-01-13 00:04:24,153] {scheduler_job.py:181} INFO - Started process (PID=363) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:24,156] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:24,164] {logging_mixin.py:103} INFO - [2021-01-13 00:04:24,164] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:24,208] {logging_mixin.py:103} INFO - [2021-01-13 00:04:24,204] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:24,217] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:24,846] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.704 seconds
[2021-01-13 00:04:24,911] {scheduler_job.py:181} INFO - Started process (PID=364) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:24,914] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:24,918] {logging_mixin.py:103} INFO - [2021-01-13 00:04:24,918] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:24,955] {logging_mixin.py:103} INFO - [2021-01-13 00:04:24,950] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:24,959] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:25,510] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.607 seconds
[2021-01-13 00:04:25,703] {scheduler_job.py:181} INFO - Started process (PID=365) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:25,706] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:25,708] {logging_mixin.py:103} INFO - [2021-01-13 00:04:25,708] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:25,734] {logging_mixin.py:103} INFO - [2021-01-13 00:04:25,731] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:25,739] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:26,427] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.730 seconds
[2021-01-13 00:04:26,470] {scheduler_job.py:181} INFO - Started process (PID=366) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:26,473] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:26,477] {logging_mixin.py:103} INFO - [2021-01-13 00:04:26,477] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:26,503] {logging_mixin.py:103} INFO - [2021-01-13 00:04:26,500] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:26,506] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:27,109] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.645 seconds
[2021-01-13 00:04:27,169] {scheduler_job.py:181} INFO - Started process (PID=367) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:27,172] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:27,175] {logging_mixin.py:103} INFO - [2021-01-13 00:04:27,175] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:27,225] {logging_mixin.py:103} INFO - [2021-01-13 00:04:27,221] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:27,235] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:27,811] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.650 seconds
[2021-01-13 00:04:27,900] {scheduler_job.py:181} INFO - Started process (PID=368) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:27,907] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:27,911] {logging_mixin.py:103} INFO - [2021-01-13 00:04:27,911] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:28,019] {logging_mixin.py:103} INFO - [2021-01-13 00:04:28,014] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:28,025] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:28,627] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.738 seconds
[2021-01-13 00:04:29,416] {scheduler_job.py:181} INFO - Started process (PID=369) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:29,421] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:29,425] {logging_mixin.py:103} INFO - [2021-01-13 00:04:29,425] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:29,468] {logging_mixin.py:103} INFO - [2021-01-13 00:04:29,463] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:29,473] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:30,035] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.627 seconds
[2021-01-13 00:04:30,110] {scheduler_job.py:181} INFO - Started process (PID=370) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:30,114] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:30,118] {logging_mixin.py:103} INFO - [2021-01-13 00:04:30,117] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:30,146] {logging_mixin.py:103} INFO - [2021-01-13 00:04:30,144] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:30,151] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:30,790] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.691 seconds
[2021-01-13 00:04:30,845] {scheduler_job.py:181} INFO - Started process (PID=371) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:30,860] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:30,862] {logging_mixin.py:103} INFO - [2021-01-13 00:04:30,862] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:30,899] {logging_mixin.py:103} INFO - [2021-01-13 00:04:30,896] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:30,909] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:31,491] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.651 seconds
[2021-01-13 00:04:31,534] {scheduler_job.py:181} INFO - Started process (PID=372) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:31,538] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:31,541] {logging_mixin.py:103} INFO - [2021-01-13 00:04:31,540] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:31,586] {logging_mixin.py:103} INFO - [2021-01-13 00:04:31,583] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:31,590] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:32,135] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.605 seconds
[2021-01-13 00:04:32,199] {scheduler_job.py:181} INFO - Started process (PID=373) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:32,206] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:32,211] {logging_mixin.py:103} INFO - [2021-01-13 00:04:32,211] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:32,248] {logging_mixin.py:103} INFO - [2021-01-13 00:04:32,245] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:32,256] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:32,891] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.698 seconds
[2021-01-13 00:04:32,984] {scheduler_job.py:181} INFO - Started process (PID=374) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:32,995] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:32,998] {logging_mixin.py:103} INFO - [2021-01-13 00:04:32,998] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:33,038] {logging_mixin.py:103} INFO - [2021-01-13 00:04:33,034] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:33,045] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:33,652] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.676 seconds
[2021-01-13 00:04:33,737] {scheduler_job.py:181} INFO - Started process (PID=375) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:33,741] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:33,746] {logging_mixin.py:103} INFO - [2021-01-13 00:04:33,745] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:33,778] {logging_mixin.py:103} INFO - [2021-01-13 00:04:33,775] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:33,783] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:34,337] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.610 seconds
[2021-01-13 00:04:34,384] {scheduler_job.py:181} INFO - Started process (PID=376) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:34,387] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:34,391] {logging_mixin.py:103} INFO - [2021-01-13 00:04:34,390] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:34,436] {logging_mixin.py:103} INFO - [2021-01-13 00:04:34,432] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:34,440] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:35,140] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.762 seconds
[2021-01-13 00:04:35,210] {scheduler_job.py:181} INFO - Started process (PID=377) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:35,215] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:35,218] {logging_mixin.py:103} INFO - [2021-01-13 00:04:35,218] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:35,258] {logging_mixin.py:103} INFO - [2021-01-13 00:04:35,251] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:35,266] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:36,002] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.803 seconds
[2021-01-13 00:04:36,318] {scheduler_job.py:181} INFO - Started process (PID=378) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:36,323] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:36,330] {logging_mixin.py:103} INFO - [2021-01-13 00:04:36,328] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:36,804] {logging_mixin.py:103} INFO - [2021-01-13 00:04:36,798] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:36,976] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:37,589] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.287 seconds
[2021-01-13 00:04:37,663] {scheduler_job.py:181} INFO - Started process (PID=379) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:37,669] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:37,673] {logging_mixin.py:103} INFO - [2021-01-13 00:04:37,673] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:37,733] {logging_mixin.py:103} INFO - [2021-01-13 00:04:37,729] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:37,739] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:38,278] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.628 seconds
[2021-01-13 00:04:38,327] {scheduler_job.py:181} INFO - Started process (PID=380) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:38,330] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:38,334] {logging_mixin.py:103} INFO - [2021-01-13 00:04:38,333] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:38,369] {logging_mixin.py:103} INFO - [2021-01-13 00:04:38,365] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:38,384] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:38,929] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.611 seconds
[2021-01-13 00:04:38,995] {scheduler_job.py:181} INFO - Started process (PID=381) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:39,000] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:39,003] {logging_mixin.py:103} INFO - [2021-01-13 00:04:39,002] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:39,039] {logging_mixin.py:103} INFO - [2021-01-13 00:04:39,033] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:39,044] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:39,638] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.653 seconds
[2021-01-13 00:04:39,707] {scheduler_job.py:181} INFO - Started process (PID=382) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:39,711] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:39,714] {logging_mixin.py:103} INFO - [2021-01-13 00:04:39,714] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:39,755] {logging_mixin.py:103} INFO - [2021-01-13 00:04:39,750] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:39,763] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:40,501] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.799 seconds
[2021-01-13 00:04:40,545] {scheduler_job.py:181} INFO - Started process (PID=383) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:40,551] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:40,553] {logging_mixin.py:103} INFO - [2021-01-13 00:04:40,553] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:40,590] {logging_mixin.py:103} INFO - [2021-01-13 00:04:40,585] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:40,594] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:41,210] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.671 seconds
[2021-01-13 00:04:41,266] {scheduler_job.py:181} INFO - Started process (PID=384) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:41,269] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:41,272] {logging_mixin.py:103} INFO - [2021-01-13 00:04:41,272] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:41,307] {logging_mixin.py:103} INFO - [2021-01-13 00:04:41,299] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:41,311] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:41,851] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.592 seconds
[2021-01-13 00:04:41,917] {scheduler_job.py:181} INFO - Started process (PID=385) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:41,921] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:41,928] {logging_mixin.py:103} INFO - [2021-01-13 00:04:41,928] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:41,975] {logging_mixin.py:103} INFO - [2021-01-13 00:04:41,968] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:41,980] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:42,620] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.715 seconds
[2021-01-13 00:04:42,727] {scheduler_job.py:181} INFO - Started process (PID=386) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:42,731] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:42,737] {logging_mixin.py:103} INFO - [2021-01-13 00:04:42,737] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:42,780] {logging_mixin.py:103} INFO - [2021-01-13 00:04:42,776] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:42,790] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:43,355] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.684 seconds
[2021-01-13 00:04:43,412] {scheduler_job.py:181} INFO - Started process (PID=387) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:43,421] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:43,425] {logging_mixin.py:103} INFO - [2021-01-13 00:04:43,424] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:43,469] {logging_mixin.py:103} INFO - [2021-01-13 00:04:43,462] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:43,475] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:44,074] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.669 seconds
[2021-01-13 00:04:44,147] {scheduler_job.py:181} INFO - Started process (PID=388) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:44,152] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:44,155] {logging_mixin.py:103} INFO - [2021-01-13 00:04:44,155] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:44,196] {logging_mixin.py:103} INFO - [2021-01-13 00:04:44,188] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:44,205] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:44,846] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.707 seconds
[2021-01-13 00:04:44,956] {scheduler_job.py:181} INFO - Started process (PID=389) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:44,962] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:44,973] {logging_mixin.py:103} INFO - [2021-01-13 00:04:44,971] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:45,046] {logging_mixin.py:103} INFO - [2021-01-13 00:04:45,043] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:45,057] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:45,804] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.889 seconds
[2021-01-13 00:04:45,872] {scheduler_job.py:181} INFO - Started process (PID=390) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:45,875] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:45,878] {logging_mixin.py:103} INFO - [2021-01-13 00:04:45,877] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:45,921] {logging_mixin.py:103} INFO - [2021-01-13 00:04:45,912] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:45,927] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:46,582] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.748 seconds
[2021-01-13 00:04:46,769] {scheduler_job.py:181} INFO - Started process (PID=391) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:46,775] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:46,785] {logging_mixin.py:103} INFO - [2021-01-13 00:04:46,783] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:46,932] {logging_mixin.py:103} INFO - [2021-01-13 00:04:46,893] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:47,012] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:47,610] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.888 seconds
[2021-01-13 00:04:47,693] {scheduler_job.py:181} INFO - Started process (PID=392) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:47,698] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:47,702] {logging_mixin.py:103} INFO - [2021-01-13 00:04:47,702] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:47,746] {logging_mixin.py:103} INFO - [2021-01-13 00:04:47,742] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:47,750] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:48,343] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.665 seconds
[2021-01-13 00:04:48,402] {scheduler_job.py:181} INFO - Started process (PID=393) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:48,410] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:48,412] {logging_mixin.py:103} INFO - [2021-01-13 00:04:48,412] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:48,451] {logging_mixin.py:103} INFO - [2021-01-13 00:04:48,448] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:48,457] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:49,035] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.640 seconds
[2021-01-13 00:04:49,102] {scheduler_job.py:181} INFO - Started process (PID=394) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:49,110] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:49,113] {logging_mixin.py:103} INFO - [2021-01-13 00:04:49,113] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:49,148] {logging_mixin.py:103} INFO - [2021-01-13 00:04:49,144] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:49,153] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:49,858] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.764 seconds
[2021-01-13 00:04:49,931] {scheduler_job.py:181} INFO - Started process (PID=395) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:49,935] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:49,954] {logging_mixin.py:103} INFO - [2021-01-13 00:04:49,954] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:50,033] {logging_mixin.py:103} INFO - [2021-01-13 00:04:50,021] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:50,068] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:50,644] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.725 seconds
[2021-01-13 00:04:50,688] {scheduler_job.py:181} INFO - Started process (PID=396) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:50,691] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:50,694] {logging_mixin.py:103} INFO - [2021-01-13 00:04:50,693] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:50,718] {logging_mixin.py:103} INFO - [2021-01-13 00:04:50,715] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:50,722] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:51,435] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.754 seconds
[2021-01-13 00:04:51,512] {scheduler_job.py:181} INFO - Started process (PID=397) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:51,522] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:51,529] {logging_mixin.py:103} INFO - [2021-01-13 00:04:51,528] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:51,575] {logging_mixin.py:103} INFO - [2021-01-13 00:04:51,570] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:51,583] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:52,282] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.781 seconds
[2021-01-13 00:04:52,441] {scheduler_job.py:181} INFO - Started process (PID=398) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:52,453] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:52,458] {logging_mixin.py:103} INFO - [2021-01-13 00:04:52,457] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:52,504] {logging_mixin.py:103} INFO - [2021-01-13 00:04:52,498] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:52,511] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:53,166] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.740 seconds
[2021-01-13 00:04:53,227] {scheduler_job.py:181} INFO - Started process (PID=399) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:53,232] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:53,238] {logging_mixin.py:103} INFO - [2021-01-13 00:04:53,238] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:53,284] {logging_mixin.py:103} INFO - [2021-01-13 00:04:53,276] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:53,289] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:53,978] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.757 seconds
[2021-01-13 00:04:54,056] {scheduler_job.py:181} INFO - Started process (PID=400) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:54,060] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:54,064] {logging_mixin.py:103} INFO - [2021-01-13 00:04:54,064] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:54,122] {logging_mixin.py:103} INFO - [2021-01-13 00:04:54,114] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:54,131] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:54,751] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.690 seconds
[2021-01-13 00:04:54,797] {scheduler_job.py:181} INFO - Started process (PID=401) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:54,800] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:54,803] {logging_mixin.py:103} INFO - [2021-01-13 00:04:54,803] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:54,854] {logging_mixin.py:103} INFO - [2021-01-13 00:04:54,846] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:54,872] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:55,424] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.633 seconds
[2021-01-13 00:04:55,463] {scheduler_job.py:181} INFO - Started process (PID=402) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:55,466] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:55,469] {logging_mixin.py:103} INFO - [2021-01-13 00:04:55,468] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:55,504] {logging_mixin.py:103} INFO - [2021-01-13 00:04:55,500] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:55,510] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:56,423] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.965 seconds
[2021-01-13 00:04:56,614] {scheduler_job.py:181} INFO - Started process (PID=403) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:56,623] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:56,628] {logging_mixin.py:103} INFO - [2021-01-13 00:04:56,627] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:56,685] {logging_mixin.py:103} INFO - [2021-01-13 00:04:56,679] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:56,692] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:57,338] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.730 seconds
[2021-01-13 00:04:57,400] {scheduler_job.py:181} INFO - Started process (PID=404) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:57,409] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:57,415] {logging_mixin.py:103} INFO - [2021-01-13 00:04:57,414] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:57,465] {logging_mixin.py:103} INFO - [2021-01-13 00:04:57,458] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:57,474] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:58,120] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.730 seconds
[2021-01-13 00:04:58,188] {scheduler_job.py:181} INFO - Started process (PID=405) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:58,196] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:58,201] {logging_mixin.py:103} INFO - [2021-01-13 00:04:58,200] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:58,283] {logging_mixin.py:103} INFO - [2021-01-13 00:04:58,278] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:58,289] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:58,914] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.738 seconds
[2021-01-13 00:04:58,960] {scheduler_job.py:181} INFO - Started process (PID=406) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:58,965] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:58,970] {logging_mixin.py:103} INFO - [2021-01-13 00:04:58,969] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:59,007] {logging_mixin.py:103} INFO - [2021-01-13 00:04:59,003] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:59,014] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:04:59,558] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.610 seconds
[2021-01-13 00:04:59,605] {scheduler_job.py:181} INFO - Started process (PID=407) to work on /opt/airflow/dags/example.py
[2021-01-13 00:04:59,608] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:04:59,610] {logging_mixin.py:103} INFO - [2021-01-13 00:04:59,610] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:04:59,635] {logging_mixin.py:103} INFO - [2021-01-13 00:04:59,633] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:04:59,639] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:00,333] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.734 seconds
[2021-01-13 00:05:00,376] {scheduler_job.py:181} INFO - Started process (PID=408) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:00,379] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:00,382] {logging_mixin.py:103} INFO - [2021-01-13 00:05:00,382] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:00,407] {logging_mixin.py:103} INFO - [2021-01-13 00:05:00,405] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:00,411] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:01,009] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.638 seconds
[2021-01-13 00:05:01,082] {scheduler_job.py:181} INFO - Started process (PID=409) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:01,086] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:01,089] {logging_mixin.py:103} INFO - [2021-01-13 00:05:01,089] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:01,118] {logging_mixin.py:103} INFO - [2021-01-13 00:05:01,115] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:01,123] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:01,738] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.666 seconds
[2021-01-13 00:05:01,800] {scheduler_job.py:181} INFO - Started process (PID=410) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:01,805] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:01,809] {logging_mixin.py:103} INFO - [2021-01-13 00:05:01,809] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:01,905] {logging_mixin.py:103} INFO - [2021-01-13 00:05:01,900] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:01,921] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:02,563] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.774 seconds
[2021-01-13 00:05:02,818] {scheduler_job.py:181} INFO - Started process (PID=411) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:02,821] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:02,838] {logging_mixin.py:103} INFO - [2021-01-13 00:05:02,836] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:02,922] {logging_mixin.py:103} INFO - [2021-01-13 00:05:02,917] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:02,939] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:03,539] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.765 seconds
[2021-01-13 00:05:03,581] {scheduler_job.py:181} INFO - Started process (PID=412) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:03,585] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:03,587] {logging_mixin.py:103} INFO - [2021-01-13 00:05:03,587] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:03,612] {logging_mixin.py:103} INFO - [2021-01-13 00:05:03,608] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:03,616] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:04,282] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.707 seconds
[2021-01-13 00:05:04,329] {scheduler_job.py:181} INFO - Started process (PID=413) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:04,334] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:04,337] {logging_mixin.py:103} INFO - [2021-01-13 00:05:04,337] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:04,372] {logging_mixin.py:103} INFO - [2021-01-13 00:05:04,369] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:04,377] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:05,141] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.818 seconds
[2021-01-13 00:05:05,197] {scheduler_job.py:181} INFO - Started process (PID=414) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:05,200] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:05,205] {logging_mixin.py:103} INFO - [2021-01-13 00:05:05,205] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:05,244] {logging_mixin.py:103} INFO - [2021-01-13 00:05:05,240] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:05,248] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:05,830] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.639 seconds
[2021-01-13 00:05:05,872] {scheduler_job.py:181} INFO - Started process (PID=415) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:05,879] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:05,882] {logging_mixin.py:103} INFO - [2021-01-13 00:05:05,881] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:05,917] {logging_mixin.py:103} INFO - [2021-01-13 00:05:05,913] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:05,935] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:06,519] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.655 seconds
[2021-01-13 00:05:06,738] {scheduler_job.py:181} INFO - Started process (PID=416) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:06,742] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:06,748] {logging_mixin.py:103} INFO - [2021-01-13 00:05:06,747] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:06,779] {logging_mixin.py:103} INFO - [2021-01-13 00:05:06,774] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:06,785] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:07,436] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.705 seconds
[2021-01-13 00:05:07,492] {scheduler_job.py:181} INFO - Started process (PID=417) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:07,497] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:07,499] {logging_mixin.py:103} INFO - [2021-01-13 00:05:07,499] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:07,531] {logging_mixin.py:103} INFO - [2021-01-13 00:05:07,527] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:07,538] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:08,152] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.662 seconds
[2021-01-13 00:05:08,208] {scheduler_job.py:181} INFO - Started process (PID=418) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:08,213] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:08,216] {logging_mixin.py:103} INFO - [2021-01-13 00:05:08,215] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:08,251] {logging_mixin.py:103} INFO - [2021-01-13 00:05:08,247] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:08,256] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:08,889] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.689 seconds
[2021-01-13 00:05:09,001] {scheduler_job.py:181} INFO - Started process (PID=419) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:09,013] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:09,020] {logging_mixin.py:103} INFO - [2021-01-13 00:05:09,019] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:09,063] {logging_mixin.py:103} INFO - [2021-01-13 00:05:09,056] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:09,076] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:09,583] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.592 seconds
[2021-01-13 00:05:09,649] {scheduler_job.py:181} INFO - Started process (PID=420) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:09,653] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:09,656] {logging_mixin.py:103} INFO - [2021-01-13 00:05:09,656] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:09,701] {logging_mixin.py:103} INFO - [2021-01-13 00:05:09,697] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:09,707] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:10,234] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.597 seconds
[2021-01-13 00:05:10,435] {scheduler_job.py:181} INFO - Started process (PID=421) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:10,456] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:10,460] {logging_mixin.py:103} INFO - [2021-01-13 00:05:10,459] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:10,549] {logging_mixin.py:103} INFO - [2021-01-13 00:05:10,545] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:10,555] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:11,149] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.730 seconds
[2021-01-13 00:05:11,227] {scheduler_job.py:181} INFO - Started process (PID=422) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:11,233] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:11,236] {logging_mixin.py:103} INFO - [2021-01-13 00:05:11,235] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:11,308] {logging_mixin.py:103} INFO - [2021-01-13 00:05:11,296] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:11,326] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:11,958] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.742 seconds
[2021-01-13 00:05:12,047] {scheduler_job.py:181} INFO - Started process (PID=423) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:12,053] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:12,058] {logging_mixin.py:103} INFO - [2021-01-13 00:05:12,058] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:12,110] {logging_mixin.py:103} INFO - [2021-01-13 00:05:12,101] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:12,122] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:12,782] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.741 seconds
[2021-01-13 00:05:12,946] {scheduler_job.py:181} INFO - Started process (PID=424) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:12,954] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:12,963] {logging_mixin.py:103} INFO - [2021-01-13 00:05:12,963] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:13,111] {logging_mixin.py:103} INFO - [2021-01-13 00:05:13,097] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:13,117] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:13,757] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.844 seconds
[2021-01-13 00:05:13,834] {scheduler_job.py:181} INFO - Started process (PID=425) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:13,840] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:13,843] {logging_mixin.py:103} INFO - [2021-01-13 00:05:13,843] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:13,979] {logging_mixin.py:103} INFO - [2021-01-13 00:05:13,974] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:13,985] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:14,632] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.809 seconds
[2021-01-13 00:05:14,843] {scheduler_job.py:181} INFO - Started process (PID=426) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:14,855] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:14,861] {logging_mixin.py:103} INFO - [2021-01-13 00:05:14,861] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:14,919] {logging_mixin.py:103} INFO - [2021-01-13 00:05:14,904] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:14,936] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:15,710] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.877 seconds
[2021-01-13 00:05:15,771] {scheduler_job.py:181} INFO - Started process (PID=427) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:15,776] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:15,783] {logging_mixin.py:103} INFO - [2021-01-13 00:05:15,782] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:15,832] {logging_mixin.py:103} INFO - [2021-01-13 00:05:15,828] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:15,844] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:16,409] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.679 seconds
[2021-01-13 00:05:16,460] {scheduler_job.py:181} INFO - Started process (PID=428) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:16,469] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:16,477] {logging_mixin.py:103} INFO - [2021-01-13 00:05:16,476] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:16,522] {logging_mixin.py:103} INFO - [2021-01-13 00:05:16,518] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:16,529] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:17,133] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.684 seconds
[2021-01-13 00:05:17,306] {scheduler_job.py:181} INFO - Started process (PID=429) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:17,318] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:17,321] {logging_mixin.py:103} INFO - [2021-01-13 00:05:17,321] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:17,350] {logging_mixin.py:103} INFO - [2021-01-13 00:05:17,347] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:17,355] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:17,896] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.607 seconds
[2021-01-13 00:05:17,943] {scheduler_job.py:181} INFO - Started process (PID=430) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:17,949] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:17,952] {logging_mixin.py:103} INFO - [2021-01-13 00:05:17,952] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:17,992] {logging_mixin.py:103} INFO - [2021-01-13 00:05:17,988] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:17,996] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:18,811] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.877 seconds
[2021-01-13 00:05:18,865] {scheduler_job.py:181} INFO - Started process (PID=431) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:18,871] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:18,876] {logging_mixin.py:103} INFO - [2021-01-13 00:05:18,875] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:18,903] {logging_mixin.py:103} INFO - [2021-01-13 00:05:18,901] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:18,909] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:19,524] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.666 seconds
[2021-01-13 00:05:19,572] {scheduler_job.py:181} INFO - Started process (PID=432) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:19,577] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:19,579] {logging_mixin.py:103} INFO - [2021-01-13 00:05:19,579] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:19,603] {logging_mixin.py:103} INFO - [2021-01-13 00:05:19,599] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:19,616] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:20,184] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.619 seconds
[2021-01-13 00:05:20,234] {scheduler_job.py:181} INFO - Started process (PID=433) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:20,238] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:20,241] {logging_mixin.py:103} INFO - [2021-01-13 00:05:20,241] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:20,287] {logging_mixin.py:103} INFO - [2021-01-13 00:05:20,284] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:20,292] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:21,121] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.893 seconds
[2021-01-13 00:05:21,178] {scheduler_job.py:181} INFO - Started process (PID=434) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:21,185] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:21,189] {logging_mixin.py:103} INFO - [2021-01-13 00:05:21,189] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:21,227] {logging_mixin.py:103} INFO - [2021-01-13 00:05:21,224] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:21,436] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:22,034] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.862 seconds
[2021-01-13 00:05:22,132] {scheduler_job.py:181} INFO - Started process (PID=435) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:22,138] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:22,141] {logging_mixin.py:103} INFO - [2021-01-13 00:05:22,140] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:22,190] {logging_mixin.py:103} INFO - [2021-01-13 00:05:22,186] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:22,195] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:22,761] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.639 seconds
[2021-01-13 00:05:22,824] {scheduler_job.py:181} INFO - Started process (PID=436) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:22,830] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:22,834] {logging_mixin.py:103} INFO - [2021-01-13 00:05:22,834] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:22,940] {logging_mixin.py:103} INFO - [2021-01-13 00:05:22,929] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:22,963] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:23,669] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.854 seconds
[2021-01-13 00:05:23,736] {scheduler_job.py:181} INFO - Started process (PID=437) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:23,742] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:23,746] {logging_mixin.py:103} INFO - [2021-01-13 00:05:23,745] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:23,793] {logging_mixin.py:103} INFO - [2021-01-13 00:05:23,788] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:23,803] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:24,390] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.663 seconds
[2021-01-13 00:05:24,440] {scheduler_job.py:181} INFO - Started process (PID=438) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:24,444] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:24,446] {logging_mixin.py:103} INFO - [2021-01-13 00:05:24,446] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:24,478] {logging_mixin.py:103} INFO - [2021-01-13 00:05:24,475] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:24,486] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:25,053] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.621 seconds
[2021-01-13 00:05:25,122] {scheduler_job.py:181} INFO - Started process (PID=439) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:25,131] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:25,135] {logging_mixin.py:103} INFO - [2021-01-13 00:05:25,134] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:25,214] {logging_mixin.py:103} INFO - [2021-01-13 00:05:25,208] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:25,224] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:25,800] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.689 seconds
[2021-01-13 00:05:25,855] {scheduler_job.py:181} INFO - Started process (PID=440) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:25,861] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:25,863] {logging_mixin.py:103} INFO - [2021-01-13 00:05:25,863] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:25,945] {logging_mixin.py:103} INFO - [2021-01-13 00:05:25,942] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:25,957] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:26,480] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.633 seconds
[2021-01-13 00:05:26,577] {scheduler_job.py:181} INFO - Started process (PID=441) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:26,583] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:26,589] {logging_mixin.py:103} INFO - [2021-01-13 00:05:26,589] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:26,630] {logging_mixin.py:103} INFO - [2021-01-13 00:05:26,626] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:26,634] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:27,256] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.689 seconds
[2021-01-13 00:05:27,459] {scheduler_job.py:181} INFO - Started process (PID=442) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:27,469] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:27,475] {logging_mixin.py:103} INFO - [2021-01-13 00:05:27,475] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:27,506] {logging_mixin.py:103} INFO - [2021-01-13 00:05:27,500] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:27,513] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:28,166] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.722 seconds
[2021-01-13 00:05:28,227] {scheduler_job.py:181} INFO - Started process (PID=443) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:28,230] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:28,234] {logging_mixin.py:103} INFO - [2021-01-13 00:05:28,233] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:28,273] {logging_mixin.py:103} INFO - [2021-01-13 00:05:28,266] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:28,277] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:28,779] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.561 seconds
[2021-01-13 00:05:28,816] {scheduler_job.py:181} INFO - Started process (PID=444) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:28,820] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:28,824] {logging_mixin.py:103} INFO - [2021-01-13 00:05:28,824] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:28,851] {logging_mixin.py:103} INFO - [2021-01-13 00:05:28,846] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:28,875] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:29,472] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.660 seconds
[2021-01-13 00:05:29,529] {scheduler_job.py:181} INFO - Started process (PID=445) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:29,532] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:29,534] {logging_mixin.py:103} INFO - [2021-01-13 00:05:29,534] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:29,564] {logging_mixin.py:103} INFO - [2021-01-13 00:05:29,561] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:29,567] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:30,216] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.695 seconds
[2021-01-13 00:05:30,277] {scheduler_job.py:181} INFO - Started process (PID=446) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:30,282] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:30,285] {logging_mixin.py:103} INFO - [2021-01-13 00:05:30,284] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:30,326] {logging_mixin.py:103} INFO - [2021-01-13 00:05:30,322] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:30,332] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:30,887] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.621 seconds
[2021-01-13 00:05:31,032] {scheduler_job.py:181} INFO - Started process (PID=447) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:31,037] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:31,040] {logging_mixin.py:103} INFO - [2021-01-13 00:05:31,040] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:31,078] {logging_mixin.py:103} INFO - [2021-01-13 00:05:31,075] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:31,082] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:31,668] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.649 seconds
[2021-01-13 00:05:31,713] {scheduler_job.py:181} INFO - Started process (PID=448) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:31,716] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:31,719] {logging_mixin.py:103} INFO - [2021-01-13 00:05:31,718] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:31,887] {logging_mixin.py:103} INFO - [2021-01-13 00:05:31,764] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:31,909] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:32,582] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.878 seconds
[2021-01-13 00:05:32,654] {scheduler_job.py:181} INFO - Started process (PID=449) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:32,660] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:32,664] {logging_mixin.py:103} INFO - [2021-01-13 00:05:32,664] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:32,750] {logging_mixin.py:103} INFO - [2021-01-13 00:05:32,742] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:32,762] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:33,278] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.641 seconds
[2021-01-13 00:05:33,342] {scheduler_job.py:181} INFO - Started process (PID=450) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:33,353] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:33,357] {logging_mixin.py:103} INFO - [2021-01-13 00:05:33,357] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:33,401] {logging_mixin.py:103} INFO - [2021-01-13 00:05:33,398] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:33,404] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:33,983] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.648 seconds
[2021-01-13 00:05:34,065] {scheduler_job.py:181} INFO - Started process (PID=451) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:34,069] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:34,074] {logging_mixin.py:103} INFO - [2021-01-13 00:05:34,074] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:34,104] {logging_mixin.py:103} INFO - [2021-01-13 00:05:34,101] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:34,110] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:34,792] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.733 seconds
[2021-01-13 00:05:34,850] {scheduler_job.py:181} INFO - Started process (PID=452) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:34,854] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:34,858] {logging_mixin.py:103} INFO - [2021-01-13 00:05:34,858] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:34,904] {logging_mixin.py:103} INFO - [2021-01-13 00:05:34,900] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:34,909] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:35,616] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.777 seconds
[2021-01-13 00:05:35,668] {scheduler_job.py:181} INFO - Started process (PID=453) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:35,671] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:35,674] {logging_mixin.py:103} INFO - [2021-01-13 00:05:35,674] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:35,723] {logging_mixin.py:103} INFO - [2021-01-13 00:05:35,717] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:35,731] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:36,263] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.604 seconds
[2021-01-13 00:05:36,309] {scheduler_job.py:181} INFO - Started process (PID=454) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:36,312] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:36,315] {logging_mixin.py:103} INFO - [2021-01-13 00:05:36,314] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:36,342] {logging_mixin.py:103} INFO - [2021-01-13 00:05:36,339] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:36,347] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:37,058] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.755 seconds
[2021-01-13 00:05:37,112] {scheduler_job.py:181} INFO - Started process (PID=455) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:37,117] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:37,119] {logging_mixin.py:103} INFO - [2021-01-13 00:05:37,119] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:37,160] {logging_mixin.py:103} INFO - [2021-01-13 00:05:37,156] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:37,167] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:37,644] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.541 seconds
[2021-01-13 00:05:38,126] {scheduler_job.py:181} INFO - Started process (PID=456) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:38,130] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:38,132] {logging_mixin.py:103} INFO - [2021-01-13 00:05:38,132] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:38,163] {logging_mixin.py:103} INFO - [2021-01-13 00:05:38,160] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:38,168] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:38,716] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.595 seconds
[2021-01-13 00:05:38,776] {scheduler_job.py:181} INFO - Started process (PID=457) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:38,779] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:38,782] {logging_mixin.py:103} INFO - [2021-01-13 00:05:38,781] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:38,812] {logging_mixin.py:103} INFO - [2021-01-13 00:05:38,806] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:38,817] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:39,331] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.562 seconds
[2021-01-13 00:05:39,383] {scheduler_job.py:181} INFO - Started process (PID=458) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:39,387] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:39,389] {logging_mixin.py:103} INFO - [2021-01-13 00:05:39,389] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:39,415] {logging_mixin.py:103} INFO - [2021-01-13 00:05:39,413] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:39,421] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:39,908] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.533 seconds
[2021-01-13 00:05:39,964] {scheduler_job.py:181} INFO - Started process (PID=459) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:39,968] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:39,970] {logging_mixin.py:103} INFO - [2021-01-13 00:05:39,970] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:40,004] {logging_mixin.py:103} INFO - [2021-01-13 00:05:39,998] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:40,022] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:40,554] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.594 seconds
[2021-01-13 00:05:40,609] {scheduler_job.py:181} INFO - Started process (PID=460) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:40,612] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:40,614] {logging_mixin.py:103} INFO - [2021-01-13 00:05:40,614] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:40,642] {logging_mixin.py:103} INFO - [2021-01-13 00:05:40,639] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:40,646] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:41,239] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.635 seconds
[2021-01-13 00:05:41,302] {scheduler_job.py:181} INFO - Started process (PID=461) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:41,307] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:41,310] {logging_mixin.py:103} INFO - [2021-01-13 00:05:41,309] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:41,351] {logging_mixin.py:103} INFO - [2021-01-13 00:05:41,347] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:41,356] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:41,880] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.590 seconds
[2021-01-13 00:05:41,963] {scheduler_job.py:181} INFO - Started process (PID=462) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:41,968] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:41,970] {logging_mixin.py:103} INFO - [2021-01-13 00:05:41,970] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:42,011] {logging_mixin.py:103} INFO - [2021-01-13 00:05:42,009] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:42,018] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:42,560] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.603 seconds
[2021-01-13 00:05:42,612] {scheduler_job.py:181} INFO - Started process (PID=463) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:42,615] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:42,618] {logging_mixin.py:103} INFO - [2021-01-13 00:05:42,617] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:42,650] {logging_mixin.py:103} INFO - [2021-01-13 00:05:42,645] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:42,654] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:43,189] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.583 seconds
[2021-01-13 00:05:43,239] {scheduler_job.py:181} INFO - Started process (PID=464) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:43,243] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:43,245] {logging_mixin.py:103} INFO - [2021-01-13 00:05:43,244] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:43,269] {logging_mixin.py:103} INFO - [2021-01-13 00:05:43,266] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:43,274] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:43,872] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.637 seconds
[2021-01-13 00:05:43,946] {scheduler_job.py:181} INFO - Started process (PID=465) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:43,955] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:43,962] {logging_mixin.py:103} INFO - [2021-01-13 00:05:43,961] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:44,010] {logging_mixin.py:103} INFO - [2021-01-13 00:05:44,005] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:44,022] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:44,573] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.658 seconds
[2021-01-13 00:05:44,620] {scheduler_job.py:181} INFO - Started process (PID=466) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:44,624] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:44,628] {logging_mixin.py:103} INFO - [2021-01-13 00:05:44,628] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:44,660] {logging_mixin.py:103} INFO - [2021-01-13 00:05:44,654] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:44,663] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:45,237] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.623 seconds
[2021-01-13 00:05:45,294] {scheduler_job.py:181} INFO - Started process (PID=467) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:45,301] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:45,307] {logging_mixin.py:103} INFO - [2021-01-13 00:05:45,306] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:45,351] {logging_mixin.py:103} INFO - [2021-01-13 00:05:45,345] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:45,359] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:46,002] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.720 seconds
[2021-01-13 00:05:46,107] {scheduler_job.py:181} INFO - Started process (PID=468) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:46,135] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:46,140] {logging_mixin.py:103} INFO - [2021-01-13 00:05:46,140] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:46,188] {logging_mixin.py:103} INFO - [2021-01-13 00:05:46,181] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:46,195] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:46,803] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.749 seconds
[2021-01-13 00:05:46,856] {scheduler_job.py:181} INFO - Started process (PID=469) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:46,862] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:46,868] {logging_mixin.py:103} INFO - [2021-01-13 00:05:46,867] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:46,898] {logging_mixin.py:103} INFO - [2021-01-13 00:05:46,891] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:46,906] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:47,488] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.643 seconds
[2021-01-13 00:05:47,538] {scheduler_job.py:181} INFO - Started process (PID=470) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:47,544] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:47,547] {logging_mixin.py:103} INFO - [2021-01-13 00:05:47,547] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:47,585] {logging_mixin.py:103} INFO - [2021-01-13 00:05:47,579] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:47,591] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:48,309] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.775 seconds
[2021-01-13 00:05:48,550] {scheduler_job.py:181} INFO - Started process (PID=471) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:48,554] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:48,557] {logging_mixin.py:103} INFO - [2021-01-13 00:05:48,556] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:48,606] {logging_mixin.py:103} INFO - [2021-01-13 00:05:48,603] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:48,612] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:49,326] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.787 seconds
[2021-01-13 00:05:49,381] {scheduler_job.py:181} INFO - Started process (PID=472) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:49,386] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:49,392] {logging_mixin.py:103} INFO - [2021-01-13 00:05:49,391] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:49,433] {logging_mixin.py:103} INFO - [2021-01-13 00:05:49,428] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:49,438] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:50,147] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.779 seconds
[2021-01-13 00:05:50,212] {scheduler_job.py:181} INFO - Started process (PID=473) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:50,218] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:50,223] {logging_mixin.py:103} INFO - [2021-01-13 00:05:50,222] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:50,269] {logging_mixin.py:103} INFO - [2021-01-13 00:05:50,263] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:50,275] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:51,011] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.811 seconds
[2021-01-13 00:05:51,097] {scheduler_job.py:181} INFO - Started process (PID=474) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:51,103] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:51,108] {logging_mixin.py:103} INFO - [2021-01-13 00:05:51,107] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:51,154] {logging_mixin.py:103} INFO - [2021-01-13 00:05:51,150] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:51,161] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:52,058] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.972 seconds
[2021-01-13 00:05:52,433] {scheduler_job.py:181} INFO - Started process (PID=475) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:52,438] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:52,441] {logging_mixin.py:103} INFO - [2021-01-13 00:05:52,441] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:52,541] {logging_mixin.py:103} INFO - [2021-01-13 00:05:52,528] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:52,594] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:53,160] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.740 seconds
[2021-01-13 00:05:53,216] {scheduler_job.py:181} INFO - Started process (PID=476) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:53,220] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:53,226] {logging_mixin.py:103} INFO - [2021-01-13 00:05:53,225] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:53,283] {logging_mixin.py:103} INFO - [2021-01-13 00:05:53,270] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:53,292] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:53,893] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.690 seconds
[2021-01-13 00:05:53,997] {scheduler_job.py:181} INFO - Started process (PID=477) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:54,013] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:54,028] {logging_mixin.py:103} INFO - [2021-01-13 00:05:54,027] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:54,096] {logging_mixin.py:103} INFO - [2021-01-13 00:05:54,092] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:54,107] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:54,784] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.808 seconds
[2021-01-13 00:05:54,830] {scheduler_job.py:181} INFO - Started process (PID=478) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:54,839] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:54,841] {logging_mixin.py:103} INFO - [2021-01-13 00:05:54,841] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:54,889] {logging_mixin.py:103} INFO - [2021-01-13 00:05:54,885] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:54,898] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:55,508] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.686 seconds
[2021-01-13 00:05:55,567] {scheduler_job.py:181} INFO - Started process (PID=479) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:55,570] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:55,573] {logging_mixin.py:103} INFO - [2021-01-13 00:05:55,573] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:55,604] {logging_mixin.py:103} INFO - [2021-01-13 00:05:55,600] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:55,608] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:56,200] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.644 seconds
[2021-01-13 00:05:56,258] {scheduler_job.py:181} INFO - Started process (PID=480) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:56,263] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:56,266] {logging_mixin.py:103} INFO - [2021-01-13 00:05:56,266] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:56,304] {logging_mixin.py:103} INFO - [2021-01-13 00:05:56,300] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:56,309] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:56,923] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.672 seconds
[2021-01-13 00:05:56,978] {scheduler_job.py:181} INFO - Started process (PID=481) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:56,986] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:56,993] {logging_mixin.py:103} INFO - [2021-01-13 00:05:56,992] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:57,036] {logging_mixin.py:103} INFO - [2021-01-13 00:05:57,032] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:57,040] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:57,591] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.627 seconds
[2021-01-13 00:05:57,635] {scheduler_job.py:181} INFO - Started process (PID=482) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:57,638] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:57,640] {logging_mixin.py:103} INFO - [2021-01-13 00:05:57,640] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:57,670] {logging_mixin.py:103} INFO - [2021-01-13 00:05:57,666] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:57,674] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:58,214] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.585 seconds
[2021-01-13 00:05:58,272] {scheduler_job.py:181} INFO - Started process (PID=483) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:58,277] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:58,280] {logging_mixin.py:103} INFO - [2021-01-13 00:05:58,280] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:58,311] {logging_mixin.py:103} INFO - [2021-01-13 00:05:58,307] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:58,320] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:58,915] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.649 seconds
[2021-01-13 00:05:58,970] {scheduler_job.py:181} INFO - Started process (PID=484) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:58,973] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:58,976] {logging_mixin.py:103} INFO - [2021-01-13 00:05:58,976] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:59,016] {logging_mixin.py:103} INFO - [2021-01-13 00:05:59,014] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:59,027] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:05:59,546] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.581 seconds
[2021-01-13 00:05:59,599] {scheduler_job.py:181} INFO - Started process (PID=485) to work on /opt/airflow/dags/example.py
[2021-01-13 00:05:59,603] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:05:59,606] {logging_mixin.py:103} INFO - [2021-01-13 00:05:59,606] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:05:59,635] {logging_mixin.py:103} INFO - [2021-01-13 00:05:59,633] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:05:59,640] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:00,438] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.845 seconds
[2021-01-13 00:06:00,504] {scheduler_job.py:181} INFO - Started process (PID=486) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:00,508] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:00,511] {logging_mixin.py:103} INFO - [2021-01-13 00:06:00,510] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:00,551] {logging_mixin.py:103} INFO - [2021-01-13 00:06:00,548] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:00,555] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:01,115] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.623 seconds
[2021-01-13 00:06:01,182] {scheduler_job.py:181} INFO - Started process (PID=487) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:01,186] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:01,189] {logging_mixin.py:103} INFO - [2021-01-13 00:06:01,188] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:01,226] {logging_mixin.py:103} INFO - [2021-01-13 00:06:01,223] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:01,231] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:01,836] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.663 seconds
[2021-01-13 00:06:01,885] {scheduler_job.py:181} INFO - Started process (PID=488) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:01,888] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:01,897] {logging_mixin.py:103} INFO - [2021-01-13 00:06:01,897] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:01,934] {logging_mixin.py:103} INFO - [2021-01-13 00:06:01,931] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:01,941] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:02,500] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.620 seconds
[2021-01-13 00:06:02,547] {scheduler_job.py:181} INFO - Started process (PID=489) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:02,550] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:02,553] {logging_mixin.py:103} INFO - [2021-01-13 00:06:02,552] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:02,577] {logging_mixin.py:103} INFO - [2021-01-13 00:06:02,573] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:02,581] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:03,219] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.678 seconds
[2021-01-13 00:06:03,322] {scheduler_job.py:181} INFO - Started process (PID=490) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:03,340] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:03,345] {logging_mixin.py:103} INFO - [2021-01-13 00:06:03,344] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:03,378] {logging_mixin.py:103} INFO - [2021-01-13 00:06:03,375] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:03,385] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:03,936] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.626 seconds
[2021-01-13 00:06:04,018] {scheduler_job.py:181} INFO - Started process (PID=491) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:04,026] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:04,029] {logging_mixin.py:103} INFO - [2021-01-13 00:06:04,029] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:04,069] {logging_mixin.py:103} INFO - [2021-01-13 00:06:04,066] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:04,073] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:04,619] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.612 seconds
[2021-01-13 00:06:04,679] {scheduler_job.py:181} INFO - Started process (PID=492) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:04,686] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:04,691] {logging_mixin.py:103} INFO - [2021-01-13 00:06:04,691] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:04,809] {logging_mixin.py:103} INFO - [2021-01-13 00:06:04,799] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:04,817] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:05,441] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.774 seconds
[2021-01-13 00:06:05,518] {scheduler_job.py:181} INFO - Started process (PID=493) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:05,521] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:05,524] {logging_mixin.py:103} INFO - [2021-01-13 00:06:05,523] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:05,554] {logging_mixin.py:103} INFO - [2021-01-13 00:06:05,547] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:05,557] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:06,109] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.597 seconds
[2021-01-13 00:06:06,162] {scheduler_job.py:181} INFO - Started process (PID=494) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:06,165] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:06,169] {logging_mixin.py:103} INFO - [2021-01-13 00:06:06,168] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:06,218] {logging_mixin.py:103} INFO - [2021-01-13 00:06:06,213] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:06,228] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:06,821] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.667 seconds
[2021-01-13 00:06:06,881] {scheduler_job.py:181} INFO - Started process (PID=495) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:06,901] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:06,919] {logging_mixin.py:103} INFO - [2021-01-13 00:06:06,918] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:06,998] {logging_mixin.py:103} INFO - [2021-01-13 00:06:06,993] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:07,011] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:07,568] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.694 seconds
[2021-01-13 00:06:07,632] {scheduler_job.py:181} INFO - Started process (PID=496) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:07,637] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:07,640] {logging_mixin.py:103} INFO - [2021-01-13 00:06:07,640] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:07,670] {logging_mixin.py:103} INFO - [2021-01-13 00:06:07,665] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:07,675] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:08,191] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.564 seconds
[2021-01-13 00:06:08,261] {scheduler_job.py:181} INFO - Started process (PID=497) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:08,265] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:08,272] {logging_mixin.py:103} INFO - [2021-01-13 00:06:08,272] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:08,314] {logging_mixin.py:103} INFO - [2021-01-13 00:06:08,308] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:08,320] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:08,933] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.678 seconds
[2021-01-13 00:06:09,131] {scheduler_job.py:181} INFO - Started process (PID=498) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:09,134] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:09,138] {logging_mixin.py:103} INFO - [2021-01-13 00:06:09,137] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:09,170] {logging_mixin.py:103} INFO - [2021-01-13 00:06:09,168] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:09,177] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:09,676] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.557 seconds
[2021-01-13 00:06:09,869] {scheduler_job.py:181} INFO - Started process (PID=499) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:09,877] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:09,882] {logging_mixin.py:103} INFO - [2021-01-13 00:06:09,881] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:09,916] {logging_mixin.py:103} INFO - [2021-01-13 00:06:09,912] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:09,919] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:10,866] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.012 seconds
[2021-01-13 00:06:11,246] {scheduler_job.py:181} INFO - Started process (PID=500) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:11,510] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:11,515] {logging_mixin.py:103} INFO - [2021-01-13 00:06:11,515] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:11,747] {logging_mixin.py:103} INFO - [2021-01-13 00:06:11,705] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:11,752] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:12,290] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.053 seconds
[2021-01-13 00:06:12,356] {scheduler_job.py:181} INFO - Started process (PID=501) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:12,361] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:12,364] {logging_mixin.py:103} INFO - [2021-01-13 00:06:12,363] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:12,410] {logging_mixin.py:103} INFO - [2021-01-13 00:06:12,406] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:12,416] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:12,956] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.611 seconds
[2021-01-13 00:06:13,021] {scheduler_job.py:181} INFO - Started process (PID=502) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:13,032] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:13,035] {logging_mixin.py:103} INFO - [2021-01-13 00:06:13,034] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:13,072] {logging_mixin.py:103} INFO - [2021-01-13 00:06:13,070] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:13,077] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:13,575] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.566 seconds
[2021-01-13 00:06:13,644] {scheduler_job.py:181} INFO - Started process (PID=503) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:13,648] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:13,651] {logging_mixin.py:103} INFO - [2021-01-13 00:06:13,651] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:13,695] {logging_mixin.py:103} INFO - [2021-01-13 00:06:13,692] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:13,706] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:14,247] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.612 seconds
[2021-01-13 00:06:14,309] {scheduler_job.py:181} INFO - Started process (PID=504) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:14,313] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:14,316] {logging_mixin.py:103} INFO - [2021-01-13 00:06:14,316] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:14,354] {logging_mixin.py:103} INFO - [2021-01-13 00:06:14,349] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:14,356] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:14,922] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.618 seconds
[2021-01-13 00:06:14,996] {scheduler_job.py:181} INFO - Started process (PID=505) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:15,000] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:15,002] {logging_mixin.py:103} INFO - [2021-01-13 00:06:15,002] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:15,048] {logging_mixin.py:103} INFO - [2021-01-13 00:06:15,042] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:15,052] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:15,624] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.639 seconds
[2021-01-13 00:06:15,676] {scheduler_job.py:181} INFO - Started process (PID=506) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:15,680] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:15,683] {logging_mixin.py:103} INFO - [2021-01-13 00:06:15,683] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:15,725] {logging_mixin.py:103} INFO - [2021-01-13 00:06:15,721] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:15,732] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:16,435] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.801 seconds
[2021-01-13 00:06:16,487] {scheduler_job.py:181} INFO - Started process (PID=507) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:16,490] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:16,493] {logging_mixin.py:103} INFO - [2021-01-13 00:06:16,492] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:16,520] {logging_mixin.py:103} INFO - [2021-01-13 00:06:16,516] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:16,524] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:17,263] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.782 seconds
[2021-01-13 00:06:17,329] {scheduler_job.py:181} INFO - Started process (PID=508) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:17,334] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:17,337] {logging_mixin.py:103} INFO - [2021-01-13 00:06:17,336] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:17,371] {logging_mixin.py:103} INFO - [2021-01-13 00:06:17,363] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:17,376] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:18,071] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.751 seconds
[2021-01-13 00:06:18,131] {scheduler_job.py:181} INFO - Started process (PID=509) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:18,136] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:18,140] {logging_mixin.py:103} INFO - [2021-01-13 00:06:18,140] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:18,188] {logging_mixin.py:103} INFO - [2021-01-13 00:06:18,184] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:18,209] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:18,745] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.624 seconds
[2021-01-13 00:06:18,810] {scheduler_job.py:181} INFO - Started process (PID=510) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:18,816] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:18,822] {logging_mixin.py:103} INFO - [2021-01-13 00:06:18,821] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:18,867] {logging_mixin.py:103} INFO - [2021-01-13 00:06:18,862] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:18,886] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:19,450] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.654 seconds
[2021-01-13 00:06:19,635] {scheduler_job.py:181} INFO - Started process (PID=511) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:19,644] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:19,647] {logging_mixin.py:103} INFO - [2021-01-13 00:06:19,647] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:19,686] {logging_mixin.py:103} INFO - [2021-01-13 00:06:19,681] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:19,690] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:20,279] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.655 seconds
[2021-01-13 00:06:20,323] {scheduler_job.py:181} INFO - Started process (PID=512) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:20,326] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:20,330] {logging_mixin.py:103} INFO - [2021-01-13 00:06:20,330] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:20,353] {logging_mixin.py:103} INFO - [2021-01-13 00:06:20,350] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:20,358] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:20,920] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.604 seconds
[2021-01-13 00:06:20,981] {scheduler_job.py:181} INFO - Started process (PID=513) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:20,984] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:20,986] {logging_mixin.py:103} INFO - [2021-01-13 00:06:20,986] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:21,050] {logging_mixin.py:103} INFO - [2021-01-13 00:06:21,046] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:21,056] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:21,648] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.676 seconds
[2021-01-13 00:06:21,779] {scheduler_job.py:181} INFO - Started process (PID=514) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:21,793] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:21,802] {logging_mixin.py:103} INFO - [2021-01-13 00:06:21,800] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:21,984] {logging_mixin.py:103} INFO - [2021-01-13 00:06:21,971] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:22,008] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:22,529] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.764 seconds
[2021-01-13 00:06:22,598] {scheduler_job.py:181} INFO - Started process (PID=515) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:22,601] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:22,604] {logging_mixin.py:103} INFO - [2021-01-13 00:06:22,604] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:22,648] {logging_mixin.py:103} INFO - [2021-01-13 00:06:22,639] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:22,654] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:23,219] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.627 seconds
[2021-01-13 00:06:23,282] {scheduler_job.py:181} INFO - Started process (PID=516) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:23,287] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:23,293] {logging_mixin.py:103} INFO - [2021-01-13 00:06:23,293] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:23,341] {logging_mixin.py:103} INFO - [2021-01-13 00:06:23,334] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:23,347] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:29,572] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 6.299 seconds
[2021-01-13 00:06:30,061] {scheduler_job.py:181} INFO - Started process (PID=517) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:30,067] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:30,075] {logging_mixin.py:103} INFO - [2021-01-13 00:06:30,071] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:30,111] {logging_mixin.py:103} INFO - [2021-01-13 00:06:30,106] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:30,124] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:30,828] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.777 seconds
[2021-01-13 00:06:31,122] {scheduler_job.py:181} INFO - Started process (PID=518) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:31,129] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:31,140] {logging_mixin.py:103} INFO - [2021-01-13 00:06:31,140] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:31,292] {logging_mixin.py:103} INFO - [2021-01-13 00:06:31,289] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:31,297] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:31,830] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.740 seconds
[2021-01-13 00:06:31,909] {scheduler_job.py:181} INFO - Started process (PID=519) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:31,912] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:31,917] {logging_mixin.py:103} INFO - [2021-01-13 00:06:31,917] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:31,996] {logging_mixin.py:103} INFO - [2021-01-13 00:06:31,951] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:32,006] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:32,625] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.724 seconds
[2021-01-13 00:06:32,677] {scheduler_job.py:181} INFO - Started process (PID=520) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:32,684] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:32,690] {logging_mixin.py:103} INFO - [2021-01-13 00:06:32,690] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:33,065] {logging_mixin.py:103} INFO - [2021-01-13 00:06:33,042] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:33,074] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:33,674] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.008 seconds
[2021-01-13 00:06:33,762] {scheduler_job.py:181} INFO - Started process (PID=521) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:33,769] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:33,773] {logging_mixin.py:103} INFO - [2021-01-13 00:06:33,773] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:33,822] {logging_mixin.py:103} INFO - [2021-01-13 00:06:33,817] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:33,828] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:34,422] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.674 seconds
[2021-01-13 00:06:34,478] {scheduler_job.py:181} INFO - Started process (PID=522) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:34,482] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:34,485] {logging_mixin.py:103} INFO - [2021-01-13 00:06:34,485] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:34,519] {logging_mixin.py:103} INFO - [2021-01-13 00:06:34,513] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:34,524] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:35,096] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.624 seconds
[2021-01-13 00:06:35,156] {scheduler_job.py:181} INFO - Started process (PID=523) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:35,159] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:35,162] {logging_mixin.py:103} INFO - [2021-01-13 00:06:35,162] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:35,198] {logging_mixin.py:103} INFO - [2021-01-13 00:06:35,194] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:35,202] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:35,864] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.719 seconds
[2021-01-13 00:06:35,972] {scheduler_job.py:181} INFO - Started process (PID=524) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:35,988] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:35,996] {logging_mixin.py:103} INFO - [2021-01-13 00:06:35,996] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:36,063] {logging_mixin.py:103} INFO - [2021-01-13 00:06:36,051] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:36,071] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:36,662] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.698 seconds
[2021-01-13 00:06:36,751] {scheduler_job.py:181} INFO - Started process (PID=525) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:36,754] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:36,757] {logging_mixin.py:103} INFO - [2021-01-13 00:06:36,756] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:36,792] {logging_mixin.py:103} INFO - [2021-01-13 00:06:36,789] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:36,796] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:37,397] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.651 seconds
[2021-01-13 00:06:37,520] {scheduler_job.py:181} INFO - Started process (PID=526) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:37,534] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:37,631] {logging_mixin.py:103} INFO - [2021-01-13 00:06:37,630] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:37,776] {logging_mixin.py:103} INFO - [2021-01-13 00:06:37,770] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:37,783] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:38,357] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.852 seconds
[2021-01-13 00:06:38,471] {scheduler_job.py:181} INFO - Started process (PID=527) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:38,479] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:38,483] {logging_mixin.py:103} INFO - [2021-01-13 00:06:38,482] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:38,515] {logging_mixin.py:103} INFO - [2021-01-13 00:06:38,512] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:38,520] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:39,093] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.632 seconds
[2021-01-13 00:06:39,181] {scheduler_job.py:181} INFO - Started process (PID=528) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:39,184] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:39,188] {logging_mixin.py:103} INFO - [2021-01-13 00:06:39,187] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:39,232] {logging_mixin.py:103} INFO - [2021-01-13 00:06:39,227] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:39,238] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:39,931] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.761 seconds
[2021-01-13 00:06:40,130] {scheduler_job.py:181} INFO - Started process (PID=529) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:40,133] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:40,136] {logging_mixin.py:103} INFO - [2021-01-13 00:06:40,136] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:40,177] {logging_mixin.py:103} INFO - [2021-01-13 00:06:40,168] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:40,183] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:40,757] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.634 seconds
[2021-01-13 00:06:40,805] {scheduler_job.py:181} INFO - Started process (PID=530) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:40,809] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:40,812] {logging_mixin.py:103} INFO - [2021-01-13 00:06:40,812] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:40,845] {logging_mixin.py:103} INFO - [2021-01-13 00:06:40,839] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:40,868] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:41,437] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.640 seconds
[2021-01-13 00:06:41,489] {scheduler_job.py:181} INFO - Started process (PID=531) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:41,495] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:41,501] {logging_mixin.py:103} INFO - [2021-01-13 00:06:41,500] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:41,541] {logging_mixin.py:103} INFO - [2021-01-13 00:06:41,536] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:41,548] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:42,193] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.715 seconds
[2021-01-13 00:06:42,239] {scheduler_job.py:181} INFO - Started process (PID=532) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:42,242] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:42,246] {logging_mixin.py:103} INFO - [2021-01-13 00:06:42,246] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:42,285] {logging_mixin.py:103} INFO - [2021-01-13 00:06:42,278] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:42,290] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:42,895] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.667 seconds
[2021-01-13 00:06:42,981] {scheduler_job.py:181} INFO - Started process (PID=533) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:42,985] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:42,997] {logging_mixin.py:103} INFO - [2021-01-13 00:06:42,997] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:43,054] {logging_mixin.py:103} INFO - [2021-01-13 00:06:43,050] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:43,058] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:43,626] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.652 seconds
[2021-01-13 00:06:43,691] {scheduler_job.py:181} INFO - Started process (PID=534) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:43,695] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:43,698] {logging_mixin.py:103} INFO - [2021-01-13 00:06:43,698] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:43,728] {logging_mixin.py:103} INFO - [2021-01-13 00:06:43,725] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:43,734] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:44,446] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.765 seconds
[2021-01-13 00:06:44,489] {scheduler_job.py:181} INFO - Started process (PID=535) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:44,492] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:44,494] {logging_mixin.py:103} INFO - [2021-01-13 00:06:44,494] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:44,519] {logging_mixin.py:103} INFO - [2021-01-13 00:06:44,516] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:44,523] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:45,293] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.809 seconds
[2021-01-13 00:06:45,401] {scheduler_job.py:181} INFO - Started process (PID=536) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:45,404] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:45,408] {logging_mixin.py:103} INFO - [2021-01-13 00:06:45,407] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:45,447] {logging_mixin.py:103} INFO - [2021-01-13 00:06:45,441] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:45,452] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:46,046] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.652 seconds
[2021-01-13 00:06:46,113] {scheduler_job.py:181} INFO - Started process (PID=537) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:46,121] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:46,129] {logging_mixin.py:103} INFO - [2021-01-13 00:06:46,128] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:46,452] {logging_mixin.py:103} INFO - [2021-01-13 00:06:46,407] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:46,459] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:47,225] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.157 seconds
[2021-01-13 00:06:47,270] {scheduler_job.py:181} INFO - Started process (PID=538) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:47,273] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:47,277] {logging_mixin.py:103} INFO - [2021-01-13 00:06:47,277] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:47,305] {logging_mixin.py:103} INFO - [2021-01-13 00:06:47,303] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:47,310] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:48,031] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.767 seconds
[2021-01-13 00:06:48,118] {scheduler_job.py:181} INFO - Started process (PID=539) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:48,126] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:48,132] {logging_mixin.py:103} INFO - [2021-01-13 00:06:48,131] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:48,177] {logging_mixin.py:103} INFO - [2021-01-13 00:06:48,171] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:48,185] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:48,710] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.603 seconds
[2021-01-13 00:06:48,771] {scheduler_job.py:181} INFO - Started process (PID=540) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:48,796] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:48,798] {logging_mixin.py:103} INFO - [2021-01-13 00:06:48,798] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:48,833] {logging_mixin.py:103} INFO - [2021-01-13 00:06:48,829] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:48,840] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:49,566] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.806 seconds
[2021-01-13 00:06:49,625] {scheduler_job.py:181} INFO - Started process (PID=541) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:49,631] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:49,635] {logging_mixin.py:103} INFO - [2021-01-13 00:06:49,634] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:49,741] {logging_mixin.py:103} INFO - [2021-01-13 00:06:49,731] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:49,806] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:50,386] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.772 seconds
[2021-01-13 00:06:50,439] {scheduler_job.py:181} INFO - Started process (PID=542) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:50,446] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:50,450] {logging_mixin.py:103} INFO - [2021-01-13 00:06:50,450] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:50,489] {logging_mixin.py:103} INFO - [2021-01-13 00:06:50,484] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:50,496] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:51,150] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.723 seconds
[2021-01-13 00:06:51,208] {scheduler_job.py:181} INFO - Started process (PID=543) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:51,214] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:51,220] {logging_mixin.py:103} INFO - [2021-01-13 00:06:51,219] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:51,265] {logging_mixin.py:103} INFO - [2021-01-13 00:06:51,260] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:51,323] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:52,121] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.924 seconds
[2021-01-13 00:06:52,176] {scheduler_job.py:181} INFO - Started process (PID=544) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:52,182] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:52,193] {logging_mixin.py:103} INFO - [2021-01-13 00:06:52,192] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:52,233] {logging_mixin.py:103} INFO - [2021-01-13 00:06:52,228] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:52,250] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:52,818] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.652 seconds
[2021-01-13 00:06:52,883] {scheduler_job.py:181} INFO - Started process (PID=545) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:52,897] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:52,905] {logging_mixin.py:103} INFO - [2021-01-13 00:06:52,904] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:52,994] {logging_mixin.py:103} INFO - [2021-01-13 00:06:52,989] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:53,003] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:57,633] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 4.763 seconds
[2021-01-13 00:06:57,697] {scheduler_job.py:181} INFO - Started process (PID=546) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:57,699] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:57,701] {logging_mixin.py:103} INFO - [2021-01-13 00:06:57,701] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:57,726] {logging_mixin.py:103} INFO - [2021-01-13 00:06:57,723] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:57,730] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:58,295] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.604 seconds
[2021-01-13 00:06:58,343] {scheduler_job.py:181} INFO - Started process (PID=547) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:58,346] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:58,352] {logging_mixin.py:103} INFO - [2021-01-13 00:06:58,352] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:58,382] {logging_mixin.py:103} INFO - [2021-01-13 00:06:58,376] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:58,386] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:58,934] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.597 seconds
[2021-01-13 00:06:58,983] {scheduler_job.py:181} INFO - Started process (PID=548) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:58,990] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:58,998] {logging_mixin.py:103} INFO - [2021-01-13 00:06:58,998] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:59,055] {logging_mixin.py:103} INFO - [2021-01-13 00:06:59,048] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:59,061] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:06:59,660] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.684 seconds
[2021-01-13 00:06:59,712] {scheduler_job.py:181} INFO - Started process (PID=549) to work on /opt/airflow/dags/example.py
[2021-01-13 00:06:59,715] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:06:59,717] {logging_mixin.py:103} INFO - [2021-01-13 00:06:59,717] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:06:59,742] {logging_mixin.py:103} INFO - [2021-01-13 00:06:59,738] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:06:59,745] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:00,388] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.682 seconds
[2021-01-13 00:07:00,555] {scheduler_job.py:181} INFO - Started process (PID=550) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:00,563] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:00,568] {logging_mixin.py:103} INFO - [2021-01-13 00:07:00,568] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:00,595] {logging_mixin.py:103} INFO - [2021-01-13 00:07:00,591] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:00,599] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:01,279] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.733 seconds
[2021-01-13 00:07:01,397] {scheduler_job.py:181} INFO - Started process (PID=551) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:01,401] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:01,405] {logging_mixin.py:103} INFO - [2021-01-13 00:07:01,404] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:01,444] {logging_mixin.py:103} INFO - [2021-01-13 00:07:01,441] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:01,450] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:02,121] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.740 seconds
[2021-01-13 00:07:02,204] {scheduler_job.py:181} INFO - Started process (PID=552) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:02,223] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:02,231] {logging_mixin.py:103} INFO - [2021-01-13 00:07:02,231] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:02,307] {logging_mixin.py:103} INFO - [2021-01-13 00:07:02,300] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:02,314] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:02,920] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.730 seconds
[2021-01-13 00:07:03,044] {scheduler_job.py:181} INFO - Started process (PID=553) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:03,047] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:03,050] {logging_mixin.py:103} INFO - [2021-01-13 00:07:03,049] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:03,118] {logging_mixin.py:103} INFO - [2021-01-13 00:07:03,115] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:03,123] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:03,708] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.676 seconds
[2021-01-13 00:07:03,765] {scheduler_job.py:181} INFO - Started process (PID=554) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:03,768] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:03,772] {logging_mixin.py:103} INFO - [2021-01-13 00:07:03,772] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:03,803] {logging_mixin.py:103} INFO - [2021-01-13 00:07:03,799] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:03,807] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:04,368] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.622 seconds
[2021-01-13 00:07:04,419] {scheduler_job.py:181} INFO - Started process (PID=555) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:04,424] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:04,431] {logging_mixin.py:103} INFO - [2021-01-13 00:07:04,431] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:04,478] {logging_mixin.py:103} INFO - [2021-01-13 00:07:04,468] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:04,483] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:05,082] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.669 seconds
[2021-01-13 00:07:05,155] {scheduler_job.py:181} INFO - Started process (PID=556) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:05,160] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:05,181] {logging_mixin.py:103} INFO - [2021-01-13 00:07:05,179] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:05,264] {logging_mixin.py:103} INFO - [2021-01-13 00:07:05,256] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:05,278] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:05,858] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.712 seconds
[2021-01-13 00:07:05,952] {scheduler_job.py:181} INFO - Started process (PID=557) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:05,960] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:05,964] {logging_mixin.py:103} INFO - [2021-01-13 00:07:05,963] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:06,028] {logging_mixin.py:103} INFO - [2021-01-13 00:07:06,024] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:06,032] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:06,805] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.859 seconds
[2021-01-13 00:07:06,868] {scheduler_job.py:181} INFO - Started process (PID=558) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:06,873] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:06,877] {logging_mixin.py:103} INFO - [2021-01-13 00:07:06,876] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:06,928] {logging_mixin.py:103} INFO - [2021-01-13 00:07:06,922] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:06,934] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:07,601] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.737 seconds
[2021-01-13 00:07:07,705] {scheduler_job.py:181} INFO - Started process (PID=559) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:07,711] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:07,714] {logging_mixin.py:103} INFO - [2021-01-13 00:07:07,713] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:07,746] {logging_mixin.py:103} INFO - [2021-01-13 00:07:07,744] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:07,751] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:08,392] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.696 seconds
[2021-01-13 00:07:08,494] {scheduler_job.py:181} INFO - Started process (PID=560) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:08,504] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:08,518] {logging_mixin.py:103} INFO - [2021-01-13 00:07:08,518] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:08,568] {logging_mixin.py:103} INFO - [2021-01-13 00:07:08,564] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:08,572] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:09,135] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.662 seconds
[2021-01-13 00:07:09,220] {scheduler_job.py:181} INFO - Started process (PID=561) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:09,231] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:09,238] {logging_mixin.py:103} INFO - [2021-01-13 00:07:09,237] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:09,286] {logging_mixin.py:103} INFO - [2021-01-13 00:07:09,284] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:09,300] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:09,981] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.774 seconds
[2021-01-13 00:07:10,038] {scheduler_job.py:181} INFO - Started process (PID=562) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:10,053] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:10,065] {logging_mixin.py:103} INFO - [2021-01-13 00:07:10,065] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:10,140] {logging_mixin.py:103} INFO - [2021-01-13 00:07:10,121] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:10,185] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:10,699] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.669 seconds
[2021-01-13 00:07:11,052] {scheduler_job.py:181} INFO - Started process (PID=563) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:11,065] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:11,088] {logging_mixin.py:103} INFO - [2021-01-13 00:07:11,088] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:11,132] {logging_mixin.py:103} INFO - [2021-01-13 00:07:11,126] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:11,138] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:11,860] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.821 seconds
[2021-01-13 00:07:12,189] {scheduler_job.py:181} INFO - Started process (PID=564) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:12,208] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:12,240] {logging_mixin.py:103} INFO - [2021-01-13 00:07:12,239] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:12,325] {logging_mixin.py:103} INFO - [2021-01-13 00:07:12,309] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:12,343] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:13,060] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.898 seconds
[2021-01-13 00:07:13,118] {scheduler_job.py:181} INFO - Started process (PID=565) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:13,124] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:13,127] {logging_mixin.py:103} INFO - [2021-01-13 00:07:13,127] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:13,179] {logging_mixin.py:103} INFO - [2021-01-13 00:07:13,172] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:13,187] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:13,747] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.637 seconds
[2021-01-13 00:07:13,838] {scheduler_job.py:181} INFO - Started process (PID=566) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:13,845] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:13,853] {logging_mixin.py:103} INFO - [2021-01-13 00:07:13,851] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:13,884] {logging_mixin.py:103} INFO - [2021-01-13 00:07:13,881] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:13,890] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:14,414] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.589 seconds
[2021-01-13 00:07:14,487] {scheduler_job.py:181} INFO - Started process (PID=567) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:14,498] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:14,504] {logging_mixin.py:103} INFO - [2021-01-13 00:07:14,503] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:14,541] {logging_mixin.py:103} INFO - [2021-01-13 00:07:14,537] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:14,558] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:15,242] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.764 seconds
[2021-01-13 00:07:15,304] {scheduler_job.py:181} INFO - Started process (PID=568) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:15,307] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:15,310] {logging_mixin.py:103} INFO - [2021-01-13 00:07:15,310] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:15,371] {logging_mixin.py:103} INFO - [2021-01-13 00:07:15,363] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:15,389] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:15,969] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.674 seconds
[2021-01-13 00:07:16,019] {scheduler_job.py:181} INFO - Started process (PID=569) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:16,023] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:16,026] {logging_mixin.py:103} INFO - [2021-01-13 00:07:16,026] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:16,063] {logging_mixin.py:103} INFO - [2021-01-13 00:07:16,058] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:16,083] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:16,771] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.791 seconds
[2021-01-13 00:07:16,923] {scheduler_job.py:181} INFO - Started process (PID=570) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:16,930] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:16,944] {logging_mixin.py:103} INFO - [2021-01-13 00:07:16,934] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:17,033] {logging_mixin.py:103} INFO - [2021-01-13 00:07:17,030] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:17,038] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:17,593] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.678 seconds
[2021-01-13 00:07:17,644] {scheduler_job.py:181} INFO - Started process (PID=571) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:17,650] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:17,654] {logging_mixin.py:103} INFO - [2021-01-13 00:07:17,654] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:17,750] {logging_mixin.py:103} INFO - [2021-01-13 00:07:17,744] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:17,758] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:18,297] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.659 seconds
[2021-01-13 00:07:18,349] {scheduler_job.py:181} INFO - Started process (PID=572) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:18,358] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:18,360] {logging_mixin.py:103} INFO - [2021-01-13 00:07:18,360] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:18,401] {logging_mixin.py:103} INFO - [2021-01-13 00:07:18,395] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:18,411] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:19,010] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.667 seconds
[2021-01-13 00:07:19,061] {scheduler_job.py:181} INFO - Started process (PID=573) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:19,065] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:19,069] {logging_mixin.py:103} INFO - [2021-01-13 00:07:19,068] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:19,097] {logging_mixin.py:103} INFO - [2021-01-13 00:07:19,093] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:19,103] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:19,636] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.583 seconds
[2021-01-13 00:07:19,685] {scheduler_job.py:181} INFO - Started process (PID=574) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:19,690] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:19,694] {logging_mixin.py:103} INFO - [2021-01-13 00:07:19,694] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:19,726] {logging_mixin.py:103} INFO - [2021-01-13 00:07:19,723] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:19,730] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:20,552] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.874 seconds
[2021-01-13 00:07:20,594] {scheduler_job.py:181} INFO - Started process (PID=575) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:20,597] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:20,600] {logging_mixin.py:103} INFO - [2021-01-13 00:07:20,600] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:20,628] {logging_mixin.py:103} INFO - [2021-01-13 00:07:20,624] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:20,631] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:21,271] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.683 seconds
[2021-01-13 00:07:21,461] {scheduler_job.py:181} INFO - Started process (PID=576) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:21,464] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:21,466] {logging_mixin.py:103} INFO - [2021-01-13 00:07:21,466] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:21,495] {logging_mixin.py:103} INFO - [2021-01-13 00:07:21,491] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:21,503] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:22,132] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.678 seconds
[2021-01-13 00:07:22,181] {scheduler_job.py:181} INFO - Started process (PID=577) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:22,185] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:22,188] {logging_mixin.py:103} INFO - [2021-01-13 00:07:22,188] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:22,216] {logging_mixin.py:103} INFO - [2021-01-13 00:07:22,212] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:22,225] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:22,866] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.692 seconds
[2021-01-13 00:07:22,925] {scheduler_job.py:181} INFO - Started process (PID=578) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:22,935] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:22,938] {logging_mixin.py:103} INFO - [2021-01-13 00:07:22,937] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:22,980] {logging_mixin.py:103} INFO - [2021-01-13 00:07:22,974] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:22,985] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:23,652] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.737 seconds
[2021-01-13 00:07:23,834] {scheduler_job.py:181} INFO - Started process (PID=579) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:23,840] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:23,844] {logging_mixin.py:103} INFO - [2021-01-13 00:07:23,844] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:24,414] {logging_mixin.py:103} INFO - [2021-01-13 00:07:24,410] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:24,420] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:25,219] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.396 seconds
[2021-01-13 00:07:25,296] {scheduler_job.py:181} INFO - Started process (PID=580) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:25,308] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:25,317] {logging_mixin.py:103} INFO - [2021-01-13 00:07:25,317] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:25,541] {logging_mixin.py:103} INFO - [2021-01-13 00:07:25,470] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:25,551] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:28,970] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 3.692 seconds
[2021-01-13 00:07:29,151] {scheduler_job.py:181} INFO - Started process (PID=581) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:29,177] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:29,195] {logging_mixin.py:103} INFO - [2021-01-13 00:07:29,194] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:29,457] {logging_mixin.py:103} INFO - [2021-01-13 00:07:29,450] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:29,462] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:30,186] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.084 seconds
[2021-01-13 00:07:30,237] {scheduler_job.py:181} INFO - Started process (PID=582) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:30,242] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:30,244] {logging_mixin.py:103} INFO - [2021-01-13 00:07:30,244] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:30,280] {logging_mixin.py:103} INFO - [2021-01-13 00:07:30,276] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:30,286] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:30,865] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.635 seconds
[2021-01-13 00:07:30,928] {scheduler_job.py:181} INFO - Started process (PID=583) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:30,932] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:30,934] {logging_mixin.py:103} INFO - [2021-01-13 00:07:30,934] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:30,966] {logging_mixin.py:103} INFO - [2021-01-13 00:07:30,962] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:30,972] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:31,575] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.653 seconds
[2021-01-13 00:07:31,760] {scheduler_job.py:181} INFO - Started process (PID=584) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:31,764] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:31,767] {logging_mixin.py:103} INFO - [2021-01-13 00:07:31,767] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:31,811] {logging_mixin.py:103} INFO - [2021-01-13 00:07:31,807] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:31,815] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:32,349] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.599 seconds
[2021-01-13 00:07:32,403] {scheduler_job.py:181} INFO - Started process (PID=585) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:32,409] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:32,414] {logging_mixin.py:103} INFO - [2021-01-13 00:07:32,413] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:32,446] {logging_mixin.py:103} INFO - [2021-01-13 00:07:32,443] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:32,451] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:33,059] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.665 seconds
[2021-01-13 00:07:33,117] {scheduler_job.py:181} INFO - Started process (PID=586) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:33,120] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:33,124] {logging_mixin.py:103} INFO - [2021-01-13 00:07:33,123] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:33,158] {logging_mixin.py:103} INFO - [2021-01-13 00:07:33,154] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:33,166] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:33,810] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.702 seconds
[2021-01-13 00:07:33,891] {scheduler_job.py:181} INFO - Started process (PID=587) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:33,897] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:33,902] {logging_mixin.py:103} INFO - [2021-01-13 00:07:33,901] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:34,009] {logging_mixin.py:103} INFO - [2021-01-13 00:07:34,002] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:34,018] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:34,610] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.732 seconds
[2021-01-13 00:07:34,680] {scheduler_job.py:181} INFO - Started process (PID=588) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:34,723] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:34,807] {logging_mixin.py:103} INFO - [2021-01-13 00:07:34,805] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:35,031] {logging_mixin.py:103} INFO - [2021-01-13 00:07:35,014] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:35,089] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:35,846] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.180 seconds
[2021-01-13 00:07:36,176] {scheduler_job.py:181} INFO - Started process (PID=589) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:36,185] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:36,187] {logging_mixin.py:103} INFO - [2021-01-13 00:07:36,187] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:36,222] {logging_mixin.py:103} INFO - [2021-01-13 00:07:36,217] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:36,229] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:36,964] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.797 seconds
[2021-01-13 00:07:37,205] {scheduler_job.py:181} INFO - Started process (PID=590) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:37,216] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:37,219] {logging_mixin.py:103} INFO - [2021-01-13 00:07:37,219] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:37,418] {logging_mixin.py:103} INFO - [2021-01-13 00:07:37,405] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:37,436] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:38,191] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.140 seconds
[2021-01-13 00:07:38,251] {scheduler_job.py:181} INFO - Started process (PID=591) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:38,256] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:38,259] {logging_mixin.py:103} INFO - [2021-01-13 00:07:38,258] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:38,297] {logging_mixin.py:103} INFO - [2021-01-13 00:07:38,290] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:38,302] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:39,069] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.832 seconds
[2021-01-13 00:07:39,122] {scheduler_job.py:181} INFO - Started process (PID=592) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:39,129] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:39,134] {logging_mixin.py:103} INFO - [2021-01-13 00:07:39,133] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:39,165] {logging_mixin.py:103} INFO - [2021-01-13 00:07:39,162] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:39,169] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:39,741] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.632 seconds
[2021-01-13 00:07:39,812] {scheduler_job.py:181} INFO - Started process (PID=593) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:39,817] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:39,821] {logging_mixin.py:103} INFO - [2021-01-13 00:07:39,820] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:39,868] {logging_mixin.py:103} INFO - [2021-01-13 00:07:39,861] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:39,897] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:40,499] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.698 seconds
[2021-01-13 00:07:40,556] {scheduler_job.py:181} INFO - Started process (PID=594) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:40,559] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:40,561] {logging_mixin.py:103} INFO - [2021-01-13 00:07:40,561] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:40,595] {logging_mixin.py:103} INFO - [2021-01-13 00:07:40,589] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:40,604] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:41,370] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.821 seconds
[2021-01-13 00:07:41,428] {scheduler_job.py:181} INFO - Started process (PID=595) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:41,434] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:41,437] {logging_mixin.py:103} INFO - [2021-01-13 00:07:41,437] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:41,471] {logging_mixin.py:103} INFO - [2021-01-13 00:07:41,465] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:41,487] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:42,119] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.704 seconds
[2021-01-13 00:07:42,440] {scheduler_job.py:181} INFO - Started process (PID=596) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:42,444] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:42,452] {logging_mixin.py:103} INFO - [2021-01-13 00:07:42,452] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:42,489] {logging_mixin.py:103} INFO - [2021-01-13 00:07:42,482] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:42,501] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:43,144] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.713 seconds
[2021-01-13 00:07:43,188] {scheduler_job.py:181} INFO - Started process (PID=597) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:43,193] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:43,196] {logging_mixin.py:103} INFO - [2021-01-13 00:07:43,196] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:43,222] {logging_mixin.py:103} INFO - [2021-01-13 00:07:43,219] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:43,226] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:43,891] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.709 seconds
[2021-01-13 00:07:43,941] {scheduler_job.py:181} INFO - Started process (PID=598) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:43,944] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:43,946] {logging_mixin.py:103} INFO - [2021-01-13 00:07:43,946] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:43,990] {logging_mixin.py:103} INFO - [2021-01-13 00:07:43,982] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:44,000] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:44,612] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.679 seconds
[2021-01-13 00:07:44,668] {scheduler_job.py:181} INFO - Started process (PID=599) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:44,676] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:44,681] {logging_mixin.py:103} INFO - [2021-01-13 00:07:44,681] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:44,854] {logging_mixin.py:103} INFO - [2021-01-13 00:07:44,832] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:44,887] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:45,574] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.914 seconds
[2021-01-13 00:07:45,646] {scheduler_job.py:181} INFO - Started process (PID=600) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:45,651] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:45,657] {logging_mixin.py:103} INFO - [2021-01-13 00:07:45,655] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:45,730] {logging_mixin.py:103} INFO - [2021-01-13 00:07:45,702] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:45,738] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:46,339] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.739 seconds
[2021-01-13 00:07:46,401] {scheduler_job.py:181} INFO - Started process (PID=601) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:46,406] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:46,410] {logging_mixin.py:103} INFO - [2021-01-13 00:07:46,409] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:46,449] {logging_mixin.py:103} INFO - [2021-01-13 00:07:46,444] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:46,453] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:47,148] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.755 seconds
[2021-01-13 00:07:47,323] {scheduler_job.py:181} INFO - Started process (PID=602) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:47,328] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:47,332] {logging_mixin.py:103} INFO - [2021-01-13 00:07:47,332] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:47,395] {logging_mixin.py:103} INFO - [2021-01-13 00:07:47,387] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:47,402] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:48,428] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.113 seconds
[2021-01-13 00:07:48,486] {scheduler_job.py:181} INFO - Started process (PID=603) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:48,490] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:48,497] {logging_mixin.py:103} INFO - [2021-01-13 00:07:48,496] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:48,549] {logging_mixin.py:103} INFO - [2021-01-13 00:07:48,545] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:48,560] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:49,121] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.642 seconds
[2021-01-13 00:07:49,170] {scheduler_job.py:181} INFO - Started process (PID=604) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:49,173] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:49,176] {logging_mixin.py:103} INFO - [2021-01-13 00:07:49,176] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:49,206] {logging_mixin.py:103} INFO - [2021-01-13 00:07:49,203] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:49,210] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:49,806] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.641 seconds
[2021-01-13 00:07:49,869] {scheduler_job.py:181} INFO - Started process (PID=605) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:49,875] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:49,881] {logging_mixin.py:103} INFO - [2021-01-13 00:07:49,881] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:49,948] {logging_mixin.py:103} INFO - [2021-01-13 00:07:49,941] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:49,962] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:50,485] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.625 seconds
[2021-01-13 00:07:50,549] {scheduler_job.py:181} INFO - Started process (PID=606) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:50,553] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:50,557] {logging_mixin.py:103} INFO - [2021-01-13 00:07:50,556] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:50,605] {logging_mixin.py:103} INFO - [2021-01-13 00:07:50,599] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:50,615] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:51,219] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.683 seconds
[2021-01-13 00:07:51,273] {scheduler_job.py:181} INFO - Started process (PID=607) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:51,279] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:51,286] {logging_mixin.py:103} INFO - [2021-01-13 00:07:51,285] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:51,318] {logging_mixin.py:103} INFO - [2021-01-13 00:07:51,316] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:51,331] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:51,955] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.694 seconds
[2021-01-13 00:07:52,024] {scheduler_job.py:181} INFO - Started process (PID=608) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:52,027] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:52,034] {logging_mixin.py:103} INFO - [2021-01-13 00:07:52,033] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:52,093] {logging_mixin.py:103} INFO - [2021-01-13 00:07:52,087] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:52,103] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:52,678] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.667 seconds
[2021-01-13 00:07:52,794] {scheduler_job.py:181} INFO - Started process (PID=609) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:52,799] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:52,802] {logging_mixin.py:103} INFO - [2021-01-13 00:07:52,802] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:52,848] {logging_mixin.py:103} INFO - [2021-01-13 00:07:52,835] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:52,861] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:53,450] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.699 seconds
[2021-01-13 00:07:53,517] {scheduler_job.py:181} INFO - Started process (PID=610) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:53,524] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:53,528] {logging_mixin.py:103} INFO - [2021-01-13 00:07:53,528] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:53,572] {logging_mixin.py:103} INFO - [2021-01-13 00:07:53,567] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:53,581] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:54,185] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.683 seconds
[2021-01-13 00:07:54,272] {scheduler_job.py:181} INFO - Started process (PID=611) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:54,278] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:54,285] {logging_mixin.py:103} INFO - [2021-01-13 00:07:54,283] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:54,328] {logging_mixin.py:103} INFO - [2021-01-13 00:07:54,323] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:54,335] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:54,870] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.611 seconds
[2021-01-13 00:07:54,946] {scheduler_job.py:181} INFO - Started process (PID=612) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:54,964] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:55,002] {logging_mixin.py:103} INFO - [2021-01-13 00:07:55,001] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:55,046] {logging_mixin.py:103} INFO - [2021-01-13 00:07:55,041] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:55,053] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:55,629] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.699 seconds
[2021-01-13 00:07:55,717] {scheduler_job.py:181} INFO - Started process (PID=613) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:55,727] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:55,733] {logging_mixin.py:103} INFO - [2021-01-13 00:07:55,732] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:55,792] {logging_mixin.py:103} INFO - [2021-01-13 00:07:55,785] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:55,800] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:56,358] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.662 seconds
[2021-01-13 00:07:56,429] {scheduler_job.py:181} INFO - Started process (PID=614) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:56,432] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:56,436] {logging_mixin.py:103} INFO - [2021-01-13 00:07:56,435] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:56,493] {logging_mixin.py:103} INFO - [2021-01-13 00:07:56,484] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:56,497] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:57,072] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.656 seconds
[2021-01-13 00:07:57,112] {scheduler_job.py:181} INFO - Started process (PID=615) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:57,115] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:57,119] {logging_mixin.py:103} INFO - [2021-01-13 00:07:57,119] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:57,168] {logging_mixin.py:103} INFO - [2021-01-13 00:07:57,164] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:57,173] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:57,837] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.731 seconds
[2021-01-13 00:07:57,909] {scheduler_job.py:181} INFO - Started process (PID=616) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:57,927] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:57,936] {logging_mixin.py:103} INFO - [2021-01-13 00:07:57,936] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:58,019] {logging_mixin.py:103} INFO - [2021-01-13 00:07:58,012] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:58,028] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:58,611] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.708 seconds
[2021-01-13 00:07:58,673] {scheduler_job.py:181} INFO - Started process (PID=617) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:58,678] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:58,736] {logging_mixin.py:103} INFO - [2021-01-13 00:07:58,736] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:58,831] {logging_mixin.py:103} INFO - [2021-01-13 00:07:58,814] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:58,843] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:07:59,381] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.718 seconds
[2021-01-13 00:07:59,437] {scheduler_job.py:181} INFO - Started process (PID=618) to work on /opt/airflow/dags/example.py
[2021-01-13 00:07:59,441] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:07:59,444] {logging_mixin.py:103} INFO - [2021-01-13 00:07:59,444] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:07:59,475] {logging_mixin.py:103} INFO - [2021-01-13 00:07:59,471] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:07:59,479] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:00,156] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.726 seconds
[2021-01-13 00:08:00,198] {scheduler_job.py:181} INFO - Started process (PID=619) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:00,201] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:00,203] {logging_mixin.py:103} INFO - [2021-01-13 00:08:00,203] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:00,232] {logging_mixin.py:103} INFO - [2021-01-13 00:08:00,226] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:00,236] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:00,787] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.595 seconds
[2021-01-13 00:08:00,927] {scheduler_job.py:181} INFO - Started process (PID=620) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:00,935] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:00,940] {logging_mixin.py:103} INFO - [2021-01-13 00:08:00,939] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:00,979] {logging_mixin.py:103} INFO - [2021-01-13 00:08:00,975] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:00,986] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:01,572] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.662 seconds
[2021-01-13 00:08:01,618] {scheduler_job.py:181} INFO - Started process (PID=621) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:01,621] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:01,624] {logging_mixin.py:103} INFO - [2021-01-13 00:08:01,624] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:01,655] {logging_mixin.py:103} INFO - [2021-01-13 00:08:01,651] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:01,662] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:02,185] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.572 seconds
[2021-01-13 00:08:02,243] {scheduler_job.py:181} INFO - Started process (PID=622) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:02,252] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:02,255] {logging_mixin.py:103} INFO - [2021-01-13 00:08:02,255] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:02,292] {logging_mixin.py:103} INFO - [2021-01-13 00:08:02,288] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:02,298] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:02,976] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.744 seconds
[2021-01-13 00:08:03,156] {scheduler_job.py:181} INFO - Started process (PID=623) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:03,164] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:03,167] {logging_mixin.py:103} INFO - [2021-01-13 00:08:03,166] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:03,205] {logging_mixin.py:103} INFO - [2021-01-13 00:08:03,202] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:03,210] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:03,811] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.662 seconds
[2021-01-13 00:08:03,953] {scheduler_job.py:181} INFO - Started process (PID=624) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:03,959] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:03,962] {logging_mixin.py:103} INFO - [2021-01-13 00:08:03,962] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:04,004] {logging_mixin.py:103} INFO - [2021-01-13 00:08:04,001] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:04,007] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:04,589] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.691 seconds
[2021-01-13 00:08:04,688] {scheduler_job.py:181} INFO - Started process (PID=625) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:04,693] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:04,697] {logging_mixin.py:103} INFO - [2021-01-13 00:08:04,697] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:04,849] {logging_mixin.py:103} INFO - [2021-01-13 00:08:04,784] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:04,892] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:05,579] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.904 seconds
[2021-01-13 00:08:05,810] {scheduler_job.py:181} INFO - Started process (PID=626) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:05,817] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:05,822] {logging_mixin.py:103} INFO - [2021-01-13 00:08:05,822] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:05,981] {logging_mixin.py:103} INFO - [2021-01-13 00:08:05,971] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:05,993] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:06,689] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.900 seconds
[2021-01-13 00:08:07,714] {scheduler_job.py:181} INFO - Started process (PID=627) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:07,730] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:07,816] {logging_mixin.py:103} INFO - [2021-01-13 00:08:07,816] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:07,981] {logging_mixin.py:103} INFO - [2021-01-13 00:08:07,953] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:08,002] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:08,633] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.935 seconds
[2021-01-13 00:08:09,024] {scheduler_job.py:181} INFO - Started process (PID=628) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:09,266] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:09,280] {logging_mixin.py:103} INFO - [2021-01-13 00:08:09,279] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:09,764] {logging_mixin.py:103} INFO - [2021-01-13 00:08:09,671] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:09,975] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:10,713] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.758 seconds
[2021-01-13 00:08:10,800] {scheduler_job.py:181} INFO - Started process (PID=629) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:10,811] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:10,815] {logging_mixin.py:103} INFO - [2021-01-13 00:08:10,814] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:10,892] {logging_mixin.py:103} INFO - [2021-01-13 00:08:10,860] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:10,898] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:11,496] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.712 seconds
[2021-01-13 00:08:11,585] {scheduler_job.py:181} INFO - Started process (PID=630) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:11,597] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:11,600] {logging_mixin.py:103} INFO - [2021-01-13 00:08:11,600] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:11,667] {logging_mixin.py:103} INFO - [2021-01-13 00:08:11,662] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:11,729] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:12,273] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.699 seconds
[2021-01-13 00:08:12,345] {scheduler_job.py:181} INFO - Started process (PID=631) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:12,352] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:12,358] {logging_mixin.py:103} INFO - [2021-01-13 00:08:12,358] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:12,401] {logging_mixin.py:103} INFO - [2021-01-13 00:08:12,398] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:12,412] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:12,975] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.648 seconds
[2021-01-13 00:08:13,032] {scheduler_job.py:181} INFO - Started process (PID=632) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:13,036] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:13,039] {logging_mixin.py:103} INFO - [2021-01-13 00:08:13,039] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:13,078] {logging_mixin.py:103} INFO - [2021-01-13 00:08:13,070] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:13,109] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:13,641] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.616 seconds
[2021-01-13 00:08:13,788] {scheduler_job.py:181} INFO - Started process (PID=633) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:13,793] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:13,803] {logging_mixin.py:103} INFO - [2021-01-13 00:08:13,801] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:13,858] {logging_mixin.py:103} INFO - [2021-01-13 00:08:13,851] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:13,868] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:14,417] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.634 seconds
[2021-01-13 00:08:14,466] {scheduler_job.py:181} INFO - Started process (PID=634) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:14,473] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:14,478] {logging_mixin.py:103} INFO - [2021-01-13 00:08:14,478] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:14,518] {logging_mixin.py:103} INFO - [2021-01-13 00:08:14,513] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:14,523] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:15,127] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.667 seconds
[2021-01-13 00:08:15,166] {scheduler_job.py:181} INFO - Started process (PID=635) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:15,171] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:15,173] {logging_mixin.py:103} INFO - [2021-01-13 00:08:15,173] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:15,199] {logging_mixin.py:103} INFO - [2021-01-13 00:08:15,196] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:15,202] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:15,817] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.656 seconds
[2021-01-13 00:08:15,870] {scheduler_job.py:181} INFO - Started process (PID=636) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:15,876] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:15,880] {logging_mixin.py:103} INFO - [2021-01-13 00:08:15,880] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:15,910] {logging_mixin.py:103} INFO - [2021-01-13 00:08:15,907] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:15,914] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:16,431] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.603 seconds
[2021-01-13 00:08:16,478] {scheduler_job.py:181} INFO - Started process (PID=637) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:16,482] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:16,485] {logging_mixin.py:103} INFO - [2021-01-13 00:08:16,485] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:16,517] {logging_mixin.py:103} INFO - [2021-01-13 00:08:16,513] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:16,521] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:17,074] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.605 seconds
[2021-01-13 00:08:17,127] {scheduler_job.py:181} INFO - Started process (PID=638) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:17,137] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:17,140] {logging_mixin.py:103} INFO - [2021-01-13 00:08:17,140] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:17,177] {logging_mixin.py:103} INFO - [2021-01-13 00:08:17,172] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:17,182] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:17,817] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.702 seconds
[2021-01-13 00:08:17,927] {scheduler_job.py:181} INFO - Started process (PID=639) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:17,932] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:17,934] {logging_mixin.py:103} INFO - [2021-01-13 00:08:17,934] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:17,972] {logging_mixin.py:103} INFO - [2021-01-13 00:08:17,967] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:17,979] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:18,524] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.618 seconds
[2021-01-13 00:08:18,688] {scheduler_job.py:181} INFO - Started process (PID=640) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:18,707] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:18,724] {logging_mixin.py:103} INFO - [2021-01-13 00:08:18,719] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:18,888] {logging_mixin.py:103} INFO - [2021-01-13 00:08:18,818] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:19,012] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:19,676] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.005 seconds
[2021-01-13 00:08:19,811] {scheduler_job.py:181} INFO - Started process (PID=641) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:19,818] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:19,822] {logging_mixin.py:103} INFO - [2021-01-13 00:08:19,822] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:19,880] {logging_mixin.py:103} INFO - [2021-01-13 00:08:19,871] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:19,899] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:20,539] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.744 seconds
[2021-01-13 00:08:20,601] {scheduler_job.py:181} INFO - Started process (PID=642) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:20,605] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:20,611] {logging_mixin.py:103} INFO - [2021-01-13 00:08:20,611] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:20,660] {logging_mixin.py:103} INFO - [2021-01-13 00:08:20,656] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:20,671] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:21,293] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.706 seconds
[2021-01-13 00:08:21,349] {scheduler_job.py:181} INFO - Started process (PID=643) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:21,354] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:21,357] {logging_mixin.py:103} INFO - [2021-01-13 00:08:21,357] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:21,403] {logging_mixin.py:103} INFO - [2021-01-13 00:08:21,392] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:21,412] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:21,996] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.655 seconds
[2021-01-13 00:08:22,057] {scheduler_job.py:181} INFO - Started process (PID=644) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:22,061] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:22,066] {logging_mixin.py:103} INFO - [2021-01-13 00:08:22,065] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:22,100] {logging_mixin.py:103} INFO - [2021-01-13 00:08:22,094] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:22,106] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:22,661] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.613 seconds
[2021-01-13 00:08:22,982] {scheduler_job.py:181} INFO - Started process (PID=645) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:22,992] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:22,996] {logging_mixin.py:103} INFO - [2021-01-13 00:08:22,995] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:23,037] {logging_mixin.py:103} INFO - [2021-01-13 00:08:23,032] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:23,042] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:23,682] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.708 seconds
[2021-01-13 00:08:23,864] {scheduler_job.py:181} INFO - Started process (PID=646) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:23,897] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:23,909] {logging_mixin.py:103} INFO - [2021-01-13 00:08:23,909] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:24,578] {logging_mixin.py:103} INFO - [2021-01-13 00:08:24,370] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:24,605] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:25,378] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.533 seconds
[2021-01-13 00:08:25,445] {scheduler_job.py:181} INFO - Started process (PID=647) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:25,456] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:25,460] {logging_mixin.py:103} INFO - [2021-01-13 00:08:25,460] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:25,495] {logging_mixin.py:103} INFO - [2021-01-13 00:08:25,492] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:25,510] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:26,085] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.648 seconds
[2021-01-13 00:08:26,174] {scheduler_job.py:181} INFO - Started process (PID=648) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:26,182] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:26,185] {logging_mixin.py:103} INFO - [2021-01-13 00:08:26,184] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:26,239] {logging_mixin.py:103} INFO - [2021-01-13 00:08:26,231] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:26,245] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:26,752] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.587 seconds
[2021-01-13 00:08:26,937] {scheduler_job.py:181} INFO - Started process (PID=649) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:26,943] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:26,947] {logging_mixin.py:103} INFO - [2021-01-13 00:08:26,947] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:26,993] {logging_mixin.py:103} INFO - [2021-01-13 00:08:26,989] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:26,997] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:27,581] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.656 seconds
[2021-01-13 00:08:27,634] {scheduler_job.py:181} INFO - Started process (PID=650) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:27,639] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:27,642] {logging_mixin.py:103} INFO - [2021-01-13 00:08:27,642] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:27,679] {logging_mixin.py:103} INFO - [2021-01-13 00:08:27,675] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:27,683] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:28,399] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.773 seconds
[2021-01-13 00:08:28,466] {scheduler_job.py:181} INFO - Started process (PID=651) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:28,472] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:28,477] {logging_mixin.py:103} INFO - [2021-01-13 00:08:28,476] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:28,512] {logging_mixin.py:103} INFO - [2021-01-13 00:08:28,508] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:28,518] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:29,132] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.684 seconds
[2021-01-13 00:08:29,265] {scheduler_job.py:181} INFO - Started process (PID=652) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:29,379] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:29,427] {logging_mixin.py:103} INFO - [2021-01-13 00:08:29,426] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:29,636] {logging_mixin.py:103} INFO - [2021-01-13 00:08:29,618] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:29,800] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:30,563] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.332 seconds
[2021-01-13 00:08:30,871] {scheduler_job.py:181} INFO - Started process (PID=653) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:30,906] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:30,915] {logging_mixin.py:103} INFO - [2021-01-13 00:08:30,915] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:31,048] {logging_mixin.py:103} INFO - [2021-01-13 00:08:31,027] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:31,056] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:31,708] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.852 seconds
[2021-01-13 00:08:31,810] {scheduler_job.py:181} INFO - Started process (PID=654) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:31,835] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:31,844] {logging_mixin.py:103} INFO - [2021-01-13 00:08:31,841] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:31,967] {logging_mixin.py:103} INFO - [2021-01-13 00:08:31,949] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:31,993] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:32,925] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.131 seconds
[2021-01-13 00:08:33,253] {scheduler_job.py:181} INFO - Started process (PID=655) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:33,304] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:33,312] {logging_mixin.py:103} INFO - [2021-01-13 00:08:33,311] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:33,560] {logging_mixin.py:103} INFO - [2021-01-13 00:08:33,472] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:33,584] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:34,227] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.014 seconds
[2021-01-13 00:08:35,221] {scheduler_job.py:181} INFO - Started process (PID=656) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:35,228] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:35,248] {logging_mixin.py:103} INFO - [2021-01-13 00:08:35,247] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:35,376] {logging_mixin.py:103} INFO - [2021-01-13 00:08:35,370] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:35,429] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:36,404] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.215 seconds
[2021-01-13 00:08:36,820] {scheduler_job.py:181} INFO - Started process (PID=657) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:36,833] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:36,975] {logging_mixin.py:103} INFO - [2021-01-13 00:08:36,845] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:37,315] {logging_mixin.py:103} INFO - [2021-01-13 00:08:37,310] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:37,326] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:38,425] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.662 seconds
[2021-01-13 00:08:39,213] {scheduler_job.py:181} INFO - Started process (PID=658) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:39,315] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:39,354] {logging_mixin.py:103} INFO - [2021-01-13 00:08:39,353] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:39,641] {logging_mixin.py:103} INFO - [2021-01-13 00:08:39,633] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:39,649] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:41,245] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 2.330 seconds
[2021-01-13 00:08:42,001] {scheduler_job.py:181} INFO - Started process (PID=659) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:42,027] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:42,035] {logging_mixin.py:103} INFO - [2021-01-13 00:08:42,034] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:42,871] {logging_mixin.py:103} INFO - [2021-01-13 00:08:42,838] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:42,885] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:43,885] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 2.025 seconds
[2021-01-13 00:08:44,425] {scheduler_job.py:181} INFO - Started process (PID=660) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:44,434] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:44,437] {logging_mixin.py:103} INFO - [2021-01-13 00:08:44,436] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:44,519] {logging_mixin.py:103} INFO - [2021-01-13 00:08:44,516] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:44,530] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:45,295] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.052 seconds
[2021-01-13 00:08:45,550] {scheduler_job.py:181} INFO - Started process (PID=661) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:45,579] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:45,582] {logging_mixin.py:103} INFO - [2021-01-13 00:08:45,582] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:45,839] {logging_mixin.py:103} INFO - [2021-01-13 00:08:45,832] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:45,902] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:46,849] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.381 seconds
[2021-01-13 00:08:47,202] {scheduler_job.py:181} INFO - Started process (PID=662) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:47,208] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:47,288] {logging_mixin.py:103} INFO - [2021-01-13 00:08:47,288] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:47,683] {logging_mixin.py:103} INFO - [2021-01-13 00:08:47,624] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:47,704] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:48,453] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.282 seconds
[2021-01-13 00:08:48,633] {scheduler_job.py:181} INFO - Started process (PID=663) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:48,734] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:48,757] {logging_mixin.py:103} INFO - [2021-01-13 00:08:48,756] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:48,911] {logging_mixin.py:103} INFO - [2021-01-13 00:08:48,904] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:48,924] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:49,625] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.035 seconds
[2021-01-13 00:08:49,770] {scheduler_job.py:181} INFO - Started process (PID=664) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:49,799] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:49,841] {logging_mixin.py:103} INFO - [2021-01-13 00:08:49,841] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:49,917] {logging_mixin.py:103} INFO - [2021-01-13 00:08:49,911] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:49,925] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:50,452] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.694 seconds
[2021-01-13 00:08:50,532] {scheduler_job.py:181} INFO - Started process (PID=665) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:50,537] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:50,543] {logging_mixin.py:103} INFO - [2021-01-13 00:08:50,541] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:50,588] {logging_mixin.py:103} INFO - [2021-01-13 00:08:50,584] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:50,596] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:51,216] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.698 seconds
[2021-01-13 00:08:51,296] {scheduler_job.py:181} INFO - Started process (PID=666) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:51,301] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:51,304] {logging_mixin.py:103} INFO - [2021-01-13 00:08:51,304] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:51,358] {logging_mixin.py:103} INFO - [2021-01-13 00:08:51,349] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:51,363] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:52,083] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.795 seconds
[2021-01-13 00:08:52,147] {scheduler_job.py:181} INFO - Started process (PID=667) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:52,152] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:52,155] {logging_mixin.py:103} INFO - [2021-01-13 00:08:52,155] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:52,196] {logging_mixin.py:103} INFO - [2021-01-13 00:08:52,192] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:52,204] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:52,821] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.681 seconds
[2021-01-13 00:08:52,929] {scheduler_job.py:181} INFO - Started process (PID=668) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:52,934] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:52,937] {logging_mixin.py:103} INFO - [2021-01-13 00:08:52,937] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:53,020] {logging_mixin.py:103} INFO - [2021-01-13 00:08:53,010] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:53,027] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:54,048] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.129 seconds
[2021-01-13 00:08:54,558] {scheduler_job.py:181} INFO - Started process (PID=669) to work on /opt/airflow/dags/example.py
[2021-01-13 00:08:54,562] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:08:54,567] {logging_mixin.py:103} INFO - [2021-01-13 00:08:54,566] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:08:54,639] {logging_mixin.py:103} INFO - [2021-01-13 00:08:54,631] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:08:56,035] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:08:59,425] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 4.881 seconds
[2021-01-13 00:09:00,072] {scheduler_job.py:181} INFO - Started process (PID=670) to work on /opt/airflow/dags/example.py
[2021-01-13 00:09:00,079] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:09:00,087] {logging_mixin.py:103} INFO - [2021-01-13 00:09:00,087] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:09:01,208] {logging_mixin.py:103} INFO - [2021-01-13 00:09:01,197] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:09:01,275] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:09:03,075] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 3.226 seconds
[2021-01-13 00:09:04,495] {scheduler_job.py:181} INFO - Started process (PID=671) to work on /opt/airflow/dags/example.py
[2021-01-13 00:09:04,505] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:09:04,518] {logging_mixin.py:103} INFO - [2021-01-13 00:09:04,518] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:09:05,004] {logging_mixin.py:103} INFO - [2021-01-13 00:09:04,904] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:09:05,063] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:09:06,191] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.831 seconds
[2021-01-13 00:09:07,009] {scheduler_job.py:181} INFO - Started process (PID=672) to work on /opt/airflow/dags/example.py
[2021-01-13 00:09:07,036] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:09:07,044] {logging_mixin.py:103} INFO - [2021-01-13 00:09:07,043] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:09:09,095] {logging_mixin.py:103} INFO - [2021-01-13 00:09:08,809] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:09:09,107] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:09:10,321] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 3.356 seconds
[2021-01-13 00:09:10,565] {scheduler_job.py:181} INFO - Started process (PID=673) to work on /opt/airflow/dags/example.py
[2021-01-13 00:09:10,604] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:09:10,617] {logging_mixin.py:103} INFO - [2021-01-13 00:09:10,616] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:09:11,233] {logging_mixin.py:103} INFO - [2021-01-13 00:09:11,225] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:09:11,411] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:09:12,521] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 2.062 seconds
[2021-01-13 00:09:12,638] {scheduler_job.py:181} INFO - Started process (PID=674) to work on /opt/airflow/dags/example.py
[2021-01-13 00:09:12,660] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:09:12,933] {logging_mixin.py:103} INFO - [2021-01-13 00:09:12,932] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:09:13,087] {logging_mixin.py:103} INFO - [2021-01-13 00:09:13,080] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:09:13,101] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:09:14,070] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.470 seconds
[2021-01-13 00:09:14,534] {scheduler_job.py:181} INFO - Started process (PID=675) to work on /opt/airflow/dags/example.py
[2021-01-13 00:09:14,546] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:09:14,552] {logging_mixin.py:103} INFO - [2021-01-13 00:09:14,552] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:09:14,867] {logging_mixin.py:103} INFO - [2021-01-13 00:09:14,859] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:09:15,162] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:09:16,488] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 2.112 seconds
[2021-01-13 00:09:16,935] {scheduler_job.py:181} INFO - Started process (PID=676) to work on /opt/airflow/dags/example.py
[2021-01-13 00:09:16,953] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:09:16,956] {logging_mixin.py:103} INFO - [2021-01-13 00:09:16,956] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:09:17,606] {logging_mixin.py:103} INFO - [2021-01-13 00:09:17,580] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:09:17,827] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:09:19,027] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 2.154 seconds
[2021-01-13 00:09:19,358] {scheduler_job.py:181} INFO - Started process (PID=677) to work on /opt/airflow/dags/example.py
[2021-01-13 00:09:19,376] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:09:19,571] {logging_mixin.py:103} INFO - [2021-01-13 00:09:19,569] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:09:20,451] {logging_mixin.py:103} INFO - [2021-01-13 00:09:20,404] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:09:20,468] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:09:22,255] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 2.922 seconds
[2021-01-13 00:09:22,572] {scheduler_job.py:181} INFO - Started process (PID=678) to work on /opt/airflow/dags/example.py
[2021-01-13 00:09:22,579] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:09:22,584] {logging_mixin.py:103} INFO - [2021-01-13 00:09:22,583] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:09:22,754] {logging_mixin.py:103} INFO - [2021-01-13 00:09:22,729] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:09:22,792] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:09:23,414] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.863 seconds
[2021-01-13 00:09:23,515] {scheduler_job.py:181} INFO - Started process (PID=679) to work on /opt/airflow/dags/example.py
[2021-01-13 00:09:23,524] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:09:23,542] {logging_mixin.py:103} INFO - [2021-01-13 00:09:23,535] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:09:23,619] {logging_mixin.py:103} INFO - [2021-01-13 00:09:23,615] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:09:23,634] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:09:24,892] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.388 seconds
[2021-01-13 00:09:25,463] {scheduler_job.py:181} INFO - Started process (PID=680) to work on /opt/airflow/dags/example.py
[2021-01-13 00:09:25,479] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:09:25,483] {logging_mixin.py:103} INFO - [2021-01-13 00:09:25,482] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:09:25,904] {logging_mixin.py:103} INFO - [2021-01-13 00:09:25,897] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:09:25,913] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:09:26,627] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.236 seconds
[2021-01-13 00:09:27,109] {scheduler_job.py:181} INFO - Started process (PID=681) to work on /opt/airflow/dags/example.py
[2021-01-13 00:09:27,136] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:09:27,158] {logging_mixin.py:103} INFO - [2021-01-13 00:09:27,157] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:09:27,591] {logging_mixin.py:103} INFO - [2021-01-13 00:09:27,563] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:09:27,610] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:09:28,345] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.260 seconds
[2021-01-13 00:09:28,412] {scheduler_job.py:181} INFO - Started process (PID=682) to work on /opt/airflow/dags/example.py
[2021-01-13 00:09:28,417] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:09:28,422] {logging_mixin.py:103} INFO - [2021-01-13 00:09:28,421] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:09:28,479] {logging_mixin.py:103} INFO - [2021-01-13 00:09:28,474] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:09:28,488] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:09:29,148] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.749 seconds
[2021-01-13 00:09:29,557] {scheduler_job.py:181} INFO - Started process (PID=683) to work on /opt/airflow/dags/example.py
[2021-01-13 00:09:29,567] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:09:29,573] {logging_mixin.py:103} INFO - [2021-01-13 00:09:29,573] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:09:29,630] {logging_mixin.py:103} INFO - [2021-01-13 00:09:29,623] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:09:29,640] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:09:30,573] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.027 seconds
[2021-01-13 00:09:30,865] {scheduler_job.py:181} INFO - Started process (PID=684) to work on /opt/airflow/dags/example.py
[2021-01-13 00:09:30,982] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:09:30,996] {logging_mixin.py:103} INFO - [2021-01-13 00:09:30,996] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:09:31,062] {logging_mixin.py:103} INFO - [2021-01-13 00:09:31,052] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:09:31,088] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:09:31,790] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.976 seconds
[2021-01-13 00:09:31,869] {scheduler_job.py:181} INFO - Started process (PID=685) to work on /opt/airflow/dags/example.py
[2021-01-13 00:09:31,885] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:09:31,896] {logging_mixin.py:103} INFO - [2021-01-13 00:09:31,893] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:09:31,968] {logging_mixin.py:103} INFO - [2021-01-13 00:09:31,962] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:09:32,033] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:09:32,587] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.739 seconds
[2021-01-13 00:09:33,248] {scheduler_job.py:181} INFO - Started process (PID=686) to work on /opt/airflow/dags/example.py
[2021-01-13 00:09:33,271] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:09:33,282] {logging_mixin.py:103} INFO - [2021-01-13 00:09:33,279] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:09:33,939] {logging_mixin.py:103} INFO - [2021-01-13 00:09:33,859] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:09:33,978] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:09:34,652] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.609 seconds
[2021-01-13 00:09:35,190] {scheduler_job.py:181} INFO - Started process (PID=687) to work on /opt/airflow/dags/example.py
[2021-01-13 00:09:35,203] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:09:35,208] {logging_mixin.py:103} INFO - [2021-01-13 00:09:35,208] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:09:35,391] {logging_mixin.py:103} INFO - [2021-01-13 00:09:35,370] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:09:35,412] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:09:37,917] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 2.745 seconds
[2021-01-13 00:09:39,296] {scheduler_job.py:181} INFO - Started process (PID=688) to work on /opt/airflow/dags/example.py
[2021-01-13 00:09:40,449] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:09:42,208] {logging_mixin.py:103} INFO - [2021-01-13 00:09:42,207] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:09:43,910] {logging_mixin.py:103} INFO - [2021-01-13 00:09:43,431] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:09:45,282] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:09:49,172] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 10.011 seconds
[2021-01-13 00:09:52,218] {scheduler_job.py:181} INFO - Started process (PID=689) to work on /opt/airflow/dags/example.py
[2021-01-13 00:09:52,352] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:09:52,364] {logging_mixin.py:103} INFO - [2021-01-13 00:09:52,364] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:09:52,955] {logging_mixin.py:103} INFO - [2021-01-13 00:09:52,916] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:09:53,172] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:09:55,110] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 2.938 seconds
[2021-01-13 00:09:55,857] {scheduler_job.py:181} INFO - Started process (PID=690) to work on /opt/airflow/dags/example.py
[2021-01-13 00:09:55,951] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:09:55,956] {logging_mixin.py:103} INFO - [2021-01-13 00:09:55,956] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:09:56,208] {logging_mixin.py:103} INFO - [2021-01-13 00:09:56,171] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:09:56,221] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:09:57,106] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.379 seconds
[2021-01-13 00:09:57,738] {scheduler_job.py:181} INFO - Started process (PID=691) to work on /opt/airflow/dags/example.py
[2021-01-13 00:09:57,753] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:09:57,760] {logging_mixin.py:103} INFO - [2021-01-13 00:09:57,759] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:09:58,252] {logging_mixin.py:103} INFO - [2021-01-13 00:09:58,152] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:09:58,262] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:09:59,514] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 2.055 seconds
[2021-01-13 00:09:59,681] {scheduler_job.py:181} INFO - Started process (PID=692) to work on /opt/airflow/dags/example.py
[2021-01-13 00:09:59,690] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:09:59,702] {logging_mixin.py:103} INFO - [2021-01-13 00:09:59,698] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:10:00,373] {logging_mixin.py:103} INFO - [2021-01-13 00:10:00,098] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:10:00,387] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:10:02,116] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 2.458 seconds
[2021-01-13 00:10:02,576] {scheduler_job.py:181} INFO - Started process (PID=693) to work on /opt/airflow/dags/example.py
[2021-01-13 00:10:02,878] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:10:02,882] {logging_mixin.py:103} INFO - [2021-01-13 00:10:02,882] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:10:03,163] {logging_mixin.py:103} INFO - [2021-01-13 00:10:03,130] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:10:03,175] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:10:03,968] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.486 seconds
[2021-01-13 00:10:04,258] {scheduler_job.py:181} INFO - Started process (PID=694) to work on /opt/airflow/dags/example.py
[2021-01-13 00:10:04,269] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:10:04,277] {logging_mixin.py:103} INFO - [2021-01-13 00:10:04,276] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:10:04,458] {logging_mixin.py:103} INFO - [2021-01-13 00:10:04,337] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:10:04,558] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:10:05,903] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.784 seconds
[2021-01-13 00:10:06,279] {scheduler_job.py:181} INFO - Started process (PID=695) to work on /opt/airflow/dags/example.py
[2021-01-13 00:10:06,285] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:10:06,291] {logging_mixin.py:103} INFO - [2021-01-13 00:10:06,291] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:10:06,360] {logging_mixin.py:103} INFO - [2021-01-13 00:10:06,350] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:10:06,367] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:10:07,961] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.702 seconds
[2021-01-13 00:10:14,429] {scheduler_job.py:181} INFO - Started process (PID=696) to work on /opt/airflow/dags/example.py
[2021-01-13 00:10:14,458] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:10:14,839] {logging_mixin.py:103} INFO - [2021-01-13 00:10:14,615] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:10:17,209] {logging_mixin.py:103} INFO - [2021-01-13 00:10:17,061] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:10:17,229] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:10:18,428] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 4.358 seconds
[2021-01-13 00:10:19,414] {scheduler_job.py:181} INFO - Started process (PID=697) to work on /opt/airflow/dags/example.py
[2021-01-13 00:10:19,421] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:10:19,425] {logging_mixin.py:103} INFO - [2021-01-13 00:10:19,424] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:10:19,735] {logging_mixin.py:103} INFO - [2021-01-13 00:10:19,728] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:10:19,742] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:10:20,438] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.077 seconds
[2021-01-13 00:10:20,728] {scheduler_job.py:181} INFO - Started process (PID=698) to work on /opt/airflow/dags/example.py
[2021-01-13 00:10:20,734] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:10:20,738] {logging_mixin.py:103} INFO - [2021-01-13 00:10:20,737] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:10:21,101] {logging_mixin.py:103} INFO - [2021-01-13 00:10:21,075] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:10:21,122] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:10:22,277] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.683 seconds
[2021-01-13 00:10:23,031] {scheduler_job.py:181} INFO - Started process (PID=699) to work on /opt/airflow/dags/example.py
[2021-01-13 00:10:23,040] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:10:23,064] {logging_mixin.py:103} INFO - [2021-01-13 00:10:23,064] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:10:23,261] {logging_mixin.py:103} INFO - [2021-01-13 00:10:23,241] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:10:23,274] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:10:24,251] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.275 seconds
[2021-01-13 00:10:24,381] {scheduler_job.py:181} INFO - Started process (PID=700) to work on /opt/airflow/dags/example.py
[2021-01-13 00:10:24,385] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:10:24,389] {logging_mixin.py:103} INFO - [2021-01-13 00:10:24,389] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:10:24,474] {logging_mixin.py:103} INFO - [2021-01-13 00:10:24,470] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:10:24,481] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:10:25,617] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.260 seconds
[2021-01-13 00:10:26,157] {scheduler_job.py:181} INFO - Started process (PID=701) to work on /opt/airflow/dags/example.py
[2021-01-13 00:10:26,161] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:10:26,167] {logging_mixin.py:103} INFO - [2021-01-13 00:10:26,167] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:10:26,362] {logging_mixin.py:103} INFO - [2021-01-13 00:10:26,235] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:10:26,385] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:10:27,160] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.034 seconds
[2021-01-13 00:10:27,215] {scheduler_job.py:181} INFO - Started process (PID=702) to work on /opt/airflow/dags/example.py
[2021-01-13 00:10:27,225] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:10:27,228] {logging_mixin.py:103} INFO - [2021-01-13 00:10:27,227] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:10:27,288] {logging_mixin.py:103} INFO - [2021-01-13 00:10:27,283] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:10:27,298] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:10:28,074] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.857 seconds
[2021-01-13 00:10:28,262] {scheduler_job.py:181} INFO - Started process (PID=703) to work on /opt/airflow/dags/example.py
[2021-01-13 00:10:28,268] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:10:28,273] {logging_mixin.py:103} INFO - [2021-01-13 00:10:28,273] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:10:28,337] {logging_mixin.py:103} INFO - [2021-01-13 00:10:28,328] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:10:28,342] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:10:29,132] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.887 seconds
[2021-01-13 00:10:29,208] {scheduler_job.py:181} INFO - Started process (PID=704) to work on /opt/airflow/dags/example.py
[2021-01-13 00:10:29,221] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:10:29,231] {logging_mixin.py:103} INFO - [2021-01-13 00:10:29,230] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:10:29,287] {logging_mixin.py:103} INFO - [2021-01-13 00:10:29,280] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:10:29,296] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:10:29,897] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.700 seconds
[2021-01-13 00:10:29,975] {scheduler_job.py:181} INFO - Started process (PID=705) to work on /opt/airflow/dags/example.py
[2021-01-13 00:10:29,981] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:10:29,987] {logging_mixin.py:103} INFO - [2021-01-13 00:10:29,987] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:10:30,029] {logging_mixin.py:103} INFO - [2021-01-13 00:10:30,024] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:10:30,034] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:10:30,615] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.647 seconds
[2021-01-13 00:10:30,683] {scheduler_job.py:181} INFO - Started process (PID=706) to work on /opt/airflow/dags/example.py
[2021-01-13 00:10:30,687] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:10:30,690] {logging_mixin.py:103} INFO - [2021-01-13 00:10:30,690] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:10:30,782] {logging_mixin.py:103} INFO - [2021-01-13 00:10:30,774] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:10:30,795] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:10:31,390] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.715 seconds
[2021-01-13 00:10:31,462] {scheduler_job.py:181} INFO - Started process (PID=707) to work on /opt/airflow/dags/example.py
[2021-01-13 00:10:31,469] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:10:31,473] {logging_mixin.py:103} INFO - [2021-01-13 00:10:31,473] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:10:31,553] {logging_mixin.py:103} INFO - [2021-01-13 00:10:31,549] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:10:31,559] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:10:32,199] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.750 seconds
[2021-01-13 00:10:32,302] {scheduler_job.py:181} INFO - Started process (PID=708) to work on /opt/airflow/dags/example.py
[2021-01-13 00:10:32,308] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:10:32,319] {logging_mixin.py:103} INFO - [2021-01-13 00:10:32,319] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:10:32,440] {logging_mixin.py:103} INFO - [2021-01-13 00:10:32,430] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:10:32,453] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:10:33,195] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.902 seconds
[2021-01-13 00:10:33,315] {scheduler_job.py:181} INFO - Started process (PID=709) to work on /opt/airflow/dags/example.py
[2021-01-13 00:10:33,320] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:10:33,330] {logging_mixin.py:103} INFO - [2021-01-13 00:10:33,329] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:10:33,384] {logging_mixin.py:103} INFO - [2021-01-13 00:10:33,379] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:10:33,403] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:10:34,608] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.307 seconds
[2021-01-13 00:10:34,998] {scheduler_job.py:181} INFO - Started process (PID=710) to work on /opt/airflow/dags/example.py
[2021-01-13 00:10:35,021] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:10:35,029] {logging_mixin.py:103} INFO - [2021-01-13 00:10:35,028] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:10:35,098] {logging_mixin.py:103} INFO - [2021-01-13 00:10:35,092] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:10:35,107] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:10:35,970] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.006 seconds
[2021-01-13 00:10:36,101] {scheduler_job.py:181} INFO - Started process (PID=711) to work on /opt/airflow/dags/example.py
[2021-01-13 00:10:36,110] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:10:36,117] {logging_mixin.py:103} INFO - [2021-01-13 00:10:36,116] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:10:36,174] {logging_mixin.py:103} INFO - [2021-01-13 00:10:36,168] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:10:36,183] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:10:36,812] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.735 seconds
[2021-01-13 00:10:37,185] {scheduler_job.py:181} INFO - Started process (PID=712) to work on /opt/airflow/dags/example.py
[2021-01-13 00:10:37,301] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:10:37,343] {logging_mixin.py:103} INFO - [2021-01-13 00:10:37,343] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:10:37,530] {logging_mixin.py:103} INFO - [2021-01-13 00:10:37,525] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:10:37,539] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:10:38,136] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.975 seconds
[2021-01-13 00:10:38,963] {scheduler_job.py:181} INFO - Started process (PID=713) to work on /opt/airflow/dags/example.py
[2021-01-13 00:10:38,974] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:10:38,999] {logging_mixin.py:103} INFO - [2021-01-13 00:10:38,998] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:10:39,089] {logging_mixin.py:103} INFO - [2021-01-13 00:10:39,084] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:10:39,099] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:10:39,744] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.795 seconds
[2021-01-13 00:10:39,841] {scheduler_job.py:181} INFO - Started process (PID=714) to work on /opt/airflow/dags/example.py
[2021-01-13 00:10:39,844] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:10:39,848] {logging_mixin.py:103} INFO - [2021-01-13 00:10:39,848] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:10:39,900] {logging_mixin.py:103} INFO - [2021-01-13 00:10:39,893] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:10:39,904] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:10:40,461] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.627 seconds
[2021-01-13 00:10:40,591] {scheduler_job.py:181} INFO - Started process (PID=715) to work on /opt/airflow/dags/example.py
[2021-01-13 00:10:40,600] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:10:40,603] {logging_mixin.py:103} INFO - [2021-01-13 00:10:40,603] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:10:40,639] {logging_mixin.py:103} INFO - [2021-01-13 00:10:40,636] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:10:40,832] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:10:41,436] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.881 seconds
[2021-01-13 00:10:41,497] {scheduler_job.py:181} INFO - Started process (PID=716) to work on /opt/airflow/dags/example.py
[2021-01-13 00:10:41,501] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:10:41,506] {logging_mixin.py:103} INFO - [2021-01-13 00:10:41,505] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:10:41,574] {logging_mixin.py:103} INFO - [2021-01-13 00:10:41,570] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:10:41,581] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:10:42,135] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.651 seconds
[2021-01-13 00:10:42,293] {scheduler_job.py:181} INFO - Started process (PID=717) to work on /opt/airflow/dags/example.py
[2021-01-13 00:10:42,303] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:10:42,308] {logging_mixin.py:103} INFO - [2021-01-13 00:10:42,307] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:10:42,367] {logging_mixin.py:103} INFO - [2021-01-13 00:10:42,357] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:10:42,390] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:10:44,643] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 2.375 seconds
[2021-01-13 00:10:44,954] {scheduler_job.py:181} INFO - Started process (PID=718) to work on /opt/airflow/dags/example.py
[2021-01-13 00:10:44,974] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:10:44,989] {logging_mixin.py:103} INFO - [2021-01-13 00:10:44,986] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:10:45,216] {logging_mixin.py:103} INFO - [2021-01-13 00:10:45,212] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:10:45,250] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:10:45,868] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.934 seconds
[2021-01-13 00:10:45,945] {scheduler_job.py:181} INFO - Started process (PID=719) to work on /opt/airflow/dags/example.py
[2021-01-13 00:10:45,958] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:10:45,980] {logging_mixin.py:103} INFO - [2021-01-13 00:10:45,980] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:10:46,090] {logging_mixin.py:103} INFO - [2021-01-13 00:10:46,061] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:10:46,111] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:10:46,619] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.693 seconds
[2021-01-13 00:10:46,684] {scheduler_job.py:181} INFO - Started process (PID=720) to work on /opt/airflow/dags/example.py
[2021-01-13 00:10:46,697] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:10:46,704] {logging_mixin.py:103} INFO - [2021-01-13 00:10:46,704] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:10:46,765] {logging_mixin.py:103} INFO - [2021-01-13 00:10:46,755] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:10:46,779] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:10:47,370] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.705 seconds
[2021-01-13 00:10:47,440] {scheduler_job.py:181} INFO - Started process (PID=721) to work on /opt/airflow/dags/example.py
[2021-01-13 00:10:47,452] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:10:47,463] {logging_mixin.py:103} INFO - [2021-01-13 00:10:47,462] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:10:47,514] {logging_mixin.py:103} INFO - [2021-01-13 00:10:47,505] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:10:47,523] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:10:48,120] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.697 seconds
[2021-01-13 00:10:48,186] {scheduler_job.py:181} INFO - Started process (PID=722) to work on /opt/airflow/dags/example.py
[2021-01-13 00:10:48,190] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:10:48,197] {logging_mixin.py:103} INFO - [2021-01-13 00:10:48,196] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:10:48,250] {logging_mixin.py:103} INFO - [2021-01-13 00:10:48,244] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:10:48,256] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:10:48,825] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.659 seconds
[2021-01-13 00:10:48,913] {scheduler_job.py:181} INFO - Started process (PID=723) to work on /opt/airflow/dags/example.py
[2021-01-13 00:10:48,918] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:10:48,925] {logging_mixin.py:103} INFO - [2021-01-13 00:10:48,924] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:10:49,000] {logging_mixin.py:103} INFO - [2021-01-13 00:10:48,994] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:10:49,007] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:10:49,600] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.699 seconds
[2021-01-13 00:10:49,940] {scheduler_job.py:181} INFO - Started process (PID=724) to work on /opt/airflow/dags/example.py
[2021-01-13 00:10:49,974] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:10:49,987] {logging_mixin.py:103} INFO - [2021-01-13 00:10:49,986] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:10:50,051] {logging_mixin.py:103} INFO - [2021-01-13 00:10:50,042] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:10:50,066] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:10:50,613] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.722 seconds
[2021-01-13 00:10:50,677] {scheduler_job.py:181} INFO - Started process (PID=725) to work on /opt/airflow/dags/example.py
[2021-01-13 00:10:50,681] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:10:50,683] {logging_mixin.py:103} INFO - [2021-01-13 00:10:50,683] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:10:50,766] {logging_mixin.py:103} INFO - [2021-01-13 00:10:50,756] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:10:50,775] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:10:51,326] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.658 seconds
[2021-01-13 00:10:51,373] {scheduler_job.py:181} INFO - Started process (PID=726) to work on /opt/airflow/dags/example.py
[2021-01-13 00:10:51,377] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:10:51,381] {logging_mixin.py:103} INFO - [2021-01-13 00:10:51,380] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:10:51,420] {logging_mixin.py:103} INFO - [2021-01-13 00:10:51,416] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:10:51,425] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:10:52,135] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.769 seconds
[2021-01-13 00:10:52,183] {scheduler_job.py:181} INFO - Started process (PID=727) to work on /opt/airflow/dags/example.py
[2021-01-13 00:10:52,187] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:10:52,190] {logging_mixin.py:103} INFO - [2021-01-13 00:10:52,190] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:10:52,227] {logging_mixin.py:103} INFO - [2021-01-13 00:10:52,223] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:10:52,232] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:10:52,721] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.546 seconds
[2021-01-13 00:10:52,783] {scheduler_job.py:181} INFO - Started process (PID=728) to work on /opt/airflow/dags/example.py
[2021-01-13 00:10:52,790] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:10:52,796] {logging_mixin.py:103} INFO - [2021-01-13 00:10:52,795] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:10:52,844] {logging_mixin.py:103} INFO - [2021-01-13 00:10:52,841] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:10:52,874] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:10:53,475] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.708 seconds
[2021-01-13 00:10:53,536] {scheduler_job.py:181} INFO - Started process (PID=729) to work on /opt/airflow/dags/example.py
[2021-01-13 00:10:53,544] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:10:53,551] {logging_mixin.py:103} INFO - [2021-01-13 00:10:53,550] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:10:53,589] {logging_mixin.py:103} INFO - [2021-01-13 00:10:53,584] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:10:53,594] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:10:54,366] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.843 seconds
[2021-01-13 00:10:54,428] {scheduler_job.py:181} INFO - Started process (PID=730) to work on /opt/airflow/dags/example.py
[2021-01-13 00:10:54,439] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:10:54,442] {logging_mixin.py:103} INFO - [2021-01-13 00:10:54,441] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:10:54,495] {logging_mixin.py:103} INFO - [2021-01-13 00:10:54,489] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:10:54,508] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:10:55,169] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.750 seconds
[2021-01-13 00:10:55,234] {scheduler_job.py:181} INFO - Started process (PID=731) to work on /opt/airflow/dags/example.py
[2021-01-13 00:10:55,239] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:10:55,242] {logging_mixin.py:103} INFO - [2021-01-13 00:10:55,242] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:10:55,309] {logging_mixin.py:103} INFO - [2021-01-13 00:10:55,301] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:10:55,319] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:10:57,892] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 2.667 seconds
[2021-01-13 00:10:58,281] {scheduler_job.py:181} INFO - Started process (PID=732) to work on /opt/airflow/dags/example.py
[2021-01-13 00:10:58,328] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:10:58,338] {logging_mixin.py:103} INFO - [2021-01-13 00:10:58,336] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:10:58,393] {logging_mixin.py:103} INFO - [2021-01-13 00:10:58,386] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:10:58,398] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:10:59,250] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.039 seconds
[2021-01-13 00:10:59,370] {scheduler_job.py:181} INFO - Started process (PID=733) to work on /opt/airflow/dags/example.py
[2021-01-13 00:10:59,373] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:10:59,376] {logging_mixin.py:103} INFO - [2021-01-13 00:10:59,375] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:10:59,407] {logging_mixin.py:103} INFO - [2021-01-13 00:10:59,403] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:10:59,411] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:00,338] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.975 seconds
[2021-01-13 00:11:00,698] {scheduler_job.py:181} INFO - Started process (PID=734) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:00,734] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:00,740] {logging_mixin.py:103} INFO - [2021-01-13 00:11:00,739] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:00,913] {logging_mixin.py:103} INFO - [2021-01-13 00:11:00,904] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:00,977] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:01,576] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.886 seconds
[2021-01-13 00:11:01,646] {scheduler_job.py:181} INFO - Started process (PID=735) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:01,654] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:01,701] {logging_mixin.py:103} INFO - [2021-01-13 00:11:01,700] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:01,835] {logging_mixin.py:103} INFO - [2021-01-13 00:11:01,812] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:01,867] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:03,203] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.566 seconds
[2021-01-13 00:11:03,607] {scheduler_job.py:181} INFO - Started process (PID=736) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:03,625] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:03,638] {logging_mixin.py:103} INFO - [2021-01-13 00:11:03,637] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:03,799] {logging_mixin.py:103} INFO - [2021-01-13 00:11:03,769] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:03,819] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:04,534] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.939 seconds
[2021-01-13 00:11:04,658] {scheduler_job.py:181} INFO - Started process (PID=737) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:04,720] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:04,764] {logging_mixin.py:103} INFO - [2021-01-13 00:11:04,763] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:05,032] {logging_mixin.py:103} INFO - [2021-01-13 00:11:05,016] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:05,244] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:05,774] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.142 seconds
[2021-01-13 00:11:05,853] {scheduler_job.py:181} INFO - Started process (PID=738) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:05,857] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:05,860] {logging_mixin.py:103} INFO - [2021-01-13 00:11:05,860] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:05,909] {logging_mixin.py:103} INFO - [2021-01-13 00:11:05,906] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:05,914] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:06,502] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.669 seconds
[2021-01-13 00:11:06,565] {scheduler_job.py:181} INFO - Started process (PID=739) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:06,571] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:06,576] {logging_mixin.py:103} INFO - [2021-01-13 00:11:06,575] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:06,620] {logging_mixin.py:103} INFO - [2021-01-13 00:11:06,615] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:06,632] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:07,311] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.758 seconds
[2021-01-13 00:11:07,352] {scheduler_job.py:181} INFO - Started process (PID=740) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:07,355] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:07,360] {logging_mixin.py:103} INFO - [2021-01-13 00:11:07,359] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:07,406] {logging_mixin.py:103} INFO - [2021-01-13 00:11:07,400] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:07,416] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:07,946] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.602 seconds
[2021-01-13 00:11:07,992] {scheduler_job.py:181} INFO - Started process (PID=741) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:07,999] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:08,004] {logging_mixin.py:103} INFO - [2021-01-13 00:11:08,004] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:08,055] {logging_mixin.py:103} INFO - [2021-01-13 00:11:08,040] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:08,061] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:08,601] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.618 seconds
[2021-01-13 00:11:08,672] {scheduler_job.py:181} INFO - Started process (PID=742) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:08,682] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:08,686] {logging_mixin.py:103} INFO - [2021-01-13 00:11:08,685] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:08,729] {logging_mixin.py:103} INFO - [2021-01-13 00:11:08,724] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:08,736] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:09,259] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.610 seconds
[2021-01-13 00:11:09,489] {scheduler_job.py:181} INFO - Started process (PID=743) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:09,496] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:09,501] {logging_mixin.py:103} INFO - [2021-01-13 00:11:09,501] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:09,546] {logging_mixin.py:103} INFO - [2021-01-13 00:11:09,541] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:09,556] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:10,111] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.635 seconds
[2021-01-13 00:11:10,186] {scheduler_job.py:181} INFO - Started process (PID=744) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:10,199] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:10,205] {logging_mixin.py:103} INFO - [2021-01-13 00:11:10,204] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:10,246] {logging_mixin.py:103} INFO - [2021-01-13 00:11:10,241] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:10,251] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:10,749] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.578 seconds
[2021-01-13 00:11:10,830] {scheduler_job.py:181} INFO - Started process (PID=745) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:10,836] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:10,844] {logging_mixin.py:103} INFO - [2021-01-13 00:11:10,844] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:10,891] {logging_mixin.py:103} INFO - [2021-01-13 00:11:10,880] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:10,930] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:11,500] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.681 seconds
[2021-01-13 00:11:11,559] {scheduler_job.py:181} INFO - Started process (PID=746) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:11,566] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:11,573] {logging_mixin.py:103} INFO - [2021-01-13 00:11:11,572] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:11,624] {logging_mixin.py:103} INFO - [2021-01-13 00:11:11,618] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:11,633] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:12,284] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.737 seconds
[2021-01-13 00:11:12,341] {scheduler_job.py:181} INFO - Started process (PID=747) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:12,344] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:12,350] {logging_mixin.py:103} INFO - [2021-01-13 00:11:12,350] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:12,383] {logging_mixin.py:103} INFO - [2021-01-13 00:11:12,380] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:12,389] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:12,928] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.596 seconds
[2021-01-13 00:11:12,987] {scheduler_job.py:181} INFO - Started process (PID=748) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:12,995] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:13,000] {logging_mixin.py:103} INFO - [2021-01-13 00:11:12,999] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:13,048] {logging_mixin.py:103} INFO - [2021-01-13 00:11:13,044] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:13,053] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:13,586] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.613 seconds
[2021-01-13 00:11:13,647] {scheduler_job.py:181} INFO - Started process (PID=749) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:13,651] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:13,654] {logging_mixin.py:103} INFO - [2021-01-13 00:11:13,653] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:13,682] {logging_mixin.py:103} INFO - [2021-01-13 00:11:13,678] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:13,698] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:14,294] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.653 seconds
[2021-01-13 00:11:14,352] {scheduler_job.py:181} INFO - Started process (PID=750) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:14,358] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:14,363] {logging_mixin.py:103} INFO - [2021-01-13 00:11:14,362] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:14,420] {logging_mixin.py:103} INFO - [2021-01-13 00:11:14,412] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:14,443] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:14,956] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.609 seconds
[2021-01-13 00:11:15,016] {scheduler_job.py:181} INFO - Started process (PID=751) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:15,020] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:15,023] {logging_mixin.py:103} INFO - [2021-01-13 00:11:15,022] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:15,065] {logging_mixin.py:103} INFO - [2021-01-13 00:11:15,060] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:15,072] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:15,598] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.589 seconds
[2021-01-13 00:11:15,663] {scheduler_job.py:181} INFO - Started process (PID=752) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:15,670] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:15,679] {logging_mixin.py:103} INFO - [2021-01-13 00:11:15,677] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:15,723] {logging_mixin.py:103} INFO - [2021-01-13 00:11:15,716] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:15,728] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:16,304] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.654 seconds
[2021-01-13 00:11:16,357] {scheduler_job.py:181} INFO - Started process (PID=753) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:16,361] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:16,364] {logging_mixin.py:103} INFO - [2021-01-13 00:11:16,364] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:16,400] {logging_mixin.py:103} INFO - [2021-01-13 00:11:16,396] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:16,406] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:16,906] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.591 seconds
[2021-01-13 00:11:16,957] {scheduler_job.py:181} INFO - Started process (PID=754) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:16,961] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:16,963] {logging_mixin.py:103} INFO - [2021-01-13 00:11:16,963] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:16,988] {logging_mixin.py:103} INFO - [2021-01-13 00:11:16,985] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:16,992] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:17,487] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.539 seconds
[2021-01-13 00:11:17,539] {scheduler_job.py:181} INFO - Started process (PID=755) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:17,544] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:17,548] {logging_mixin.py:103} INFO - [2021-01-13 00:11:17,548] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:17,588] {logging_mixin.py:103} INFO - [2021-01-13 00:11:17,585] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:17,597] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:18,208] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.674 seconds
[2021-01-13 00:11:18,268] {scheduler_job.py:181} INFO - Started process (PID=756) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:18,276] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:18,282] {logging_mixin.py:103} INFO - [2021-01-13 00:11:18,281] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:18,319] {logging_mixin.py:103} INFO - [2021-01-13 00:11:18,314] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:18,324] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:18,948] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.691 seconds
[2021-01-13 00:11:19,036] {scheduler_job.py:181} INFO - Started process (PID=757) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:19,043] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:19,049] {logging_mixin.py:103} INFO - [2021-01-13 00:11:19,049] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:19,100] {logging_mixin.py:103} INFO - [2021-01-13 00:11:19,098] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:19,104] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:19,828] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.803 seconds
[2021-01-13 00:11:20,165] {scheduler_job.py:181} INFO - Started process (PID=758) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:20,181] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:20,188] {logging_mixin.py:103} INFO - [2021-01-13 00:11:20,188] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:20,482] {logging_mixin.py:103} INFO - [2021-01-13 00:11:20,476] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:20,487] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:21,242] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.104 seconds
[2021-01-13 00:11:21,300] {scheduler_job.py:181} INFO - Started process (PID=759) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:21,306] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:21,309] {logging_mixin.py:103} INFO - [2021-01-13 00:11:21,309] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:21,342] {logging_mixin.py:103} INFO - [2021-01-13 00:11:21,338] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:21,348] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:22,179] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.890 seconds
[2021-01-13 00:11:22,232] {scheduler_job.py:181} INFO - Started process (PID=760) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:22,238] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:22,241] {logging_mixin.py:103} INFO - [2021-01-13 00:11:22,241] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:22,275] {logging_mixin.py:103} INFO - [2021-01-13 00:11:22,273] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:22,283] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:22,823] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.600 seconds
[2021-01-13 00:11:22,878] {scheduler_job.py:181} INFO - Started process (PID=761) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:22,888] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:22,891] {logging_mixin.py:103} INFO - [2021-01-13 00:11:22,890] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:22,953] {logging_mixin.py:103} INFO - [2021-01-13 00:11:22,948] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:22,958] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:23,496] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.626 seconds
[2021-01-13 00:11:23,560] {scheduler_job.py:181} INFO - Started process (PID=762) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:23,564] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:23,568] {logging_mixin.py:103} INFO - [2021-01-13 00:11:23,568] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:23,606] {logging_mixin.py:103} INFO - [2021-01-13 00:11:23,602] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:23,611] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:24,168] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.620 seconds
[2021-01-13 00:11:24,245] {scheduler_job.py:181} INFO - Started process (PID=763) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:24,306] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:24,313] {logging_mixin.py:103} INFO - [2021-01-13 00:11:24,313] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:24,344] {logging_mixin.py:103} INFO - [2021-01-13 00:11:24,342] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:24,353] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:24,994] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.757 seconds
[2021-01-13 00:11:25,108] {scheduler_job.py:181} INFO - Started process (PID=764) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:25,114] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:25,123] {logging_mixin.py:103} INFO - [2021-01-13 00:11:25,122] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:25,163] {logging_mixin.py:103} INFO - [2021-01-13 00:11:25,158] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:25,179] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:26,320] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 1.216 seconds
[2021-01-13 00:11:26,397] {scheduler_job.py:181} INFO - Started process (PID=765) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:26,402] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:26,405] {logging_mixin.py:103} INFO - [2021-01-13 00:11:26,404] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:26,478] {logging_mixin.py:103} INFO - [2021-01-13 00:11:26,462] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:26,488] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:27,104] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.720 seconds
[2021-01-13 00:11:27,179] {scheduler_job.py:181} INFO - Started process (PID=766) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:27,184] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:27,188] {logging_mixin.py:103} INFO - [2021-01-13 00:11:27,188] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:27,225] {logging_mixin.py:103} INFO - [2021-01-13 00:11:27,220] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:27,230] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:27,773] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.604 seconds
[2021-01-13 00:11:27,830] {scheduler_job.py:181} INFO - Started process (PID=767) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:27,843] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:27,847] {logging_mixin.py:103} INFO - [2021-01-13 00:11:27,847] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:27,893] {logging_mixin.py:103} INFO - [2021-01-13 00:11:27,888] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:27,900] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:28,454] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.637 seconds
[2021-01-13 00:11:28,517] {scheduler_job.py:181} INFO - Started process (PID=768) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:28,526] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:28,531] {logging_mixin.py:103} INFO - [2021-01-13 00:11:28,531] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:28,582] {logging_mixin.py:103} INFO - [2021-01-13 00:11:28,575] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:28,590] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:29,227] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.719 seconds
[2021-01-13 00:11:29,289] {scheduler_job.py:181} INFO - Started process (PID=769) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:29,298] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:29,304] {logging_mixin.py:103} INFO - [2021-01-13 00:11:29,303] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:29,344] {logging_mixin.py:103} INFO - [2021-01-13 00:11:29,339] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:29,351] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:29,912] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.636 seconds
[2021-01-13 00:11:30,188] {scheduler_job.py:181} INFO - Started process (PID=770) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:30,194] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:30,201] {logging_mixin.py:103} INFO - [2021-01-13 00:11:30,200] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:30,257] {logging_mixin.py:103} INFO - [2021-01-13 00:11:30,251] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:30,267] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:30,886] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.714 seconds
[2021-01-13 00:11:30,944] {scheduler_job.py:181} INFO - Started process (PID=771) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:30,948] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:30,951] {logging_mixin.py:103} INFO - [2021-01-13 00:11:30,951] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:30,989] {logging_mixin.py:103} INFO - [2021-01-13 00:11:30,985] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:30,994] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:31,537] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.602 seconds
[2021-01-13 00:11:31,579] {scheduler_job.py:181} INFO - Started process (PID=772) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:31,582] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:31,586] {logging_mixin.py:103} INFO - [2021-01-13 00:11:31,585] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:31,617] {logging_mixin.py:103} INFO - [2021-01-13 00:11:31,613] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:31,622] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:32,140] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.568 seconds
[2021-01-13 00:11:32,189] {scheduler_job.py:181} INFO - Started process (PID=773) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:32,193] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:32,197] {logging_mixin.py:103} INFO - [2021-01-13 00:11:32,197] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:32,230] {logging_mixin.py:103} INFO - [2021-01-13 00:11:32,225] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:32,234] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:32,728] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.547 seconds
[2021-01-13 00:11:32,837] {scheduler_job.py:181} INFO - Started process (PID=774) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:32,842] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:32,852] {logging_mixin.py:103} INFO - [2021-01-13 00:11:32,851] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:32,893] {logging_mixin.py:103} INFO - [2021-01-13 00:11:32,890] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:32,903] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:33,476] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.652 seconds
[2021-01-13 00:11:33,529] {scheduler_job.py:181} INFO - Started process (PID=775) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:33,533] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:33,538] {logging_mixin.py:103} INFO - [2021-01-13 00:11:33,538] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:33,564] {logging_mixin.py:103} INFO - [2021-01-13 00:11:33,561] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:33,569] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:34,291] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.768 seconds
[2021-01-13 00:11:34,334] {scheduler_job.py:181} INFO - Started process (PID=776) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:34,338] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:34,341] {logging_mixin.py:103} INFO - [2021-01-13 00:11:34,341] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:34,369] {logging_mixin.py:103} INFO - [2021-01-13 00:11:34,366] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:34,373] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:35,063] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.736 seconds
[2021-01-13 00:11:35,130] {scheduler_job.py:181} INFO - Started process (PID=777) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:35,142] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:35,146] {logging_mixin.py:103} INFO - [2021-01-13 00:11:35,145] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:35,191] {logging_mixin.py:103} INFO - [2021-01-13 00:11:35,179] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:35,207] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:35,828] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.710 seconds
[2021-01-13 00:11:35,889] {scheduler_job.py:181} INFO - Started process (PID=778) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:35,896] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:35,898] {logging_mixin.py:103} INFO - [2021-01-13 00:11:35,898] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:35,941] {logging_mixin.py:103} INFO - [2021-01-13 00:11:35,937] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:35,948] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:36,575] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.692 seconds
[2021-01-13 00:11:36,626] {scheduler_job.py:181} INFO - Started process (PID=779) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:36,631] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:36,634] {logging_mixin.py:103} INFO - [2021-01-13 00:11:36,633] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:36,715] {logging_mixin.py:103} INFO - [2021-01-13 00:11:36,663] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:36,742] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:37,433] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.813 seconds
[2021-01-13 00:11:37,523] {scheduler_job.py:181} INFO - Started process (PID=780) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:37,532] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:37,535] {logging_mixin.py:103} INFO - [2021-01-13 00:11:37,535] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:37,572] {logging_mixin.py:103} INFO - [2021-01-13 00:11:37,567] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:37,580] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:38,231] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.715 seconds
[2021-01-13 00:11:38,285] {scheduler_job.py:181} INFO - Started process (PID=781) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:38,295] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:38,304] {logging_mixin.py:103} INFO - [2021-01-13 00:11:38,303] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:38,345] {logging_mixin.py:103} INFO - [2021-01-13 00:11:38,340] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:38,355] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:38,978] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.705 seconds
[2021-01-13 00:11:39,034] {scheduler_job.py:181} INFO - Started process (PID=782) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:39,044] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:39,048] {logging_mixin.py:103} INFO - [2021-01-13 00:11:39,047] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:39,078] {logging_mixin.py:103} INFO - [2021-01-13 00:11:39,075] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:39,088] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:39,587] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.563 seconds
[2021-01-13 00:11:39,629] {scheduler_job.py:181} INFO - Started process (PID=783) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:39,633] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:39,636] {logging_mixin.py:103} INFO - [2021-01-13 00:11:39,635] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:39,666] {logging_mixin.py:103} INFO - [2021-01-13 00:11:39,663] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:39,680] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:40,430] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.807 seconds
[2021-01-13 00:11:40,664] {scheduler_job.py:181} INFO - Started process (PID=784) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:40,667] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:40,677] {logging_mixin.py:103} INFO - [2021-01-13 00:11:40,676] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:40,721] {logging_mixin.py:103} INFO - [2021-01-13 00:11:40,713] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:40,727] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:41,276] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.621 seconds
[2021-01-13 00:11:41,330] {scheduler_job.py:181} INFO - Started process (PID=785) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:41,337] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:41,345] {logging_mixin.py:103} INFO - [2021-01-13 00:11:41,344] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:41,393] {logging_mixin.py:103} INFO - [2021-01-13 00:11:41,386] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:41,407] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:42,119] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.801 seconds
[2021-01-13 00:11:42,168] {scheduler_job.py:181} INFO - Started process (PID=786) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:42,171] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:42,175] {logging_mixin.py:103} INFO - [2021-01-13 00:11:42,174] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:42,200] {logging_mixin.py:103} INFO - [2021-01-13 00:11:42,197] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:42,204] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:42,847] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.687 seconds
[2021-01-13 00:11:42,910] {scheduler_job.py:181} INFO - Started process (PID=787) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:42,916] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:42,918] {logging_mixin.py:103} INFO - [2021-01-13 00:11:42,918] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:42,948] {logging_mixin.py:103} INFO - [2021-01-13 00:11:42,944] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:42,953] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:43,558] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.660 seconds
[2021-01-13 00:11:43,605] {scheduler_job.py:181} INFO - Started process (PID=788) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:43,609] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:43,613] {logging_mixin.py:103} INFO - [2021-01-13 00:11:43,613] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:43,645] {logging_mixin.py:103} INFO - [2021-01-13 00:11:43,641] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:43,651] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:44,236] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.641 seconds
[2021-01-13 00:11:44,338] {scheduler_job.py:181} INFO - Started process (PID=789) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:44,351] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:44,358] {logging_mixin.py:103} INFO - [2021-01-13 00:11:44,358] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:44,510] {logging_mixin.py:103} INFO - [2021-01-13 00:11:44,504] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:44,523] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:45,268] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.945 seconds
[2021-01-13 00:11:45,326] {scheduler_job.py:181} INFO - Started process (PID=790) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:45,330] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:45,334] {logging_mixin.py:103} INFO - [2021-01-13 00:11:45,334] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:45,370] {logging_mixin.py:103} INFO - [2021-01-13 00:11:45,367] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:45,374] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:45,936] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.616 seconds
[2021-01-13 00:11:45,989] {scheduler_job.py:181} INFO - Started process (PID=791) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:45,994] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:45,998] {logging_mixin.py:103} INFO - [2021-01-13 00:11:45,998] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:46,026] {logging_mixin.py:103} INFO - [2021-01-13 00:11:46,023] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:46,031] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:46,532] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.586 seconds
[2021-01-13 00:11:46,593] {scheduler_job.py:181} INFO - Started process (PID=792) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:46,598] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:46,603] {logging_mixin.py:103} INFO - [2021-01-13 00:11:46,603] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:46,640] {logging_mixin.py:103} INFO - [2021-01-13 00:11:46,635] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:46,650] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:47,150] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.566 seconds
[2021-01-13 00:11:47,210] {scheduler_job.py:181} INFO - Started process (PID=793) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:47,218] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:47,222] {logging_mixin.py:103} INFO - [2021-01-13 00:11:47,221] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:47,259] {logging_mixin.py:103} INFO - [2021-01-13 00:11:47,254] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:47,263] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:47,785] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.588 seconds
[2021-01-13 00:11:47,844] {scheduler_job.py:181} INFO - Started process (PID=794) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:47,847] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:47,857] {logging_mixin.py:103} INFO - [2021-01-13 00:11:47,852] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:47,889] {logging_mixin.py:103} INFO - [2021-01-13 00:11:47,886] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:47,902] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:48,488] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.650 seconds
[2021-01-13 00:11:48,538] {scheduler_job.py:181} INFO - Started process (PID=795) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:48,541] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:48,545] {logging_mixin.py:103} INFO - [2021-01-13 00:11:48,545] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:48,584] {logging_mixin.py:103} INFO - [2021-01-13 00:11:48,579] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:48,592] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:49,180] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.652 seconds
[2021-01-13 00:11:49,235] {scheduler_job.py:181} INFO - Started process (PID=796) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:49,241] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:49,249] {logging_mixin.py:103} INFO - [2021-01-13 00:11:49,249] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:49,290] {logging_mixin.py:103} INFO - [2021-01-13 00:11:49,282] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:49,300] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:49,822] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.595 seconds
[2021-01-13 00:11:49,977] {scheduler_job.py:181} INFO - Started process (PID=797) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:49,991] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:49,995] {logging_mixin.py:103} INFO - [2021-01-13 00:11:49,995] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:50,037] {logging_mixin.py:103} INFO - [2021-01-13 00:11:50,033] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:50,043] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:11:50,657] {scheduler_job.py:189} INFO - Processing /opt/airflow/dags/example.py took 0.687 seconds
[2021-01-13 00:11:50,829] {scheduler_job.py:181} INFO - Started process (PID=798) to work on /opt/airflow/dags/example.py
[2021-01-13 00:11:50,833] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:11:50,837] {logging_mixin.py:103} INFO - [2021-01-13 00:11:50,836] {dagbag.py:440} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:11:50,875] {logging_mixin.py:103} INFO - [2021-01-13 00:11:50,872] {dagbag.py:297} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 294, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts.test'
[2021-01-13 00:11:50,881] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:03,631] {scheduler_job.py:155} INFO - Started process (PID=15) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:03,639] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:03,641] {logging_mixin.py:112} INFO - [2021-01-13 00:24:03,641] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:03,682] {logging_mixin.py:112} INFO - [2021-01-13 00:24:03,677] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:03,686] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:04,241] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.610 seconds
[2021-01-13 00:24:04,670] {scheduler_job.py:155} INFO - Started process (PID=16) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:04,685] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:04,696] {logging_mixin.py:112} INFO - [2021-01-13 00:24:04,694] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:04,764] {logging_mixin.py:112} INFO - [2021-01-13 00:24:04,750] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:04,777] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:05,442] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.772 seconds
[2021-01-13 00:24:05,672] {scheduler_job.py:155} INFO - Started process (PID=17) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:05,688] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:05,691] {logging_mixin.py:112} INFO - [2021-01-13 00:24:05,691] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:05,737] {logging_mixin.py:112} INFO - [2021-01-13 00:24:05,728] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:05,741] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:06,314] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.641 seconds
[2021-01-13 00:24:06,735] {scheduler_job.py:155} INFO - Started process (PID=18) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:06,752] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:06,754] {logging_mixin.py:112} INFO - [2021-01-13 00:24:06,754] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:06,781] {logging_mixin.py:112} INFO - [2021-01-13 00:24:06,777] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:06,784] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:07,472] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.738 seconds
[2021-01-13 00:24:07,692] {scheduler_job.py:155} INFO - Started process (PID=19) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:07,711] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:07,716] {logging_mixin.py:112} INFO - [2021-01-13 00:24:07,715] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:07,763] {logging_mixin.py:112} INFO - [2021-01-13 00:24:07,757] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:07,768] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:08,517] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.825 seconds
[2021-01-13 00:24:08,753] {scheduler_job.py:155} INFO - Started process (PID=20) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:08,762] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:08,764] {logging_mixin.py:112} INFO - [2021-01-13 00:24:08,764] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:08,787] {logging_mixin.py:112} INFO - [2021-01-13 00:24:08,781] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:08,790] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:09,369] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.616 seconds
[2021-01-13 00:24:09,764] {scheduler_job.py:155} INFO - Started process (PID=21) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:09,779] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:09,781] {logging_mixin.py:112} INFO - [2021-01-13 00:24:09,780] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:09,803] {logging_mixin.py:112} INFO - [2021-01-13 00:24:09,798] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:09,805] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:10,344] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.580 seconds
[2021-01-13 00:24:10,830] {scheduler_job.py:155} INFO - Started process (PID=22) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:10,837] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:10,839] {logging_mixin.py:112} INFO - [2021-01-13 00:24:10,839] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:10,857] {logging_mixin.py:112} INFO - [2021-01-13 00:24:10,854] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:10,859] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:11,380] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.551 seconds
[2021-01-13 00:24:11,842] {scheduler_job.py:155} INFO - Started process (PID=23) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:11,848] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:11,850] {logging_mixin.py:112} INFO - [2021-01-13 00:24:11,850] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:11,871] {logging_mixin.py:112} INFO - [2021-01-13 00:24:11,868] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:11,873] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:12,403] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.561 seconds
[2021-01-13 00:24:12,859] {scheduler_job.py:155} INFO - Started process (PID=24) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:12,865] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:12,869] {logging_mixin.py:112} INFO - [2021-01-13 00:24:12,868] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:12,895] {logging_mixin.py:112} INFO - [2021-01-13 00:24:12,891] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:12,898] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:13,430] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.571 seconds
[2021-01-13 00:24:14,007] {scheduler_job.py:155} INFO - Started process (PID=25) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:14,014] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:14,017] {logging_mixin.py:112} INFO - [2021-01-13 00:24:14,017] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:14,063] {logging_mixin.py:112} INFO - [2021-01-13 00:24:14,058] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:14,066] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:14,588] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.581 seconds
[2021-01-13 00:24:15,006] {scheduler_job.py:155} INFO - Started process (PID=26) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:15,015] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:15,021] {logging_mixin.py:112} INFO - [2021-01-13 00:24:15,021] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:15,050] {logging_mixin.py:112} INFO - [2021-01-13 00:24:15,045] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:15,053] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:15,636] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.629 seconds
[2021-01-13 00:24:16,020] {scheduler_job.py:155} INFO - Started process (PID=27) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:15,994] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:15,997] {logging_mixin.py:112} INFO - [2021-01-13 00:24:15,997] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:16,017] {logging_mixin.py:112} INFO - [2021-01-13 00:24:16,013] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:16,019] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:16,781] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.761 seconds
[2021-01-13 00:24:17,034] {scheduler_job.py:155} INFO - Started process (PID=28) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:17,040] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:17,043] {logging_mixin.py:112} INFO - [2021-01-13 00:24:17,042] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:17,069] {logging_mixin.py:112} INFO - [2021-01-13 00:24:17,065] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:17,071] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:17,655] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.621 seconds
[2021-01-13 00:24:18,050] {scheduler_job.py:155} INFO - Started process (PID=29) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:18,072] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:18,074] {logging_mixin.py:112} INFO - [2021-01-13 00:24:18,074] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:18,094] {logging_mixin.py:112} INFO - [2021-01-13 00:24:18,091] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:18,096] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:18,977] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.926 seconds
[2021-01-13 00:24:19,096] {scheduler_job.py:155} INFO - Started process (PID=30) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:19,109] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:19,113] {logging_mixin.py:112} INFO - [2021-01-13 00:24:19,113] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:19,166] {logging_mixin.py:112} INFO - [2021-01-13 00:24:19,156] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:19,168] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:19,746] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.651 seconds
[2021-01-13 00:24:20,099] {scheduler_job.py:155} INFO - Started process (PID=31) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:20,106] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:20,108] {logging_mixin.py:112} INFO - [2021-01-13 00:24:20,108] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:20,125] {logging_mixin.py:112} INFO - [2021-01-13 00:24:20,122] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:20,127] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:20,691] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.592 seconds
[2021-01-13 00:24:21,125] {scheduler_job.py:155} INFO - Started process (PID=32) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:21,133] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:21,135] {logging_mixin.py:112} INFO - [2021-01-13 00:24:21,135] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:21,162] {logging_mixin.py:112} INFO - [2021-01-13 00:24:21,158] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:21,165] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:21,699] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.575 seconds
[2021-01-13 00:24:22,149] {scheduler_job.py:155} INFO - Started process (PID=33) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:22,165] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:22,169] {logging_mixin.py:112} INFO - [2021-01-13 00:24:22,169] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:22,212] {logging_mixin.py:112} INFO - [2021-01-13 00:24:22,207] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:22,216] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:22,724] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.575 seconds
[2021-01-13 00:24:23,134] {scheduler_job.py:155} INFO - Started process (PID=34) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:23,140] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:23,143] {logging_mixin.py:112} INFO - [2021-01-13 00:24:23,142] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:23,164] {logging_mixin.py:112} INFO - [2021-01-13 00:24:23,160] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:23,165] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:23,696] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.562 seconds
[2021-01-13 00:24:24,257] {scheduler_job.py:155} INFO - Started process (PID=35) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:24,262] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:24,265] {logging_mixin.py:112} INFO - [2021-01-13 00:24:24,264] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:24,283] {logging_mixin.py:112} INFO - [2021-01-13 00:24:24,280] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:24,284] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:24,799] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.542 seconds
[2021-01-13 00:24:25,271] {scheduler_job.py:155} INFO - Started process (PID=36) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:25,278] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:25,280] {logging_mixin.py:112} INFO - [2021-01-13 00:24:25,280] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:25,308] {logging_mixin.py:112} INFO - [2021-01-13 00:24:25,296] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:25,309] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:25,878] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.607 seconds
[2021-01-13 00:24:26,292] {scheduler_job.py:155} INFO - Started process (PID=37) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:26,299] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:26,302] {logging_mixin.py:112} INFO - [2021-01-13 00:24:26,301] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:26,325] {logging_mixin.py:112} INFO - [2021-01-13 00:24:26,321] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:26,327] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:26,817] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.525 seconds
[2021-01-13 00:24:27,301] {scheduler_job.py:155} INFO - Started process (PID=38) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:27,308] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:27,310] {logging_mixin.py:112} INFO - [2021-01-13 00:24:27,310] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:27,330] {logging_mixin.py:112} INFO - [2021-01-13 00:24:27,327] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:27,333] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:27,904] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.603 seconds
[2021-01-13 00:24:28,318] {scheduler_job.py:155} INFO - Started process (PID=39) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:28,324] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:28,326] {logging_mixin.py:112} INFO - [2021-01-13 00:24:28,326] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:28,345] {logging_mixin.py:112} INFO - [2021-01-13 00:24:28,341] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:28,347] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:28,918] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.600 seconds
[2021-01-13 00:24:29,337] {scheduler_job.py:155} INFO - Started process (PID=40) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:29,344] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:29,347] {logging_mixin.py:112} INFO - [2021-01-13 00:24:29,347] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:29,374] {logging_mixin.py:112} INFO - [2021-01-13 00:24:29,367] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:29,389] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:29,925] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.588 seconds
[2021-01-13 00:24:30,357] {scheduler_job.py:155} INFO - Started process (PID=41) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:30,365] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:30,368] {logging_mixin.py:112} INFO - [2021-01-13 00:24:30,367] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:30,390] {logging_mixin.py:112} INFO - [2021-01-13 00:24:30,387] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:30,393] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:30,959] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.602 seconds
[2021-01-13 00:24:31,361] {scheduler_job.py:155} INFO - Started process (PID=42) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:31,368] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:31,373] {logging_mixin.py:112} INFO - [2021-01-13 00:24:31,373] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:31,392] {logging_mixin.py:112} INFO - [2021-01-13 00:24:31,389] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:31,394] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:31,954] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.593 seconds
[2021-01-13 00:24:32,374] {scheduler_job.py:155} INFO - Started process (PID=43) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:32,380] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:32,383] {logging_mixin.py:112} INFO - [2021-01-13 00:24:32,383] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:32,404] {logging_mixin.py:112} INFO - [2021-01-13 00:24:32,399] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:32,406] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:33,044] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.670 seconds
[2021-01-13 00:24:33,392] {scheduler_job.py:155} INFO - Started process (PID=44) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:33,405] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:33,408] {logging_mixin.py:112} INFO - [2021-01-13 00:24:33,408] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:33,447] {logging_mixin.py:112} INFO - [2021-01-13 00:24:33,440] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:33,449] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:34,079] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.687 seconds
[2021-01-13 00:24:34,512] {scheduler_job.py:155} INFO - Started process (PID=45) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:34,518] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:34,521] {logging_mixin.py:112} INFO - [2021-01-13 00:24:34,520] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:34,543] {logging_mixin.py:112} INFO - [2021-01-13 00:24:34,540] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:34,545] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:35,083] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.571 seconds
[2021-01-13 00:24:35,536] {scheduler_job.py:155} INFO - Started process (PID=46) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:35,552] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:35,555] {logging_mixin.py:112} INFO - [2021-01-13 00:24:35,555] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:35,587] {logging_mixin.py:112} INFO - [2021-01-13 00:24:35,579] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:35,589] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:36,150] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.614 seconds
[2021-01-13 00:24:36,610] {scheduler_job.py:155} INFO - Started process (PID=47) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:36,628] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:36,638] {logging_mixin.py:112} INFO - [2021-01-13 00:24:36,637] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:36,684] {logging_mixin.py:112} INFO - [2021-01-13 00:24:36,679] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:36,686] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:37,258] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.648 seconds
[2021-01-13 00:24:37,560] {scheduler_job.py:155} INFO - Started process (PID=48) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:37,568] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:37,571] {logging_mixin.py:112} INFO - [2021-01-13 00:24:37,570] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:37,593] {logging_mixin.py:112} INFO - [2021-01-13 00:24:37,589] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:37,595] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:38,148] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.587 seconds
[2021-01-13 00:24:38,578] {scheduler_job.py:155} INFO - Started process (PID=49) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:38,586] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:38,589] {logging_mixin.py:112} INFO - [2021-01-13 00:24:38,588] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:38,616] {logging_mixin.py:112} INFO - [2021-01-13 00:24:38,610] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:38,618] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:39,169] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.591 seconds
[2021-01-13 00:24:39,600] {scheduler_job.py:155} INFO - Started process (PID=50) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:39,608] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:39,611] {logging_mixin.py:112} INFO - [2021-01-13 00:24:39,610] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:39,632] {logging_mixin.py:112} INFO - [2021-01-13 00:24:39,628] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:39,633] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:40,213] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.613 seconds
[2021-01-13 00:24:40,623] {scheduler_job.py:155} INFO - Started process (PID=51) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:40,636] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:40,640] {logging_mixin.py:112} INFO - [2021-01-13 00:24:40,639] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:40,679] {logging_mixin.py:112} INFO - [2021-01-13 00:24:40,674] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:40,684] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:41,263] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.640 seconds
[2021-01-13 00:24:41,633] {scheduler_job.py:155} INFO - Started process (PID=52) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:41,642] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:41,647] {logging_mixin.py:112} INFO - [2021-01-13 00:24:41,646] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:41,671] {logging_mixin.py:112} INFO - [2021-01-13 00:24:41,665] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:41,673] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:42,207] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.574 seconds
[2021-01-13 00:24:42,642] {scheduler_job.py:155} INFO - Started process (PID=53) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:42,648] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:42,650] {logging_mixin.py:112} INFO - [2021-01-13 00:24:42,650] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:42,676] {logging_mixin.py:112} INFO - [2021-01-13 00:24:42,672] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:42,677] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:43,261] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.619 seconds
[2021-01-13 00:24:43,677] {scheduler_job.py:155} INFO - Started process (PID=54) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:43,682] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:43,684] {logging_mixin.py:112} INFO - [2021-01-13 00:24:43,684] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:43,702] {logging_mixin.py:112} INFO - [2021-01-13 00:24:43,699] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:43,704] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:44,242] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.565 seconds
[2021-01-13 00:24:44,783] {scheduler_job.py:155} INFO - Started process (PID=55) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:44,789] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:44,791] {logging_mixin.py:112} INFO - [2021-01-13 00:24:44,790] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:44,815] {logging_mixin.py:112} INFO - [2021-01-13 00:24:44,811] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:44,818] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:45,435] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.652 seconds
[2021-01-13 00:24:45,806] {scheduler_job.py:155} INFO - Started process (PID=56) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:45,812] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:45,816] {logging_mixin.py:112} INFO - [2021-01-13 00:24:45,815] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:45,836] {logging_mixin.py:112} INFO - [2021-01-13 00:24:45,832] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:45,838] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:46,360] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.554 seconds
[2021-01-13 00:24:46,789] {scheduler_job.py:155} INFO - Started process (PID=57) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:46,802] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:46,804] {logging_mixin.py:112} INFO - [2021-01-13 00:24:46,804] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:46,835] {logging_mixin.py:112} INFO - [2021-01-13 00:24:46,832] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:46,838] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:47,563] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.774 seconds
[2021-01-13 00:24:47,796] {scheduler_job.py:155} INFO - Started process (PID=58) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:47,801] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:47,803] {logging_mixin.py:112} INFO - [2021-01-13 00:24:47,802] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:47,818] {logging_mixin.py:112} INFO - [2021-01-13 00:24:47,815] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:47,820] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:48,327] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.531 seconds
[2021-01-13 00:24:48,817] {scheduler_job.py:155} INFO - Started process (PID=59) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:48,823] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:48,827] {logging_mixin.py:112} INFO - [2021-01-13 00:24:48,827] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:48,845] {logging_mixin.py:112} INFO - [2021-01-13 00:24:48,842] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:48,847] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:49,382] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.565 seconds
[2021-01-13 00:24:49,832] {scheduler_job.py:155} INFO - Started process (PID=60) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:49,837] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:49,839] {logging_mixin.py:112} INFO - [2021-01-13 00:24:49,839] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:49,857] {logging_mixin.py:112} INFO - [2021-01-13 00:24:49,853] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:49,861] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:50,415] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.583 seconds
[2021-01-13 00:24:50,836] {scheduler_job.py:155} INFO - Started process (PID=61) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:50,841] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:50,844] {logging_mixin.py:112} INFO - [2021-01-13 00:24:50,843] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:50,861] {logging_mixin.py:112} INFO - [2021-01-13 00:24:50,858] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:50,864] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:51,427] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.592 seconds
[2021-01-13 00:24:51,851] {scheduler_job.py:155} INFO - Started process (PID=62) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:51,856] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:51,858] {logging_mixin.py:112} INFO - [2021-01-13 00:24:51,858] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:51,874] {logging_mixin.py:112} INFO - [2021-01-13 00:24:51,872] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:51,876] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:52,407] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.556 seconds
[2021-01-13 00:24:52,868] {scheduler_job.py:155} INFO - Started process (PID=63) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:52,875] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:52,877] {logging_mixin.py:112} INFO - [2021-01-13 00:24:52,877] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:52,897] {logging_mixin.py:112} INFO - [2021-01-13 00:24:52,894] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:52,899] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:53,419] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.551 seconds
[2021-01-13 00:24:53,888] {scheduler_job.py:155} INFO - Started process (PID=64) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:53,894] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:53,896] {logging_mixin.py:112} INFO - [2021-01-13 00:24:53,896] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:53,914] {logging_mixin.py:112} INFO - [2021-01-13 00:24:53,910] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:53,915] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:54,482] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.594 seconds
[2021-01-13 00:24:55,022] {scheduler_job.py:155} INFO - Started process (PID=65) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:55,030] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:55,032] {logging_mixin.py:112} INFO - [2021-01-13 00:24:55,032] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:55,054] {logging_mixin.py:112} INFO - [2021-01-13 00:24:55,051] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:55,055] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:55,556] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.535 seconds
[2021-01-13 00:24:56,029] {scheduler_job.py:155} INFO - Started process (PID=66) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:56,037] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:56,039] {logging_mixin.py:112} INFO - [2021-01-13 00:24:56,039] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:56,062] {logging_mixin.py:112} INFO - [2021-01-13 00:24:56,058] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:56,064] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:56,646] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.617 seconds
[2021-01-13 00:24:57,054] {scheduler_job.py:155} INFO - Started process (PID=67) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:57,069] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:57,075] {logging_mixin.py:112} INFO - [2021-01-13 00:24:57,074] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:57,111] {logging_mixin.py:112} INFO - [2021-01-13 00:24:57,103] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:57,115] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:57,844] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.790 seconds
[2021-01-13 00:24:58,068] {scheduler_job.py:155} INFO - Started process (PID=68) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:58,074] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:58,076] {logging_mixin.py:112} INFO - [2021-01-13 00:24:58,076] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:58,094] {logging_mixin.py:112} INFO - [2021-01-13 00:24:58,091] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:58,096] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:58,646] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.578 seconds
[2021-01-13 00:24:59,079] {scheduler_job.py:155} INFO - Started process (PID=69) to work on /opt/airflow/dags/example.py
[2021-01-13 00:24:59,085] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:24:59,087] {logging_mixin.py:112} INFO - [2021-01-13 00:24:59,087] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:24:59,105] {logging_mixin.py:112} INFO - [2021-01-13 00:24:59,101] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:24:59,106] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:24:59,630] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.551 seconds
[2021-01-13 00:25:00,093] {scheduler_job.py:155} INFO - Started process (PID=70) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:00,097] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:00,099] {logging_mixin.py:112} INFO - [2021-01-13 00:25:00,099] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:00,115] {logging_mixin.py:112} INFO - [2021-01-13 00:25:00,113] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:00,117] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:00,695] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.602 seconds
[2021-01-13 00:25:01,109] {scheduler_job.py:155} INFO - Started process (PID=71) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:01,113] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:01,115] {logging_mixin.py:112} INFO - [2021-01-13 00:25:01,115] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:01,131] {logging_mixin.py:112} INFO - [2021-01-13 00:25:01,129] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:01,133] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:01,641] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.533 seconds
[2021-01-13 00:25:02,125] {scheduler_job.py:155} INFO - Started process (PID=72) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:02,130] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:02,132] {logging_mixin.py:112} INFO - [2021-01-13 00:25:02,132] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:02,149] {logging_mixin.py:112} INFO - [2021-01-13 00:25:02,146] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:02,152] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:02,630] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.505 seconds
[2021-01-13 00:25:03,143] {scheduler_job.py:155} INFO - Started process (PID=73) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:03,149] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:03,152] {logging_mixin.py:112} INFO - [2021-01-13 00:25:03,151] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:03,173] {logging_mixin.py:112} INFO - [2021-01-13 00:25:03,169] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:03,175] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:03,748] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.605 seconds
[2021-01-13 00:25:04,153] {scheduler_job.py:155} INFO - Started process (PID=74) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:04,159] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:04,164] {logging_mixin.py:112} INFO - [2021-01-13 00:25:04,163] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:04,202] {logging_mixin.py:112} INFO - [2021-01-13 00:25:04,192] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:04,206] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:04,675] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.522 seconds
[2021-01-13 00:25:05,283] {scheduler_job.py:155} INFO - Started process (PID=75) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:05,295] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:05,298] {logging_mixin.py:112} INFO - [2021-01-13 00:25:05,298] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:05,336] {logging_mixin.py:112} INFO - [2021-01-13 00:25:05,330] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:05,339] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:05,886] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.603 seconds
[2021-01-13 00:25:06,289] {scheduler_job.py:155} INFO - Started process (PID=76) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:06,296] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:06,298] {logging_mixin.py:112} INFO - [2021-01-13 00:25:06,298] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:06,315] {logging_mixin.py:112} INFO - [2021-01-13 00:25:06,312] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:06,317] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:06,842] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.553 seconds
[2021-01-13 00:25:07,302] {scheduler_job.py:155} INFO - Started process (PID=77) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:07,309] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:07,313] {logging_mixin.py:112} INFO - [2021-01-13 00:25:07,311] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:07,354] {logging_mixin.py:112} INFO - [2021-01-13 00:25:07,348] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:07,363] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:07,869] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.567 seconds
[2021-01-13 00:25:08,314] {scheduler_job.py:155} INFO - Started process (PID=78) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:08,320] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:08,322] {logging_mixin.py:112} INFO - [2021-01-13 00:25:08,322] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:08,338] {logging_mixin.py:112} INFO - [2021-01-13 00:25:08,335] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:08,340] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:08,863] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.549 seconds
[2021-01-13 00:25:09,329] {scheduler_job.py:155} INFO - Started process (PID=79) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:09,344] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:09,347] {logging_mixin.py:112} INFO - [2021-01-13 00:25:09,347] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:09,364] {logging_mixin.py:112} INFO - [2021-01-13 00:25:09,360] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:09,366] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:10,126] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.797 seconds
[2021-01-13 00:25:10,343] {scheduler_job.py:155} INFO - Started process (PID=80) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:10,348] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:10,350] {logging_mixin.py:112} INFO - [2021-01-13 00:25:10,350] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:10,374] {logging_mixin.py:112} INFO - [2021-01-13 00:25:10,370] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:10,376] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:10,906] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.563 seconds
[2021-01-13 00:25:11,356] {scheduler_job.py:155} INFO - Started process (PID=81) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:11,361] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:11,364] {logging_mixin.py:112} INFO - [2021-01-13 00:25:11,363] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:11,382] {logging_mixin.py:112} INFO - [2021-01-13 00:25:11,378] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:11,384] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:11,970] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.613 seconds
[2021-01-13 00:25:12,374] {scheduler_job.py:155} INFO - Started process (PID=82) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:12,380] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:12,381] {logging_mixin.py:112} INFO - [2021-01-13 00:25:12,381] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:12,397] {logging_mixin.py:112} INFO - [2021-01-13 00:25:12,394] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:12,399] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:12,945] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.572 seconds
[2021-01-13 00:25:13,400] {scheduler_job.py:155} INFO - Started process (PID=83) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:13,412] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:13,416] {logging_mixin.py:112} INFO - [2021-01-13 00:25:13,415] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:13,440] {logging_mixin.py:112} INFO - [2021-01-13 00:25:13,437] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:13,442] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:13,996] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.596 seconds
[2021-01-13 00:25:14,408] {scheduler_job.py:155} INFO - Started process (PID=84) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:14,413] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:14,416] {logging_mixin.py:112} INFO - [2021-01-13 00:25:14,415] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:14,442] {logging_mixin.py:112} INFO - [2021-01-13 00:25:14,436] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:14,444] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:14,961] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.553 seconds
[2021-01-13 00:25:15,529] {scheduler_job.py:155} INFO - Started process (PID=85) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:15,537] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:15,539] {logging_mixin.py:112} INFO - [2021-01-13 00:25:15,539] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:15,563] {logging_mixin.py:112} INFO - [2021-01-13 00:25:15,559] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:15,565] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:16,031] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.502 seconds
[2021-01-13 00:25:16,500] {scheduler_job.py:155} INFO - Started process (PID=86) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:16,508] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:16,510] {logging_mixin.py:112} INFO - [2021-01-13 00:25:16,510] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:16,533] {logging_mixin.py:112} INFO - [2021-01-13 00:25:16,529] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:16,536] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:17,076] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.576 seconds
[2021-01-13 00:25:17,516] {scheduler_job.py:155} INFO - Started process (PID=87) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:17,522] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:17,525] {logging_mixin.py:112} INFO - [2021-01-13 00:25:17,525] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:17,544] {logging_mixin.py:112} INFO - [2021-01-13 00:25:17,540] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:17,546] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:18,081] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.565 seconds
[2021-01-13 00:25:18,537] {scheduler_job.py:155} INFO - Started process (PID=88) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:18,544] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:18,546] {logging_mixin.py:112} INFO - [2021-01-13 00:25:18,546] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:18,565] {logging_mixin.py:112} INFO - [2021-01-13 00:25:18,562] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:18,567] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:19,101] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.564 seconds
[2021-01-13 00:25:19,548] {scheduler_job.py:155} INFO - Started process (PID=89) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:19,553] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:19,556] {logging_mixin.py:112} INFO - [2021-01-13 00:25:19,555] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:19,573] {logging_mixin.py:112} INFO - [2021-01-13 00:25:19,569] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:19,574] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:20,138] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.590 seconds
[2021-01-13 00:25:20,571] {scheduler_job.py:155} INFO - Started process (PID=90) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:20,575] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:20,577] {logging_mixin.py:112} INFO - [2021-01-13 00:25:20,577] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:20,596] {logging_mixin.py:112} INFO - [2021-01-13 00:25:20,592] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:20,598] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:21,319] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.749 seconds
[2021-01-13 00:25:21,587] {scheduler_job.py:155} INFO - Started process (PID=91) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:21,593] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:21,595] {logging_mixin.py:112} INFO - [2021-01-13 00:25:21,594] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:21,613] {logging_mixin.py:112} INFO - [2021-01-13 00:25:21,610] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:21,614] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:22,311] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.724 seconds
[2021-01-13 00:25:22,599] {scheduler_job.py:155} INFO - Started process (PID=92) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:22,604] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:22,606] {logging_mixin.py:112} INFO - [2021-01-13 00:25:22,605] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:22,622] {logging_mixin.py:112} INFO - [2021-01-13 00:25:22,619] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:22,627] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:23,162] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.563 seconds
[2021-01-13 00:25:23,612] {scheduler_job.py:155} INFO - Started process (PID=93) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:23,617] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:23,619] {logging_mixin.py:112} INFO - [2021-01-13 00:25:23,619] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:23,639] {logging_mixin.py:112} INFO - [2021-01-13 00:25:23,636] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:23,641] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:24,193] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.581 seconds
[2021-01-13 00:25:24,628] {scheduler_job.py:155} INFO - Started process (PID=94) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:24,635] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:24,643] {logging_mixin.py:112} INFO - [2021-01-13 00:25:24,642] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:24,663] {logging_mixin.py:112} INFO - [2021-01-13 00:25:24,660] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:24,667] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:25,176] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.548 seconds
[2021-01-13 00:25:25,755] {scheduler_job.py:155} INFO - Started process (PID=95) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:25,760] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:25,762] {logging_mixin.py:112} INFO - [2021-01-13 00:25:25,762] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:25,781] {logging_mixin.py:112} INFO - [2021-01-13 00:25:25,778] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:25,783] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:26,595] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.840 seconds
[2021-01-13 00:25:26,772] {scheduler_job.py:155} INFO - Started process (PID=96) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:26,778] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:26,779] {logging_mixin.py:112} INFO - [2021-01-13 00:25:26,779] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:26,797] {logging_mixin.py:112} INFO - [2021-01-13 00:25:26,793] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:26,800] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:27,533] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.761 seconds
[2021-01-13 00:25:27,793] {scheduler_job.py:155} INFO - Started process (PID=97) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:27,799] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:27,801] {logging_mixin.py:112} INFO - [2021-01-13 00:25:27,801] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:27,818] {logging_mixin.py:112} INFO - [2021-01-13 00:25:27,815] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:27,820] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:28,575] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.782 seconds
[2021-01-13 00:25:28,804] {scheduler_job.py:155} INFO - Started process (PID=98) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:28,809] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:28,811] {logging_mixin.py:112} INFO - [2021-01-13 00:25:28,810] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:28,828] {logging_mixin.py:112} INFO - [2021-01-13 00:25:28,825] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:28,830] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:29,359] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.555 seconds
[2021-01-13 00:25:29,820] {scheduler_job.py:155} INFO - Started process (PID=99) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:29,826] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:29,828] {logging_mixin.py:112} INFO - [2021-01-13 00:25:29,828] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:29,846] {logging_mixin.py:112} INFO - [2021-01-13 00:25:29,843] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:29,848] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:30,662] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.842 seconds
[2021-01-13 00:25:30,840] {scheduler_job.py:155} INFO - Started process (PID=100) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:30,852] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:30,857] {logging_mixin.py:112} INFO - [2021-01-13 00:25:30,856] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:30,878] {logging_mixin.py:112} INFO - [2021-01-13 00:25:30,875] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:30,880] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:31,373] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.533 seconds
[2021-01-13 00:25:31,851] {scheduler_job.py:155} INFO - Started process (PID=101) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:31,856] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:31,858] {logging_mixin.py:112} INFO - [2021-01-13 00:25:31,858] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:31,875] {logging_mixin.py:112} INFO - [2021-01-13 00:25:31,872] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:31,876] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:32,606] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.755 seconds
[2021-01-13 00:25:32,877] {scheduler_job.py:155} INFO - Started process (PID=102) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:32,883] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:32,885] {logging_mixin.py:112} INFO - [2021-01-13 00:25:32,884] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:32,902] {logging_mixin.py:112} INFO - [2021-01-13 00:25:32,899] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:32,904] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:33,461] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.584 seconds
[2021-01-13 00:25:33,895] {scheduler_job.py:155} INFO - Started process (PID=103) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:33,902] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:33,904] {logging_mixin.py:112} INFO - [2021-01-13 00:25:33,904] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:33,952] {logging_mixin.py:112} INFO - [2021-01-13 00:25:33,934] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:33,955] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:34,640] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.744 seconds
[2021-01-13 00:25:34,905] {scheduler_job.py:155} INFO - Started process (PID=104) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:34,911] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:34,914] {logging_mixin.py:112} INFO - [2021-01-13 00:25:34,913] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:34,968] {logging_mixin.py:112} INFO - [2021-01-13 00:25:34,961] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:34,971] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:35,549] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.645 seconds
[2021-01-13 00:25:36,040] {scheduler_job.py:155} INFO - Started process (PID=105) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:36,056] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:36,062] {logging_mixin.py:112} INFO - [2021-01-13 00:25:36,061] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:36,101] {logging_mixin.py:112} INFO - [2021-01-13 00:25:36,095] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:36,103] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:36,601] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.562 seconds
[2021-01-13 00:25:37,031] {scheduler_job.py:155} INFO - Started process (PID=106) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:37,039] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:37,042] {logging_mixin.py:112} INFO - [2021-01-13 00:25:37,041] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:37,064] {logging_mixin.py:112} INFO - [2021-01-13 00:25:37,060] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:37,065] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:37,614] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.584 seconds
[2021-01-13 00:25:38,061] {scheduler_job.py:155} INFO - Started process (PID=107) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:38,073] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:38,076] {logging_mixin.py:112} INFO - [2021-01-13 00:25:38,075] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:38,110] {logging_mixin.py:112} INFO - [2021-01-13 00:25:38,105] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:38,112] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:38,615] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.554 seconds
[2021-01-13 00:25:39,054] {scheduler_job.py:155} INFO - Started process (PID=108) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:39,059] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:39,061] {logging_mixin.py:112} INFO - [2021-01-13 00:25:39,061] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:39,080] {logging_mixin.py:112} INFO - [2021-01-13 00:25:39,076] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:39,082] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:39,813] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.759 seconds
[2021-01-13 00:25:40,090] {scheduler_job.py:155} INFO - Started process (PID=109) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:40,097] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:40,099] {logging_mixin.py:112} INFO - [2021-01-13 00:25:40,099] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:40,122] {logging_mixin.py:112} INFO - [2021-01-13 00:25:40,117] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:40,125] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:40,649] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.559 seconds
[2021-01-13 00:25:41,093] {scheduler_job.py:155} INFO - Started process (PID=110) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:41,097] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:41,099] {logging_mixin.py:112} INFO - [2021-01-13 00:25:41,099] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:41,115] {logging_mixin.py:112} INFO - [2021-01-13 00:25:41,112] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:41,117] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:41,866] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.773 seconds
[2021-01-13 00:25:42,112] {scheduler_job.py:155} INFO - Started process (PID=111) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:42,119] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:42,122] {logging_mixin.py:112} INFO - [2021-01-13 00:25:42,121] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:42,143] {logging_mixin.py:112} INFO - [2021-01-13 00:25:42,140] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:42,145] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:42,658] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.546 seconds
[2021-01-13 00:25:43,133] {scheduler_job.py:155} INFO - Started process (PID=112) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:43,146] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:43,150] {logging_mixin.py:112} INFO - [2021-01-13 00:25:43,149] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:43,177] {logging_mixin.py:112} INFO - [2021-01-13 00:25:43,170] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:43,180] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:43,714] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.580 seconds
[2021-01-13 00:25:44,152] {scheduler_job.py:155} INFO - Started process (PID=113) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:44,164] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:44,166] {logging_mixin.py:112} INFO - [2021-01-13 00:25:44,165] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:44,190] {logging_mixin.py:112} INFO - [2021-01-13 00:25:44,187] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:44,193] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:44,712] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.560 seconds
[2021-01-13 00:25:45,157] {scheduler_job.py:155} INFO - Started process (PID=114) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:45,172] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:45,177] {logging_mixin.py:112} INFO - [2021-01-13 00:25:45,176] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:45,201] {logging_mixin.py:112} INFO - [2021-01-13 00:25:45,196] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:45,204] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:45,728] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.572 seconds
[2021-01-13 00:25:46,251] {scheduler_job.py:155} INFO - Started process (PID=115) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:46,257] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:46,262] {logging_mixin.py:112} INFO - [2021-01-13 00:25:46,262] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:46,296] {logging_mixin.py:112} INFO - [2021-01-13 00:25:46,292] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:46,298] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:46,889] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.638 seconds
[2021-01-13 00:25:47,267] {scheduler_job.py:155} INFO - Started process (PID=116) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:47,279] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:47,283] {logging_mixin.py:112} INFO - [2021-01-13 00:25:47,282] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:47,301] {logging_mixin.py:112} INFO - [2021-01-13 00:25:47,298] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:47,302] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:47,822] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.555 seconds
[2021-01-13 00:25:48,282] {scheduler_job.py:155} INFO - Started process (PID=117) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:48,297] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:48,299] {logging_mixin.py:112} INFO - [2021-01-13 00:25:48,299] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:48,316] {logging_mixin.py:112} INFO - [2021-01-13 00:25:48,312] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:48,318] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:48,824] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.542 seconds
[2021-01-13 00:25:49,304] {scheduler_job.py:155} INFO - Started process (PID=118) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:49,309] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:49,313] {logging_mixin.py:112} INFO - [2021-01-13 00:25:49,312] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:49,336] {logging_mixin.py:112} INFO - [2021-01-13 00:25:49,330] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:49,338] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:49,867] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.562 seconds
[2021-01-13 00:25:50,312] {scheduler_job.py:155} INFO - Started process (PID=119) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:50,317] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:50,320] {logging_mixin.py:112} INFO - [2021-01-13 00:25:50,319] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:50,343] {logging_mixin.py:112} INFO - [2021-01-13 00:25:50,337] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:50,345] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:50,937] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.626 seconds
[2021-01-13 00:25:51,326] {scheduler_job.py:155} INFO - Started process (PID=120) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:51,332] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:51,337] {logging_mixin.py:112} INFO - [2021-01-13 00:25:51,336] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:51,364] {logging_mixin.py:112} INFO - [2021-01-13 00:25:51,360] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:51,367] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:51,866] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.540 seconds
[2021-01-13 00:25:52,328] {scheduler_job.py:155} INFO - Started process (PID=121) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:52,333] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:52,335] {logging_mixin.py:112} INFO - [2021-01-13 00:25:52,335] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:52,352] {logging_mixin.py:112} INFO - [2021-01-13 00:25:52,349] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:52,354] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:52,873] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.546 seconds
[2021-01-13 00:25:53,339] {scheduler_job.py:155} INFO - Started process (PID=122) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:53,345] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:53,348] {logging_mixin.py:112} INFO - [2021-01-13 00:25:53,347] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:53,365] {logging_mixin.py:112} INFO - [2021-01-13 00:25:53,362] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:53,368] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:53,963] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.624 seconds
[2021-01-13 00:25:54,361] {scheduler_job.py:155} INFO - Started process (PID=123) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:54,374] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:54,379] {logging_mixin.py:112} INFO - [2021-01-13 00:25:54,378] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:54,414] {logging_mixin.py:112} INFO - [2021-01-13 00:25:54,410] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:54,419] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:25:54,978] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.617 seconds
[2021-01-13 00:25:55,381] {scheduler_job.py:155} INFO - Started process (PID=124) to work on /opt/airflow/dags/example.py
[2021-01-13 00:25:55,398] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:25:55,405] {logging_mixin.py:112} INFO - [2021-01-13 00:25:55,404] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:25:55,435] {logging_mixin.py:112} INFO - [2021-01-13 00:25:55,428] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:25:55,446] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:01,094] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 5.713 seconds
[2021-01-13 00:26:01,530] {scheduler_job.py:155} INFO - Started process (PID=125) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:01,536] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:01,538] {logging_mixin.py:112} INFO - [2021-01-13 00:26:01,538] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:01,558] {logging_mixin.py:112} INFO - [2021-01-13 00:26:01,555] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:01,561] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:02,106] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.576 seconds
[2021-01-13 00:26:02,539] {scheduler_job.py:155} INFO - Started process (PID=126) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:02,547] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:02,549] {logging_mixin.py:112} INFO - [2021-01-13 00:26:02,548] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:02,569] {logging_mixin.py:112} INFO - [2021-01-13 00:26:02,566] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:02,571] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:03,122] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.582 seconds
[2021-01-13 00:26:03,560] {scheduler_job.py:155} INFO - Started process (PID=127) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:03,567] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:03,570] {logging_mixin.py:112} INFO - [2021-01-13 00:26:03,570] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:03,588] {logging_mixin.py:112} INFO - [2021-01-13 00:26:03,585] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:03,590] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:04,182] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.623 seconds
[2021-01-13 00:26:04,578] {scheduler_job.py:155} INFO - Started process (PID=128) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:04,585] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:04,587] {logging_mixin.py:112} INFO - [2021-01-13 00:26:04,586] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:04,610] {logging_mixin.py:112} INFO - [2021-01-13 00:26:04,604] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:04,612] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:05,123] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.546 seconds
[2021-01-13 00:26:05,661] {scheduler_job.py:155} INFO - Started process (PID=129) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:05,678] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:05,686] {logging_mixin.py:112} INFO - [2021-01-13 00:26:05,682] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:05,728] {logging_mixin.py:112} INFO - [2021-01-13 00:26:05,723] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:05,730] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:06,310] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.649 seconds
[2021-01-13 00:26:06,756] {scheduler_job.py:155} INFO - Started process (PID=130) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:06,763] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:06,767] {logging_mixin.py:112} INFO - [2021-01-13 00:26:06,765] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:06,796] {logging_mixin.py:112} INFO - [2021-01-13 00:26:06,790] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:06,801] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:07,331] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.575 seconds
[2021-01-13 00:26:07,788] {scheduler_job.py:155} INFO - Started process (PID=131) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:07,795] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:07,797] {logging_mixin.py:112} INFO - [2021-01-13 00:26:07,796] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:07,827] {logging_mixin.py:112} INFO - [2021-01-13 00:26:07,818] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:07,831] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:08,414] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.627 seconds
[2021-01-13 00:26:08,799] {scheduler_job.py:155} INFO - Started process (PID=132) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:08,805] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:08,807] {logging_mixin.py:112} INFO - [2021-01-13 00:26:08,806] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:08,829] {logging_mixin.py:112} INFO - [2021-01-13 00:26:08,824] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:08,830] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:09,358] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.560 seconds
[2021-01-13 00:26:09,811] {scheduler_job.py:155} INFO - Started process (PID=133) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:09,817] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:09,819] {logging_mixin.py:112} INFO - [2021-01-13 00:26:09,819] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:09,838] {logging_mixin.py:112} INFO - [2021-01-13 00:26:09,834] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:09,841] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:10,606] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.796 seconds
[2021-01-13 00:26:10,821] {scheduler_job.py:155} INFO - Started process (PID=134) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:10,827] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:10,829] {logging_mixin.py:112} INFO - [2021-01-13 00:26:10,829] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:10,847] {logging_mixin.py:112} INFO - [2021-01-13 00:26:10,844] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:10,849] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:11,572] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.751 seconds
[2021-01-13 00:26:11,833] {scheduler_job.py:155} INFO - Started process (PID=135) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:11,839] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:11,842] {logging_mixin.py:112} INFO - [2021-01-13 00:26:11,842] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:11,860] {logging_mixin.py:112} INFO - [2021-01-13 00:26:11,857] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:11,862] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:12,418] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.585 seconds
[2021-01-13 00:26:12,854] {scheduler_job.py:155} INFO - Started process (PID=136) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:12,862] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:12,865] {logging_mixin.py:112} INFO - [2021-01-13 00:26:12,864] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:12,884] {logging_mixin.py:112} INFO - [2021-01-13 00:26:12,881] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:12,886] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:13,401] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.547 seconds
[2021-01-13 00:26:13,869] {scheduler_job.py:155} INFO - Started process (PID=137) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:13,876] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:13,878] {logging_mixin.py:112} INFO - [2021-01-13 00:26:13,878] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:13,897] {logging_mixin.py:112} INFO - [2021-01-13 00:26:13,893] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:13,898] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:14,417] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.548 seconds
[2021-01-13 00:26:14,882] {scheduler_job.py:155} INFO - Started process (PID=138) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:14,888] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:14,890] {logging_mixin.py:112} INFO - [2021-01-13 00:26:14,890] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:14,909] {logging_mixin.py:112} INFO - [2021-01-13 00:26:14,905] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:14,911] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:15,553] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.671 seconds
[2021-01-13 00:26:15,899] {scheduler_job.py:155} INFO - Started process (PID=139) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:15,911] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:15,882] {logging_mixin.py:112} INFO - [2021-01-13 00:26:15,882] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:15,915] {logging_mixin.py:112} INFO - [2021-01-13 00:26:15,911] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:15,919] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:16,456] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.557 seconds
[2021-01-13 00:26:16,998] {scheduler_job.py:155} INFO - Started process (PID=140) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:17,016] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:17,018] {logging_mixin.py:112} INFO - [2021-01-13 00:26:17,018] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:17,046] {logging_mixin.py:112} INFO - [2021-01-13 00:26:17,042] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:17,049] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:17,586] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.589 seconds
[2021-01-13 00:26:18,006] {scheduler_job.py:155} INFO - Started process (PID=141) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:18,011] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:18,014] {logging_mixin.py:112} INFO - [2021-01-13 00:26:18,014] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:18,034] {logging_mixin.py:112} INFO - [2021-01-13 00:26:18,031] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:18,036] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:18,589] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.583 seconds
[2021-01-13 00:26:19,021] {scheduler_job.py:155} INFO - Started process (PID=142) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:19,028] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:19,030] {logging_mixin.py:112} INFO - [2021-01-13 00:26:19,029] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:19,049] {logging_mixin.py:112} INFO - [2021-01-13 00:26:19,045] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:19,051] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:19,544] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.523 seconds
[2021-01-13 00:26:20,051] {scheduler_job.py:155} INFO - Started process (PID=143) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:20,064] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:20,068] {logging_mixin.py:112} INFO - [2021-01-13 00:26:20,067] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:20,101] {logging_mixin.py:112} INFO - [2021-01-13 00:26:20,095] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:20,103] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:20,594] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.543 seconds
[2021-01-13 00:26:21,056] {scheduler_job.py:155} INFO - Started process (PID=144) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:21,063] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:21,065] {logging_mixin.py:112} INFO - [2021-01-13 00:26:21,065] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:21,086] {logging_mixin.py:112} INFO - [2021-01-13 00:26:21,081] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:21,088] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:21,701] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.645 seconds
[2021-01-13 00:26:22,066] {scheduler_job.py:155} INFO - Started process (PID=145) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:22,074] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:22,077] {logging_mixin.py:112} INFO - [2021-01-13 00:26:22,076] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:22,096] {logging_mixin.py:112} INFO - [2021-01-13 00:26:22,092] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:22,098] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:22,623] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.557 seconds
[2021-01-13 00:26:23,081] {scheduler_job.py:155} INFO - Started process (PID=146) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:23,087] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:23,089] {logging_mixin.py:112} INFO - [2021-01-13 00:26:23,089] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:23,107] {logging_mixin.py:112} INFO - [2021-01-13 00:26:23,103] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:23,109] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:23,647] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.566 seconds
[2021-01-13 00:26:24,107] {scheduler_job.py:155} INFO - Started process (PID=147) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:24,119] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:24,123] {logging_mixin.py:112} INFO - [2021-01-13 00:26:24,122] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:24,155] {logging_mixin.py:112} INFO - [2021-01-13 00:26:24,151] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:24,158] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:24,885] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.778 seconds
[2021-01-13 00:26:25,121] {scheduler_job.py:155} INFO - Started process (PID=148) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:25,130] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:25,133] {logging_mixin.py:112} INFO - [2021-01-13 00:26:25,133] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:25,153] {logging_mixin.py:112} INFO - [2021-01-13 00:26:25,148] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:25,157] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:25,697] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.576 seconds
[2021-01-13 00:26:26,134] {scheduler_job.py:155} INFO - Started process (PID=149) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:26,140] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:26,143] {logging_mixin.py:112} INFO - [2021-01-13 00:26:26,142] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:26,163] {logging_mixin.py:112} INFO - [2021-01-13 00:26:26,159] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:26,165] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:26,693] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.559 seconds
[2021-01-13 00:26:27,267] {scheduler_job.py:155} INFO - Started process (PID=150) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:27,273] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:27,275] {logging_mixin.py:112} INFO - [2021-01-13 00:26:27,275] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:27,294] {logging_mixin.py:112} INFO - [2021-01-13 00:26:27,290] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:27,295] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:27,848] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.581 seconds
[2021-01-13 00:26:28,283] {scheduler_job.py:155} INFO - Started process (PID=151) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:28,290] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:28,292] {logging_mixin.py:112} INFO - [2021-01-13 00:26:28,292] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:28,312] {logging_mixin.py:112} INFO - [2021-01-13 00:26:28,308] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:28,313] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:28,904] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.621 seconds
[2021-01-13 00:26:29,295] {scheduler_job.py:155} INFO - Started process (PID=152) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:29,302] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:29,305] {logging_mixin.py:112} INFO - [2021-01-13 00:26:29,305] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:29,325] {logging_mixin.py:112} INFO - [2021-01-13 00:26:29,322] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:29,328] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:29,849] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.555 seconds
[2021-01-13 00:26:30,306] {scheduler_job.py:155} INFO - Started process (PID=153) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:30,312] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:30,314] {logging_mixin.py:112} INFO - [2021-01-13 00:26:30,314] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:30,334] {logging_mixin.py:112} INFO - [2021-01-13 00:26:30,331] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:30,337] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:30,858] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.551 seconds
[2021-01-13 00:26:31,321] {scheduler_job.py:155} INFO - Started process (PID=154) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:31,326] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:31,328] {logging_mixin.py:112} INFO - [2021-01-13 00:26:31,327] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:31,346] {logging_mixin.py:112} INFO - [2021-01-13 00:26:31,343] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:31,348] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:31,898] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.577 seconds
[2021-01-13 00:26:32,339] {scheduler_job.py:155} INFO - Started process (PID=155) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:32,351] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:32,354] {logging_mixin.py:112} INFO - [2021-01-13 00:26:32,353] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:32,375] {logging_mixin.py:112} INFO - [2021-01-13 00:26:32,371] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:32,378] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:32,911] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.573 seconds
[2021-01-13 00:26:33,348] {scheduler_job.py:155} INFO - Started process (PID=156) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:33,353] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:33,355] {logging_mixin.py:112} INFO - [2021-01-13 00:26:33,355] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:33,374] {logging_mixin.py:112} INFO - [2021-01-13 00:26:33,371] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:33,375] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:33,950] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.602 seconds
[2021-01-13 00:26:34,371] {scheduler_job.py:155} INFO - Started process (PID=157) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:34,382] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:34,384] {logging_mixin.py:112} INFO - [2021-01-13 00:26:34,384] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:34,412] {logging_mixin.py:112} INFO - [2021-01-13 00:26:34,408] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:34,414] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:34,929] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.559 seconds
[2021-01-13 00:26:35,381] {scheduler_job.py:155} INFO - Started process (PID=158) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:35,390] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:35,391] {logging_mixin.py:112} INFO - [2021-01-13 00:26:35,391] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:35,413] {logging_mixin.py:112} INFO - [2021-01-13 00:26:35,408] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:35,415] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:35,967] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.586 seconds
[2021-01-13 00:26:36,401] {scheduler_job.py:155} INFO - Started process (PID=159) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:36,417] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:36,423] {logging_mixin.py:112} INFO - [2021-01-13 00:26:36,422] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:36,474] {logging_mixin.py:112} INFO - [2021-01-13 00:26:36,466] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:36,478] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:36,992] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.591 seconds
[2021-01-13 00:26:37,540] {scheduler_job.py:155} INFO - Started process (PID=160) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:37,546] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:37,552] {logging_mixin.py:112} INFO - [2021-01-13 00:26:37,550] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:37,592] {logging_mixin.py:112} INFO - [2021-01-13 00:26:37,584] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:37,595] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:38,185] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.645 seconds
[2021-01-13 00:26:38,537] {scheduler_job.py:155} INFO - Started process (PID=161) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:38,542] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:38,544] {logging_mixin.py:112} INFO - [2021-01-13 00:26:38,544] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:38,562] {logging_mixin.py:112} INFO - [2021-01-13 00:26:38,559] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:38,564] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:39,110] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.573 seconds
[2021-01-13 00:26:39,566] {scheduler_job.py:155} INFO - Started process (PID=162) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:39,579] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:39,581] {logging_mixin.py:112} INFO - [2021-01-13 00:26:39,581] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:39,601] {logging_mixin.py:112} INFO - [2021-01-13 00:26:39,598] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:39,603] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:40,144] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.578 seconds
[2021-01-13 00:26:40,568] {scheduler_job.py:155} INFO - Started process (PID=163) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:40,580] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:40,583] {logging_mixin.py:112} INFO - [2021-01-13 00:26:40,583] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:40,612] {logging_mixin.py:112} INFO - [2021-01-13 00:26:40,606] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:40,614] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:41,120] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.551 seconds
[2021-01-13 00:26:41,575] {scheduler_job.py:155} INFO - Started process (PID=164) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:41,581] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:41,583] {logging_mixin.py:112} INFO - [2021-01-13 00:26:41,583] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:41,600] {logging_mixin.py:112} INFO - [2021-01-13 00:26:41,597] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:41,602] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:42,184] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.609 seconds
[2021-01-13 00:26:42,597] {scheduler_job.py:155} INFO - Started process (PID=165) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:42,603] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:42,605] {logging_mixin.py:112} INFO - [2021-01-13 00:26:42,605] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:42,623] {logging_mixin.py:112} INFO - [2021-01-13 00:26:42,620] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:42,625] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:43,132] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.535 seconds
[2021-01-13 00:26:43,606] {scheduler_job.py:155} INFO - Started process (PID=166) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:43,614] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:43,617] {logging_mixin.py:112} INFO - [2021-01-13 00:26:43,616] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:43,637] {logging_mixin.py:112} INFO - [2021-01-13 00:26:43,633] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:43,639] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:44,152] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.546 seconds
[2021-01-13 00:26:44,626] {scheduler_job.py:155} INFO - Started process (PID=167) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:44,631] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:44,633] {logging_mixin.py:112} INFO - [2021-01-13 00:26:44,633] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:44,651] {logging_mixin.py:112} INFO - [2021-01-13 00:26:44,649] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:44,653] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:45,267] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.642 seconds
[2021-01-13 00:26:45,656] {scheduler_job.py:155} INFO - Started process (PID=168) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:45,669] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:45,672] {logging_mixin.py:112} INFO - [2021-01-13 00:26:45,672] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:45,705] {logging_mixin.py:112} INFO - [2021-01-13 00:26:45,701] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:45,707] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:46,192] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.536 seconds
[2021-01-13 00:26:46,628] {scheduler_job.py:155} INFO - Started process (PID=169) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:46,636] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:46,643] {logging_mixin.py:112} INFO - [2021-01-13 00:26:46,642] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:46,681] {logging_mixin.py:112} INFO - [2021-01-13 00:26:46,675] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:46,684] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:47,371] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.743 seconds
[2021-01-13 00:26:47,752] {scheduler_job.py:155} INFO - Started process (PID=170) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:47,757] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:47,759] {logging_mixin.py:112} INFO - [2021-01-13 00:26:47,758] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:47,778] {logging_mixin.py:112} INFO - [2021-01-13 00:26:47,774] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:47,779] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:48,349] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.596 seconds
[2021-01-13 00:26:48,778] {scheduler_job.py:155} INFO - Started process (PID=171) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:48,783] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:48,789] {logging_mixin.py:112} INFO - [2021-01-13 00:26:48,787] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:48,814] {logging_mixin.py:112} INFO - [2021-01-13 00:26:48,811] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:48,816] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:49,400] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.622 seconds
[2021-01-13 00:26:49,787] {scheduler_job.py:155} INFO - Started process (PID=172) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:49,795] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:49,797] {logging_mixin.py:112} INFO - [2021-01-13 00:26:49,797] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:49,817] {logging_mixin.py:112} INFO - [2021-01-13 00:26:49,813] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:49,819] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:50,377] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.590 seconds
[2021-01-13 00:26:50,800] {scheduler_job.py:155} INFO - Started process (PID=173) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:50,809] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:50,811] {logging_mixin.py:112} INFO - [2021-01-13 00:26:50,811] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:50,833] {logging_mixin.py:112} INFO - [2021-01-13 00:26:50,830] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:50,835] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:51,369] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.568 seconds
[2021-01-13 00:26:51,830] {scheduler_job.py:155} INFO - Started process (PID=174) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:51,851] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:51,853] {logging_mixin.py:112} INFO - [2021-01-13 00:26:51,853] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:51,877] {logging_mixin.py:112} INFO - [2021-01-13 00:26:51,871] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:51,879] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:52,437] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.607 seconds
[2021-01-13 00:26:52,827] {scheduler_job.py:155} INFO - Started process (PID=175) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:52,833] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:52,835] {logging_mixin.py:112} INFO - [2021-01-13 00:26:52,835] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:52,855] {logging_mixin.py:112} INFO - [2021-01-13 00:26:52,852] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:52,860] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:53,445] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.618 seconds
[2021-01-13 00:26:53,844] {scheduler_job.py:155} INFO - Started process (PID=176) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:53,849] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:53,851] {logging_mixin.py:112} INFO - [2021-01-13 00:26:53,851] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:53,880] {logging_mixin.py:112} INFO - [2021-01-13 00:26:53,877] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:53,882] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:54,449] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.605 seconds
[2021-01-13 00:26:54,850] {scheduler_job.py:155} INFO - Started process (PID=177) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:54,859] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:54,862] {logging_mixin.py:112} INFO - [2021-01-13 00:26:54,861] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:54,887] {logging_mixin.py:112} INFO - [2021-01-13 00:26:54,883] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:54,890] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:55,399] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.549 seconds
[2021-01-13 00:26:55,867] {scheduler_job.py:155} INFO - Started process (PID=178) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:55,882] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:55,889] {logging_mixin.py:112} INFO - [2021-01-13 00:26:55,886] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:55,923] {logging_mixin.py:112} INFO - [2021-01-13 00:26:55,919] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:55,928] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:56,500] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.633 seconds
[2021-01-13 00:26:56,894] {scheduler_job.py:155} INFO - Started process (PID=179) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:56,906] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:56,909] {logging_mixin.py:112} INFO - [2021-01-13 00:26:56,909] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:56,938] {logging_mixin.py:112} INFO - [2021-01-13 00:26:56,934] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:56,940] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:57,497] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.603 seconds
[2021-01-13 00:26:58,006] {scheduler_job.py:155} INFO - Started process (PID=180) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:58,015] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:58,019] {logging_mixin.py:112} INFO - [2021-01-13 00:26:58,018] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:58,045] {logging_mixin.py:112} INFO - [2021-01-13 00:26:58,041] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:58,048] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:58,617] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.612 seconds
[2021-01-13 00:26:59,040] {scheduler_job.py:155} INFO - Started process (PID=181) to work on /opt/airflow/dags/example.py
[2021-01-13 00:26:59,055] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:26:59,060] {logging_mixin.py:112} INFO - [2021-01-13 00:26:59,058] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:26:59,095] {logging_mixin.py:112} INFO - [2021-01-13 00:26:59,092] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:26:59,100] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:26:59,661] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.621 seconds
[2021-01-13 00:27:00,040] {scheduler_job.py:155} INFO - Started process (PID=182) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:00,049] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:00,054] {logging_mixin.py:112} INFO - [2021-01-13 00:27:00,054] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:00,087] {logging_mixin.py:112} INFO - [2021-01-13 00:27:00,083] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:00,089] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:00,655] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.615 seconds
[2021-01-13 00:27:01,064] {scheduler_job.py:155} INFO - Started process (PID=183) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:01,077] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:01,087] {logging_mixin.py:112} INFO - [2021-01-13 00:27:01,086] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:01,145] {logging_mixin.py:112} INFO - [2021-01-13 00:27:01,140] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:01,151] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:01,727] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.662 seconds
[2021-01-13 00:27:02,082] {scheduler_job.py:155} INFO - Started process (PID=184) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:02,089] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:02,091] {logging_mixin.py:112} INFO - [2021-01-13 00:27:02,091] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:02,116] {logging_mixin.py:112} INFO - [2021-01-13 00:27:02,110] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:02,118] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:02,674] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.591 seconds
[2021-01-13 00:27:03,098] {scheduler_job.py:155} INFO - Started process (PID=185) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:03,107] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:03,110] {logging_mixin.py:112} INFO - [2021-01-13 00:27:03,109] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:03,137] {logging_mixin.py:112} INFO - [2021-01-13 00:27:03,131] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:03,139] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:03,695] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.596 seconds
[2021-01-13 00:27:04,107] {scheduler_job.py:155} INFO - Started process (PID=186) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:04,118] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:04,125] {logging_mixin.py:112} INFO - [2021-01-13 00:27:04,124] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:04,230] {logging_mixin.py:112} INFO - [2021-01-13 00:27:04,215] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:04,233] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:04,835] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.728 seconds
[2021-01-13 00:27:05,126] {scheduler_job.py:155} INFO - Started process (PID=187) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:05,132] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:05,136] {logging_mixin.py:112} INFO - [2021-01-13 00:27:05,135] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:05,187] {logging_mixin.py:112} INFO - [2021-01-13 00:27:05,181] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:05,191] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:05,789] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.663 seconds
[2021-01-13 00:27:06,136] {scheduler_job.py:155} INFO - Started process (PID=188) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:06,143] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:06,146] {logging_mixin.py:112} INFO - [2021-01-13 00:27:06,146] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:06,173] {logging_mixin.py:112} INFO - [2021-01-13 00:27:06,167] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:06,177] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:06,727] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.591 seconds
[2021-01-13 00:27:07,162] {scheduler_job.py:155} INFO - Started process (PID=189) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:07,184] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:07,188] {logging_mixin.py:112} INFO - [2021-01-13 00:27:07,187] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:07,231] {logging_mixin.py:112} INFO - [2021-01-13 00:27:07,223] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:07,237] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:07,748] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.586 seconds
[2021-01-13 00:27:08,266] {scheduler_job.py:155} INFO - Started process (PID=190) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:08,279] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:08,285] {logging_mixin.py:112} INFO - [2021-01-13 00:27:08,284] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:08,325] {logging_mixin.py:112} INFO - [2021-01-13 00:27:08,319] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:08,327] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:09,006] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.739 seconds
[2021-01-13 00:27:09,267] {scheduler_job.py:155} INFO - Started process (PID=191) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:09,273] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:09,275] {logging_mixin.py:112} INFO - [2021-01-13 00:27:09,275] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:09,292] {logging_mixin.py:112} INFO - [2021-01-13 00:27:09,289] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:09,294] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:09,835] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.568 seconds
[2021-01-13 00:27:10,292] {scheduler_job.py:155} INFO - Started process (PID=192) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:10,305] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:10,309] {logging_mixin.py:112} INFO - [2021-01-13 00:27:10,308] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:10,340] {logging_mixin.py:112} INFO - [2021-01-13 00:27:10,334] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:10,342] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:10,836] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.543 seconds
[2021-01-13 00:27:11,296] {scheduler_job.py:155} INFO - Started process (PID=193) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:11,301] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:11,303] {logging_mixin.py:112} INFO - [2021-01-13 00:27:11,303] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:11,323] {logging_mixin.py:112} INFO - [2021-01-13 00:27:11,320] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:11,325] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:11,873] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.578 seconds
[2021-01-13 00:27:12,309] {scheduler_job.py:155} INFO - Started process (PID=194) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:12,315] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:12,317] {logging_mixin.py:112} INFO - [2021-01-13 00:27:12,316] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:12,337] {logging_mixin.py:112} INFO - [2021-01-13 00:27:12,334] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:12,339] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:12,921] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.612 seconds
[2021-01-13 00:27:13,330] {scheduler_job.py:155} INFO - Started process (PID=195) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:13,337] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:13,339] {logging_mixin.py:112} INFO - [2021-01-13 00:27:13,339] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:13,357] {logging_mixin.py:112} INFO - [2021-01-13 00:27:13,353] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:13,359] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:13,887] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.557 seconds
[2021-01-13 00:27:14,349] {scheduler_job.py:155} INFO - Started process (PID=196) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:14,356] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:14,358] {logging_mixin.py:112} INFO - [2021-01-13 00:27:14,358] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:14,380] {logging_mixin.py:112} INFO - [2021-01-13 00:27:14,375] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:14,382] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:14,960] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.611 seconds
[2021-01-13 00:27:15,365] {scheduler_job.py:155} INFO - Started process (PID=197) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:15,379] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:15,383] {logging_mixin.py:112} INFO - [2021-01-13 00:27:15,382] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:15,405] {logging_mixin.py:112} INFO - [2021-01-13 00:27:15,403] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:15,407] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:15,897] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.532 seconds
[2021-01-13 00:27:16,354] {scheduler_job.py:155} INFO - Started process (PID=198) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:16,366] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:16,371] {logging_mixin.py:112} INFO - [2021-01-13 00:27:16,369] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:16,401] {logging_mixin.py:112} INFO - [2021-01-13 00:27:16,398] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:16,405] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:16,947] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.594 seconds
[2021-01-13 00:27:17,365] {scheduler_job.py:155} INFO - Started process (PID=199) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:17,371] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:17,373] {logging_mixin.py:112} INFO - [2021-01-13 00:27:17,373] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:17,392] {logging_mixin.py:112} INFO - [2021-01-13 00:27:17,388] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:17,393] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:17,985] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.620 seconds
[2021-01-13 00:27:18,489] {scheduler_job.py:155} INFO - Started process (PID=200) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:18,501] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:18,504] {logging_mixin.py:112} INFO - [2021-01-13 00:27:18,503] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:18,524] {logging_mixin.py:112} INFO - [2021-01-13 00:27:18,520] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:18,526] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:19,085] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.596 seconds
[2021-01-13 00:27:19,501] {scheduler_job.py:155} INFO - Started process (PID=201) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:19,506] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:19,508] {logging_mixin.py:112} INFO - [2021-01-13 00:27:19,508] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:19,526] {logging_mixin.py:112} INFO - [2021-01-13 00:27:19,523] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:19,528] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:20,092] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.591 seconds
[2021-01-13 00:27:20,520] {scheduler_job.py:155} INFO - Started process (PID=202) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:20,527] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:20,530] {logging_mixin.py:112} INFO - [2021-01-13 00:27:20,529] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:20,560] {logging_mixin.py:112} INFO - [2021-01-13 00:27:20,553] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:20,563] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:21,314] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.794 seconds
[2021-01-13 00:27:21,535] {scheduler_job.py:155} INFO - Started process (PID=203) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:21,546] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:21,550] {logging_mixin.py:112} INFO - [2021-01-13 00:27:21,549] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:21,584] {logging_mixin.py:112} INFO - [2021-01-13 00:27:21,579] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:21,586] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:22,112] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.577 seconds
[2021-01-13 00:27:22,551] {scheduler_job.py:155} INFO - Started process (PID=204) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:22,556] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:22,558] {logging_mixin.py:112} INFO - [2021-01-13 00:27:22,557] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:22,575] {logging_mixin.py:112} INFO - [2021-01-13 00:27:22,571] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:22,577] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:23,120] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.570 seconds
[2021-01-13 00:27:23,570] {scheduler_job.py:155} INFO - Started process (PID=205) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:23,580] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:23,587] {logging_mixin.py:112} INFO - [2021-01-13 00:27:23,586] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:23,625] {logging_mixin.py:112} INFO - [2021-01-13 00:27:23,612] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:23,628] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:24,157] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.586 seconds
[2021-01-13 00:27:24,575] {scheduler_job.py:155} INFO - Started process (PID=206) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:24,584] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:24,587] {logging_mixin.py:112} INFO - [2021-01-13 00:27:24,587] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:24,617] {logging_mixin.py:112} INFO - [2021-01-13 00:27:24,610] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:24,619] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:25,170] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.595 seconds
[2021-01-13 00:27:25,581] {scheduler_job.py:155} INFO - Started process (PID=207) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:25,587] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:25,589] {logging_mixin.py:112} INFO - [2021-01-13 00:27:25,589] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:25,607] {logging_mixin.py:112} INFO - [2021-01-13 00:27:25,605] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:25,609] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:26,146] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.565 seconds
[2021-01-13 00:27:26,597] {scheduler_job.py:155} INFO - Started process (PID=208) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:26,608] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:26,610] {logging_mixin.py:112} INFO - [2021-01-13 00:27:26,610] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:26,641] {logging_mixin.py:112} INFO - [2021-01-13 00:27:26,634] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:26,644] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:27,207] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.609 seconds
[2021-01-13 00:27:27,613] {scheduler_job.py:155} INFO - Started process (PID=209) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:27,626] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:27,628] {logging_mixin.py:112} INFO - [2021-01-13 00:27:27,628] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:27,648] {logging_mixin.py:112} INFO - [2021-01-13 00:27:27,644] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:27,650] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:28,244] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.631 seconds
[2021-01-13 00:27:28,730] {scheduler_job.py:155} INFO - Started process (PID=210) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:28,744] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:28,746] {logging_mixin.py:112} INFO - [2021-01-13 00:27:28,746] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:28,768] {logging_mixin.py:112} INFO - [2021-01-13 00:27:28,764] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:28,772] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:29,313] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.583 seconds
[2021-01-13 00:27:29,738] {scheduler_job.py:155} INFO - Started process (PID=211) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:29,745] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:29,747] {logging_mixin.py:112} INFO - [2021-01-13 00:27:29,747] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:29,766] {logging_mixin.py:112} INFO - [2021-01-13 00:27:29,763] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:29,769] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:30,388] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.650 seconds
[2021-01-13 00:27:30,763] {scheduler_job.py:155} INFO - Started process (PID=212) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:30,768] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:30,772] {logging_mixin.py:112} INFO - [2021-01-13 00:27:30,771] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:30,794] {logging_mixin.py:112} INFO - [2021-01-13 00:27:30,790] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:30,797] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:31,342] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.578 seconds
[2021-01-13 00:27:31,781] {scheduler_job.py:155} INFO - Started process (PID=213) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:31,786] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:31,788] {logging_mixin.py:112} INFO - [2021-01-13 00:27:31,788] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:31,808] {logging_mixin.py:112} INFO - [2021-01-13 00:27:31,803] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:31,809] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:32,329] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.549 seconds
[2021-01-13 00:27:32,805] {scheduler_job.py:155} INFO - Started process (PID=214) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:32,813] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:32,816] {logging_mixin.py:112} INFO - [2021-01-13 00:27:32,815] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:32,837] {logging_mixin.py:112} INFO - [2021-01-13 00:27:32,834] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:32,839] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:33,445] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.639 seconds
[2021-01-13 00:27:33,824] {scheduler_job.py:155} INFO - Started process (PID=215) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:33,829] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:33,832] {logging_mixin.py:112} INFO - [2021-01-13 00:27:33,831] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:33,851] {logging_mixin.py:112} INFO - [2021-01-13 00:27:33,848] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:33,852] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:34,411] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.587 seconds
[2021-01-13 00:27:34,840] {scheduler_job.py:155} INFO - Started process (PID=216) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:34,845] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:34,848] {logging_mixin.py:112} INFO - [2021-01-13 00:27:34,847] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:34,868] {logging_mixin.py:112} INFO - [2021-01-13 00:27:34,865] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:34,871] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:35,429] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.589 seconds
[2021-01-13 00:27:35,844] {scheduler_job.py:155} INFO - Started process (PID=217) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:35,850] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:35,853] {logging_mixin.py:112} INFO - [2021-01-13 00:27:35,853] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:35,873] {logging_mixin.py:112} INFO - [2021-01-13 00:27:35,870] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:35,875] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:36,411] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.567 seconds
[2021-01-13 00:27:36,872] {scheduler_job.py:155} INFO - Started process (PID=218) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:36,882] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:36,885] {logging_mixin.py:112} INFO - [2021-01-13 00:27:36,884] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:36,911] {logging_mixin.py:112} INFO - [2021-01-13 00:27:36,907] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:36,914] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:37,518] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.646 seconds
[2021-01-13 00:27:37,882] {scheduler_job.py:155} INFO - Started process (PID=219) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:37,890] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:37,894] {logging_mixin.py:112} INFO - [2021-01-13 00:27:37,893] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:37,948] {logging_mixin.py:112} INFO - [2021-01-13 00:27:37,939] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:37,951] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:38,543] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.660 seconds
[2021-01-13 00:27:39,011] {scheduler_job.py:155} INFO - Started process (PID=220) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:39,026] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:39,029] {logging_mixin.py:112} INFO - [2021-01-13 00:27:39,029] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:39,074] {logging_mixin.py:112} INFO - [2021-01-13 00:27:39,067] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:39,076] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:39,786] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.775 seconds
[2021-01-13 00:27:40,007] {scheduler_job.py:155} INFO - Started process (PID=221) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:40,011] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:40,014] {logging_mixin.py:112} INFO - [2021-01-13 00:27:40,014] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:40,037] {logging_mixin.py:112} INFO - [2021-01-13 00:27:40,032] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:40,041] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:40,600] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.594 seconds
[2021-01-13 00:27:41,016] {scheduler_job.py:155} INFO - Started process (PID=222) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:41,023] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:41,025] {logging_mixin.py:112} INFO - [2021-01-13 00:27:41,025] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:41,044] {logging_mixin.py:112} INFO - [2021-01-13 00:27:41,041] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:41,047] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:41,604] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.588 seconds
[2021-01-13 00:27:42,035] {scheduler_job.py:155} INFO - Started process (PID=223) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:42,045] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:42,048] {logging_mixin.py:112} INFO - [2021-01-13 00:27:42,048] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:42,069] {logging_mixin.py:112} INFO - [2021-01-13 00:27:42,065] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:42,071] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:42,620] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.585 seconds
[2021-01-13 00:27:43,047] {scheduler_job.py:155} INFO - Started process (PID=224) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:43,053] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:43,055] {logging_mixin.py:112} INFO - [2021-01-13 00:27:43,055] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:43,077] {logging_mixin.py:112} INFO - [2021-01-13 00:27:43,074] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:43,079] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:43,607] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.560 seconds
[2021-01-13 00:27:44,066] {scheduler_job.py:155} INFO - Started process (PID=225) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:44,073] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:44,075] {logging_mixin.py:112} INFO - [2021-01-13 00:27:44,075] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:44,097] {logging_mixin.py:112} INFO - [2021-01-13 00:27:44,093] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:44,098] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:44,676] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.611 seconds
[2021-01-13 00:27:45,083] {scheduler_job.py:155} INFO - Started process (PID=226) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:45,091] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:45,093] {logging_mixin.py:112} INFO - [2021-01-13 00:27:45,092] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:45,115] {logging_mixin.py:112} INFO - [2021-01-13 00:27:45,110] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:45,117] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:45,669] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.586 seconds
[2021-01-13 00:27:46,070] {scheduler_job.py:155} INFO - Started process (PID=227) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:46,083] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:46,085] {logging_mixin.py:112} INFO - [2021-01-13 00:27:46,085] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:46,126] {logging_mixin.py:112} INFO - [2021-01-13 00:27:46,121] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:46,128] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:46,626] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.556 seconds
[2021-01-13 00:27:47,092] {scheduler_job.py:155} INFO - Started process (PID=228) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:47,097] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:47,101] {logging_mixin.py:112} INFO - [2021-01-13 00:27:47,100] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:47,123] {logging_mixin.py:112} INFO - [2021-01-13 00:27:47,119] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:47,124] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:47,668] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.576 seconds
[2021-01-13 00:27:48,100] {scheduler_job.py:155} INFO - Started process (PID=229) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:48,105] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:48,107] {logging_mixin.py:112} INFO - [2021-01-13 00:27:48,107] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:48,125] {logging_mixin.py:112} INFO - [2021-01-13 00:27:48,121] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:48,126] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:48,657] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.557 seconds
[2021-01-13 00:27:49,225] {scheduler_job.py:155} INFO - Started process (PID=230) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:49,236] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:49,239] {logging_mixin.py:112} INFO - [2021-01-13 00:27:49,238] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:49,268] {logging_mixin.py:112} INFO - [2021-01-13 00:27:49,262] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:49,269] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:49,843] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.618 seconds
[2021-01-13 00:27:50,233] {scheduler_job.py:155} INFO - Started process (PID=231) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:50,239] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:50,241] {logging_mixin.py:112} INFO - [2021-01-13 00:27:50,241] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:50,259] {logging_mixin.py:112} INFO - [2021-01-13 00:27:50,255] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:50,261] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:50,866] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.632 seconds
[2021-01-13 00:27:51,251] {scheduler_job.py:155} INFO - Started process (PID=232) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:51,257] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:51,260] {logging_mixin.py:112} INFO - [2021-01-13 00:27:51,259] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:51,280] {logging_mixin.py:112} INFO - [2021-01-13 00:27:51,276] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:51,282] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:51,771] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.519 seconds
[2021-01-13 00:27:52,268] {scheduler_job.py:155} INFO - Started process (PID=233) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:52,274] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:52,277] {logging_mixin.py:112} INFO - [2021-01-13 00:27:52,276] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:52,300] {logging_mixin.py:112} INFO - [2021-01-13 00:27:52,295] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:52,302] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:52,806] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.539 seconds
[2021-01-13 00:27:53,278] {scheduler_job.py:155} INFO - Started process (PID=234) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:53,284] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:53,286] {logging_mixin.py:112} INFO - [2021-01-13 00:27:53,286] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:53,307] {logging_mixin.py:112} INFO - [2021-01-13 00:27:53,303] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:53,309] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:53,850] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.573 seconds
[2021-01-13 00:27:54,292] {scheduler_job.py:155} INFO - Started process (PID=235) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:54,298] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:54,300] {logging_mixin.py:112} INFO - [2021-01-13 00:27:54,300] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:54,318] {logging_mixin.py:112} INFO - [2021-01-13 00:27:54,315] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:54,319] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:54,879] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.587 seconds
[2021-01-13 00:27:55,310] {scheduler_job.py:155} INFO - Started process (PID=236) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:55,323] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:55,326] {logging_mixin.py:112} INFO - [2021-01-13 00:27:55,326] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:55,348] {logging_mixin.py:112} INFO - [2021-01-13 00:27:55,345] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:55,350] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:55,899] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.588 seconds
[2021-01-13 00:27:56,330] {scheduler_job.py:155} INFO - Started process (PID=237) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:56,335] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:56,341] {logging_mixin.py:112} INFO - [2021-01-13 00:27:56,341] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:56,374] {logging_mixin.py:112} INFO - [2021-01-13 00:27:56,367] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:56,378] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:56,937] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.608 seconds
[2021-01-13 00:27:57,341] {scheduler_job.py:155} INFO - Started process (PID=238) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:57,346] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:57,348] {logging_mixin.py:112} INFO - [2021-01-13 00:27:57,348] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:57,369] {logging_mixin.py:112} INFO - [2021-01-13 00:27:57,366] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:57,371] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:57,918] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.576 seconds
[2021-01-13 00:27:58,366] {scheduler_job.py:155} INFO - Started process (PID=239) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:58,371] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:58,375] {logging_mixin.py:112} INFO - [2021-01-13 00:27:58,374] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:58,416] {logging_mixin.py:112} INFO - [2021-01-13 00:27:58,402] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:58,418] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:27:58,966] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.600 seconds
[2021-01-13 00:27:59,499] {scheduler_job.py:155} INFO - Started process (PID=240) to work on /opt/airflow/dags/example.py
[2021-01-13 00:27:59,508] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:27:59,511] {logging_mixin.py:112} INFO - [2021-01-13 00:27:59,510] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:27:59,535] {logging_mixin.py:112} INFO - [2021-01-13 00:27:59,530] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:27:59,539] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:28:00,177] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.678 seconds
[2021-01-13 00:28:00,518] {scheduler_job.py:155} INFO - Started process (PID=241) to work on /opt/airflow/dags/example.py
[2021-01-13 00:28:00,523] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:28:00,525] {logging_mixin.py:112} INFO - [2021-01-13 00:28:00,525] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:28:00,543] {logging_mixin.py:112} INFO - [2021-01-13 00:28:00,541] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:28:00,545] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:28:01,097] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.580 seconds
[2021-01-13 00:28:01,543] {scheduler_job.py:155} INFO - Started process (PID=242) to work on /opt/airflow/dags/example.py
[2021-01-13 00:28:01,559] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:28:01,564] {logging_mixin.py:112} INFO - [2021-01-13 00:28:01,563] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:28:01,597] {logging_mixin.py:112} INFO - [2021-01-13 00:28:01,593] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:28:01,600] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:28:02,285] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.741 seconds
[2021-01-13 00:28:02,557] {scheduler_job.py:155} INFO - Started process (PID=243) to work on /opt/airflow/dags/example.py
[2021-01-13 00:28:02,564] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:28:02,567] {logging_mixin.py:112} INFO - [2021-01-13 00:28:02,567] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:28:02,598] {logging_mixin.py:112} INFO - [2021-01-13 00:28:02,593] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:28:02,599] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:28:03,106] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.550 seconds
[2021-01-13 00:28:03,564] {scheduler_job.py:155} INFO - Started process (PID=244) to work on /opt/airflow/dags/example.py
[2021-01-13 00:28:03,573] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:28:03,575] {logging_mixin.py:112} INFO - [2021-01-13 00:28:03,575] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:28:03,622] {logging_mixin.py:112} INFO - [2021-01-13 00:28:03,617] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:28:03,624] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:28:04,250] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.686 seconds
[2021-01-13 00:28:04,580] {scheduler_job.py:155} INFO - Started process (PID=245) to work on /opt/airflow/dags/example.py
[2021-01-13 00:28:04,594] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:28:04,596] {logging_mixin.py:112} INFO - [2021-01-13 00:28:04,596] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:28:04,630] {logging_mixin.py:112} INFO - [2021-01-13 00:28:04,626] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:28:04,631] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:28:05,182] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.602 seconds
[2021-01-13 00:28:05,600] {scheduler_job.py:155} INFO - Started process (PID=246) to work on /opt/airflow/dags/example.py
[2021-01-13 00:28:05,611] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:28:05,618] {logging_mixin.py:112} INFO - [2021-01-13 00:28:05,617] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:28:05,669] {logging_mixin.py:112} INFO - [2021-01-13 00:28:05,659] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:28:05,673] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:28:06,217] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.616 seconds
[2021-01-13 00:28:06,608] {scheduler_job.py:155} INFO - Started process (PID=247) to work on /opt/airflow/dags/example.py
[2021-01-13 00:28:06,624] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:28:06,627] {logging_mixin.py:112} INFO - [2021-01-13 00:28:06,627] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:28:06,669] {logging_mixin.py:112} INFO - [2021-01-13 00:28:06,662] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:28:06,673] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:28:07,350] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.743 seconds
[2021-01-13 00:28:07,624] {scheduler_job.py:155} INFO - Started process (PID=248) to work on /opt/airflow/dags/example.py
[2021-01-13 00:28:07,634] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:28:07,637] {logging_mixin.py:112} INFO - [2021-01-13 00:28:07,637] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:28:07,670] {logging_mixin.py:112} INFO - [2021-01-13 00:28:07,662] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:28:07,672] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:28:08,207] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.583 seconds
[2021-01-13 00:28:08,649] {scheduler_job.py:155} INFO - Started process (PID=249) to work on /opt/airflow/dags/example.py
[2021-01-13 00:28:08,667] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:28:08,674] {logging_mixin.py:112} INFO - [2021-01-13 00:28:08,674] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:28:08,784] {logging_mixin.py:112} INFO - [2021-01-13 00:28:08,778] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:28:08,787] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:28:09,363] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.715 seconds
[2021-01-13 00:28:09,772] {scheduler_job.py:155} INFO - Started process (PID=250) to work on /opt/airflow/dags/example.py
[2021-01-13 00:28:09,778] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:28:09,780] {logging_mixin.py:112} INFO - [2021-01-13 00:28:09,780] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:28:09,800] {logging_mixin.py:112} INFO - [2021-01-13 00:28:09,797] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:28:09,802] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:28:10,303] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.531 seconds
[2021-01-13 00:28:10,790] {scheduler_job.py:155} INFO - Started process (PID=251) to work on /opt/airflow/dags/example.py
[2021-01-13 00:28:10,799] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:28:10,802] {logging_mixin.py:112} INFO - [2021-01-13 00:28:10,801] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:28:10,828] {logging_mixin.py:112} INFO - [2021-01-13 00:28:10,823] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:28:10,830] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:28:11,345] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.554 seconds
[2021-01-13 00:28:11,810] {scheduler_job.py:155} INFO - Started process (PID=252) to work on /opt/airflow/dags/example.py
[2021-01-13 00:28:11,824] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:28:11,828] {logging_mixin.py:112} INFO - [2021-01-13 00:28:11,827] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:28:11,934] {logging_mixin.py:112} INFO - [2021-01-13 00:28:11,869] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:28:11,937] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:28:12,482] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.673 seconds
[2021-01-13 00:28:12,801] {scheduler_job.py:155} INFO - Started process (PID=253) to work on /opt/airflow/dags/example.py
[2021-01-13 00:28:12,810] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:28:12,812] {logging_mixin.py:112} INFO - [2021-01-13 00:28:12,812] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:28:12,841] {logging_mixin.py:112} INFO - [2021-01-13 00:28:12,834] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:28:12,843] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:28:13,408] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.606 seconds
[2021-01-13 00:28:13,819] {scheduler_job.py:155} INFO - Started process (PID=254) to work on /opt/airflow/dags/example.py
[2021-01-13 00:28:13,833] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:28:13,835] {logging_mixin.py:112} INFO - [2021-01-13 00:28:13,835] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:28:13,854] {logging_mixin.py:112} INFO - [2021-01-13 00:28:13,851] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:28:13,857] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:28:14,428] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.609 seconds
[2021-01-13 00:28:14,837] {scheduler_job.py:155} INFO - Started process (PID=255) to work on /opt/airflow/dags/example.py
[2021-01-13 00:28:14,846] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:28:14,851] {logging_mixin.py:112} INFO - [2021-01-13 00:28:14,850] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:28:14,894] {logging_mixin.py:112} INFO - [2021-01-13 00:28:14,885] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:28:14,896] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:28:15,502] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.665 seconds
[2021-01-13 00:28:15,836] {scheduler_job.py:155} INFO - Started process (PID=256) to work on /opt/airflow/dags/example.py
[2021-01-13 00:28:15,848] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:28:15,853] {logging_mixin.py:112} INFO - [2021-01-13 00:28:15,853] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:28:15,894] {logging_mixin.py:112} INFO - [2021-01-13 00:28:15,887] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:28:15,896] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:28:16,473] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.637 seconds
[2021-01-13 00:28:16,820] {scheduler_job.py:155} INFO - Started process (PID=257) to work on /opt/airflow/dags/example.py
[2021-01-13 00:28:16,826] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:28:16,830] {logging_mixin.py:112} INFO - [2021-01-13 00:28:16,829] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:28:16,853] {logging_mixin.py:112} INFO - [2021-01-13 00:28:16,850] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:28:16,855] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:28:17,468] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.649 seconds
[2021-01-13 00:28:17,840] {scheduler_job.py:155} INFO - Started process (PID=258) to work on /opt/airflow/dags/example.py
[2021-01-13 00:28:17,849] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:28:17,851] {logging_mixin.py:112} INFO - [2021-01-13 00:28:17,850] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:28:17,872] {logging_mixin.py:112} INFO - [2021-01-13 00:28:17,867] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 6, in <module>
    from scripts.test import run_pipeline
ModuleNotFoundError: No module named 'scripts'
[2021-01-13 00:28:17,874] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:28:18,443] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.603 seconds
[2021-01-13 00:28:37,302] {scheduler_job.py:155} INFO - Started process (PID=16) to work on /opt/airflow/dags/example.py
[2021-01-13 00:28:37,311] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:28:37,315] {logging_mixin.py:112} INFO - [2021-01-13 00:28:37,315] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:28:37,365] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:28:38,083] {logging_mixin.py:112} INFO - [2021-01-13 00:28:38,083] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 00:28:38,134] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 00:28:37.367468+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "*/5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 00:28:37.367468+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "*/5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 0, 28, 37, 367468, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"*/5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 00:28:38,351] {scheduler_job.py:155} INFO - Started process (PID=17) to work on /opt/airflow/dags/example.py
[2021-01-13 00:28:38,360] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:28:38,363] {logging_mixin.py:112} INFO - [2021-01-13 00:28:38,362] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:28:38,410] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:28:38,899] {logging_mixin.py:112} INFO - [2021-01-13 00:28:38,899] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 00:28:38,952] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 00:28:38.412113+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "*/5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 00:28:38.412113+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "*/5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 0, 28, 38, 412113, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"*/5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 00:28:39,362] {scheduler_job.py:155} INFO - Started process (PID=18) to work on /opt/airflow/dags/example.py
[2021-01-13 00:28:39,367] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:28:39,369] {logging_mixin.py:112} INFO - [2021-01-13 00:28:39,369] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:28:39,396] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:28:39,885] {logging_mixin.py:112} INFO - [2021-01-13 00:28:39,884] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 00:28:39,939] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 00:28:39.398088+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "*/5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 00:28:39.398088+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "*/5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 0, 28, 39, 398088, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"*/5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 00:28:40,396] {scheduler_job.py:155} INFO - Started process (PID=19) to work on /opt/airflow/dags/example.py
[2021-01-13 00:28:40,406] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:28:40,408] {logging_mixin.py:112} INFO - [2021-01-13 00:28:40,408] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:28:40,438] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:28:40,921] {logging_mixin.py:112} INFO - [2021-01-13 00:28:40,921] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 00:28:40,977] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 00:28:40.439601+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "*/5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 00:28:40.439601+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "*/5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 0, 28, 40, 439601, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"*/5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 00:28:41,412] {scheduler_job.py:155} INFO - Started process (PID=20) to work on /opt/airflow/dags/example.py
[2021-01-13 00:28:41,417] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:28:41,419] {logging_mixin.py:112} INFO - [2021-01-13 00:28:41,419] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:28:41,446] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:28:41,949] {logging_mixin.py:112} INFO - [2021-01-13 00:28:41,948] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 00:28:42,003] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 00:28:41.448648+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "*/5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 00:28:41.448648+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "*/5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 0, 28, 41, 448648, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"*/5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 00:28:42,435] {scheduler_job.py:155} INFO - Started process (PID=21) to work on /opt/airflow/dags/example.py
[2021-01-13 00:28:42,441] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:28:42,444] {logging_mixin.py:112} INFO - [2021-01-13 00:28:42,443] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:28:42,480] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:28:42,965] {logging_mixin.py:112} INFO - [2021-01-13 00:28:42,964] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 00:28:43,011] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 00:28:42.481681+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "*/5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 00:28:42.481681+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "*/5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 0, 28, 42, 481681, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"*/5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 00:28:43,454] {scheduler_job.py:155} INFO - Started process (PID=22) to work on /opt/airflow/dags/example.py
[2021-01-13 00:28:43,460] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:28:43,462] {logging_mixin.py:112} INFO - [2021-01-13 00:28:43,462] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:28:43,492] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:28:44,085] {logging_mixin.py:112} INFO - [2021-01-13 00:28:44,084] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 00:28:44,140] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 00:28:43.494033+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "*/5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 00:28:43.494033+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "*/5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 0, 28, 43, 494033, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"*/5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 00:28:44,470] {scheduler_job.py:155} INFO - Started process (PID=23) to work on /opt/airflow/dags/example.py
[2021-01-13 00:28:44,476] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:28:44,478] {logging_mixin.py:112} INFO - [2021-01-13 00:28:44,478] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:28:44,507] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:28:44,995] {logging_mixin.py:112} INFO - [2021-01-13 00:28:44,995] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 00:28:45,052] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 00:28:44.508389+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "*/5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 00:28:44.508389+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "*/5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 0, 28, 44, 508389, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"*/5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 00:28:45,492] {scheduler_job.py:155} INFO - Started process (PID=24) to work on /opt/airflow/dags/example.py
[2021-01-13 00:28:45,497] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:28:45,499] {logging_mixin.py:112} INFO - [2021-01-13 00:28:45,498] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:28:45,529] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:28:45,977] {logging_mixin.py:112} INFO - [2021-01-13 00:28:45,977] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 00:28:46,037] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 00:28:45.531016+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "*/5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 00:28:45.531016+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "*/5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 0, 28, 45, 531016, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"*/5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 00:28:46,483] {scheduler_job.py:155} INFO - Started process (PID=25) to work on /opt/airflow/dags/example.py
[2021-01-13 00:28:46,489] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:28:46,492] {logging_mixin.py:112} INFO - [2021-01-13 00:28:46,491] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:28:46,535] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:28:47,177] {logging_mixin.py:112} INFO - [2021-01-13 00:28:47,176] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 00:28:47,226] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 00:28:46.53871+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "*/5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 00:28:46.53871+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "*/5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 0, 28, 46, 538710, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"*/5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 00:28:47,666] {scheduler_job.py:155} INFO - Started process (PID=26) to work on /opt/airflow/dags/example.py
[2021-01-13 00:28:47,671] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:28:47,673] {logging_mixin.py:112} INFO - [2021-01-13 00:28:47,673] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:28:47,701] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:28:48,185] {logging_mixin.py:112} INFO - [2021-01-13 00:28:48,184] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 00:28:48,246] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 00:28:47.702571+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "*/5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 00:28:47.702571+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "*/5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 0, 28, 47, 702571, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"*/5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 00:28:48,690] {scheduler_job.py:155} INFO - Started process (PID=27) to work on /opt/airflow/dags/example.py
[2021-01-13 00:28:48,699] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:28:48,701] {logging_mixin.py:112} INFO - [2021-01-13 00:28:48,701] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:28:48,741] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:28:49,231] {logging_mixin.py:112} INFO - [2021-01-13 00:28:49,230] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 00:28:49,289] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 00:28:48.743636+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "*/5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 00:28:48.743636+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "*/5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 0, 28, 48, 743636, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"*/5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 00:28:49,710] {scheduler_job.py:155} INFO - Started process (PID=28) to work on /opt/airflow/dags/example.py
[2021-01-13 00:28:49,715] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:28:49,716] {logging_mixin.py:112} INFO - [2021-01-13 00:28:49,716] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:28:49,745] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:28:50,247] {logging_mixin.py:112} INFO - [2021-01-13 00:28:50,246] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 00:28:50,300] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 00:28:49.748208+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "*/5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 00:28:49.748208+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "*/5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 0, 28, 49, 748208, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"*/5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 00:28:50,730] {scheduler_job.py:155} INFO - Started process (PID=29) to work on /opt/airflow/dags/example.py
[2021-01-13 00:28:50,736] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 00:28:50,739] {logging_mixin.py:112} INFO - [2021-01-13 00:28:50,739] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 00:28:50,777] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 00:28:51,090] {scheduler_job.py:423} INFO - Exiting gracefully upon receiving signal 15
[2021-01-13 09:29:23,686] {scheduler_job.py:155} INFO - Started process (PID=15) to work on /opt/airflow/dags/example.py
[2021-01-13 09:29:23,711] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:29:23,721] {logging_mixin.py:112} INFO - [2021-01-13 09:29:23,720] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:29:23,820] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:29:24,341] {logging_mixin.py:112} INFO - [2021-01-13 09:29:24,341] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:29:24,398] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:23.823047+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:23.823047+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 29, 23, 823047, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:29:24,751] {scheduler_job.py:155} INFO - Started process (PID=16) to work on /opt/airflow/dags/example.py
[2021-01-13 09:29:24,757] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:29:24,760] {logging_mixin.py:112} INFO - [2021-01-13 09:29:24,760] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:29:24,831] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:29:25,433] {logging_mixin.py:112} INFO - [2021-01-13 09:29:25,432] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:29:25,503] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:24.833925+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:24.833925+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 29, 24, 833925, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:29:25,795] {scheduler_job.py:155} INFO - Started process (PID=17) to work on /opt/airflow/dags/example.py
[2021-01-13 09:29:25,814] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:29:25,826] {logging_mixin.py:112} INFO - [2021-01-13 09:29:25,825] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:29:25,966] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:29:26,763] {logging_mixin.py:112} INFO - [2021-01-13 09:29:26,763] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:29:26,856] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:25.970122+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:25.970122+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 29, 25, 970122, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:29:27,828] {scheduler_job.py:155} INFO - Started process (PID=18) to work on /opt/airflow/dags/example.py
[2021-01-13 09:29:27,848] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:29:27,851] {logging_mixin.py:112} INFO - [2021-01-13 09:29:27,851] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:29:27,965] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:29:28,595] {logging_mixin.py:112} INFO - [2021-01-13 09:29:28,594] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:29:28,664] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:27.969513+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:27.969513+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 29, 27, 969513, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:29:29,132] {scheduler_job.py:155} INFO - Started process (PID=19) to work on /opt/airflow/dags/example.py
[2021-01-13 09:29:29,166] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:29:29,179] {logging_mixin.py:112} INFO - [2021-01-13 09:29:29,177] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:29:29,284] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:29:29,950] {logging_mixin.py:112} INFO - [2021-01-13 09:29:29,950] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:29:30,149] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:29.294109+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:29.294109+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 29, 29, 294109, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:29:30,859] {scheduler_job.py:155} INFO - Started process (PID=20) to work on /opt/airflow/dags/example.py
[2021-01-13 09:29:30,889] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:29:30,899] {logging_mixin.py:112} INFO - [2021-01-13 09:29:30,898] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:29:30,982] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:29:31,819] {logging_mixin.py:112} INFO - [2021-01-13 09:29:31,819] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:29:31,943] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:30.985142+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:30.985142+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 29, 30, 985142, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:29:32,858] {scheduler_job.py:155} INFO - Started process (PID=21) to work on /opt/airflow/dags/example.py
[2021-01-13 09:29:32,878] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:29:32,887] {logging_mixin.py:112} INFO - [2021-01-13 09:29:32,886] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:29:32,972] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:29:33,700] {logging_mixin.py:112} INFO - [2021-01-13 09:29:33,700] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:29:33,774] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:32.977161+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:32.977161+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 29, 32, 977161, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:29:34,243] {scheduler_job.py:155} INFO - Started process (PID=22) to work on /opt/airflow/dags/example.py
[2021-01-13 09:29:34,255] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:29:34,259] {logging_mixin.py:112} INFO - [2021-01-13 09:29:34,258] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:29:34,324] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:29:34,830] {logging_mixin.py:112} INFO - [2021-01-13 09:29:34,829] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:29:34,911] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:34.327377+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:34.327377+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 29, 34, 327377, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:29:35,247] {scheduler_job.py:155} INFO - Started process (PID=23) to work on /opt/airflow/dags/example.py
[2021-01-13 09:29:35,257] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:29:35,261] {logging_mixin.py:112} INFO - [2021-01-13 09:29:35,260] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:29:35,319] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:29:35,902] {logging_mixin.py:112} INFO - [2021-01-13 09:29:35,902] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:29:35,976] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:35.323166+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:35.323166+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 29, 35, 323166, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:29:36,365] {scheduler_job.py:155} INFO - Started process (PID=24) to work on /opt/airflow/dags/example.py
[2021-01-13 09:29:36,372] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:29:36,377] {logging_mixin.py:112} INFO - [2021-01-13 09:29:36,377] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:29:36,475] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:29:37,089] {logging_mixin.py:112} INFO - [2021-01-13 09:29:37,089] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:29:37,183] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:36.485979+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:36.485979+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 29, 36, 485979, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:29:37,340] {scheduler_job.py:155} INFO - Started process (PID=25) to work on /opt/airflow/dags/example.py
[2021-01-13 09:29:37,350] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:29:37,352] {logging_mixin.py:112} INFO - [2021-01-13 09:29:37,352] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:29:37,409] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:29:37,943] {logging_mixin.py:112} INFO - [2021-01-13 09:29:37,943] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:29:38,003] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:37.412188+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:37.412188+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 29, 37, 412188, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:29:38,354] {scheduler_job.py:155} INFO - Started process (PID=26) to work on /opt/airflow/dags/example.py
[2021-01-13 09:29:38,368] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:29:38,371] {logging_mixin.py:112} INFO - [2021-01-13 09:29:38,371] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:29:38,424] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:29:38,995] {logging_mixin.py:112} INFO - [2021-01-13 09:29:38,995] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:29:39,070] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:38.427156+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:38.427156+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 29, 38, 427156, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:29:39,373] {scheduler_job.py:155} INFO - Started process (PID=27) to work on /opt/airflow/dags/example.py
[2021-01-13 09:29:39,391] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:29:39,399] {logging_mixin.py:112} INFO - [2021-01-13 09:29:39,399] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:29:39,450] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:29:40,215] {logging_mixin.py:112} INFO - [2021-01-13 09:29:40,214] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:29:40,275] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:39.452545+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:39.452545+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 29, 39, 452545, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:29:40,388] {scheduler_job.py:155} INFO - Started process (PID=28) to work on /opt/airflow/dags/example.py
[2021-01-13 09:29:40,401] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:29:40,406] {logging_mixin.py:112} INFO - [2021-01-13 09:29:40,406] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:29:40,471] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:29:40,953] {logging_mixin.py:112} INFO - [2021-01-13 09:29:40,953] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:29:41,019] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:40.477512+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:40.477512+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 29, 40, 477512, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:29:41,425] {scheduler_job.py:155} INFO - Started process (PID=29) to work on /opt/airflow/dags/example.py
[2021-01-13 09:29:41,443] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:29:41,449] {logging_mixin.py:112} INFO - [2021-01-13 09:29:41,447] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:29:41,518] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:29:42,071] {logging_mixin.py:112} INFO - [2021-01-13 09:29:42,071] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:29:42,146] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:41.52157+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:41.52157+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 29, 41, 521570, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:29:42,449] {scheduler_job.py:155} INFO - Started process (PID=30) to work on /opt/airflow/dags/example.py
[2021-01-13 09:29:42,458] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:29:42,461] {logging_mixin.py:112} INFO - [2021-01-13 09:29:42,461] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:29:42,512] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:29:43,131] {logging_mixin.py:112} INFO - [2021-01-13 09:29:43,131] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:29:43,191] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:42.514126+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:42.514126+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 29, 42, 514126, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:29:43,470] {scheduler_job.py:155} INFO - Started process (PID=31) to work on /opt/airflow/dags/example.py
[2021-01-13 09:29:43,477] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:29:43,482] {logging_mixin.py:112} INFO - [2021-01-13 09:29:43,482] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:29:43,536] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:29:44,239] {logging_mixin.py:112} INFO - [2021-01-13 09:29:44,239] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:29:44,312] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:43.538133+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:43.538133+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 29, 43, 538133, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:29:44,627] {scheduler_job.py:155} INFO - Started process (PID=32) to work on /opt/airflow/dags/example.py
[2021-01-13 09:29:44,633] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:29:44,636] {logging_mixin.py:112} INFO - [2021-01-13 09:29:44,636] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:29:44,687] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:29:45,338] {logging_mixin.py:112} INFO - [2021-01-13 09:29:45,338] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:29:45,405] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:44.691424+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:44.691424+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 29, 44, 691424, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:29:45,657] {scheduler_job.py:155} INFO - Started process (PID=33) to work on /opt/airflow/dags/example.py
[2021-01-13 09:29:45,668] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:29:45,672] {logging_mixin.py:112} INFO - [2021-01-13 09:29:45,671] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:29:45,736] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:29:46,384] {logging_mixin.py:112} INFO - [2021-01-13 09:29:46,384] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:29:46,446] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:45.73803+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:45.73803+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 29, 45, 738030, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:29:46,700] {scheduler_job.py:155} INFO - Started process (PID=34) to work on /opt/airflow/dags/example.py
[2021-01-13 09:29:46,711] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:29:46,715] {logging_mixin.py:112} INFO - [2021-01-13 09:29:46,714] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:29:46,797] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:29:47,403] {logging_mixin.py:112} INFO - [2021-01-13 09:29:47,403] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:29:47,467] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:46.801404+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:46.801404+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 29, 46, 801404, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:29:47,743] {scheduler_job.py:155} INFO - Started process (PID=35) to work on /opt/airflow/dags/example.py
[2021-01-13 09:29:47,757] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:29:47,762] {logging_mixin.py:112} INFO - [2021-01-13 09:29:47,761] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:29:47,825] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:29:48,481] {logging_mixin.py:112} INFO - [2021-01-13 09:29:48,481] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:29:48,531] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:47.829554+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:47.829554+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 29, 47, 829554, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:29:48,747] {scheduler_job.py:155} INFO - Started process (PID=36) to work on /opt/airflow/dags/example.py
[2021-01-13 09:29:48,758] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:29:48,761] {logging_mixin.py:112} INFO - [2021-01-13 09:29:48,760] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:29:48,818] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:29:49,608] {logging_mixin.py:112} INFO - [2021-01-13 09:29:49,608] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:29:49,666] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:48.824529+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:48.824529+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 29, 48, 824529, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:29:49,770] {scheduler_job.py:155} INFO - Started process (PID=37) to work on /opt/airflow/dags/example.py
[2021-01-13 09:29:49,779] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:29:49,782] {logging_mixin.py:112} INFO - [2021-01-13 09:29:49,782] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:29:49,834] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:29:50,376] {logging_mixin.py:112} INFO - [2021-01-13 09:29:50,375] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:29:50,444] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:49.83722+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:49.83722+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 29, 49, 837220, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:29:50,787] {scheduler_job.py:155} INFO - Started process (PID=38) to work on /opt/airflow/dags/example.py
[2021-01-13 09:29:50,798] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:29:50,803] {logging_mixin.py:112} INFO - [2021-01-13 09:29:50,802] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:29:50,870] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:29:51,530] {logging_mixin.py:112} INFO - [2021-01-13 09:29:51,529] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:29:51,810] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:50.875485+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:50.875485+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 29, 50, 875485, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:29:52,818] {scheduler_job.py:155} INFO - Started process (PID=39) to work on /opt/airflow/dags/example.py
[2021-01-13 09:29:52,826] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:29:52,831] {logging_mixin.py:112} INFO - [2021-01-13 09:29:52,830] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:29:52,869] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:29:53,388] {logging_mixin.py:112} INFO - [2021-01-13 09:29:53,388] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:29:53,605] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:52.871544+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:29:52.871544+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 29, 52, 871544, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:29:53,837] {scheduler_job.py:155} INFO - Started process (PID=40) to work on /opt/airflow/dags/example.py
[2021-01-13 09:29:53,845] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:29:53,848] {logging_mixin.py:112} INFO - [2021-01-13 09:29:53,848] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:29:53,900] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:29:54,195] {scheduler_job.py:423} INFO - Exiting gracefully upon receiving signal 15
[2021-01-13 09:35:26,227] {scheduler_job.py:155} INFO - Started process (PID=15) to work on /opt/airflow/dags/example.py
[2021-01-13 09:35:26,241] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:35:26,254] {logging_mixin.py:112} INFO - [2021-01-13 09:35:26,254] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:35:26,320] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:35:26,813] {logging_mixin.py:112} INFO - [2021-01-13 09:35:26,813] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:35:26,880] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:35:26.323048+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:35:26.323048+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 35, 26, 323048, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:35:27,303] {scheduler_job.py:155} INFO - Started process (PID=16) to work on /opt/airflow/dags/example.py
[2021-01-13 09:35:27,317] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:35:27,321] {logging_mixin.py:112} INFO - [2021-01-13 09:35:27,320] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:35:27,375] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:35:28,121] {logging_mixin.py:112} INFO - [2021-01-13 09:35:28,121] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:35:28,193] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:35:27.377817+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:35:27.377817+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 35, 27, 377817, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:35:28,315] {scheduler_job.py:155} INFO - Started process (PID=17) to work on /opt/airflow/dags/example.py
[2021-01-13 09:35:28,322] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:35:28,325] {logging_mixin.py:112} INFO - [2021-01-13 09:35:28,325] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:35:28,405] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:35:29,120] {logging_mixin.py:112} INFO - [2021-01-13 09:35:29,120] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:35:29,187] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:35:28.407573+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:35:28.407573+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 35, 28, 407573, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:35:29,333] {scheduler_job.py:155} INFO - Started process (PID=18) to work on /opt/airflow/dags/example.py
[2021-01-13 09:35:29,353] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:35:29,357] {logging_mixin.py:112} INFO - [2021-01-13 09:35:29,356] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:35:29,404] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:35:29,915] {logging_mixin.py:112} INFO - [2021-01-13 09:35:29,915] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:35:29,965] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:35:29.407897+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:35:29.407897+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 35, 29, 407897, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:35:30,400] {scheduler_job.py:155} INFO - Started process (PID=19) to work on /opt/airflow/dags/example.py
[2021-01-13 09:35:30,428] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:35:30,430] {logging_mixin.py:112} INFO - [2021-01-13 09:35:30,430] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:35:30,531] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:35:39,860] {logging_mixin.py:112} INFO - [2021-01-13 09:35:39,860] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:35:39,923] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:35:30.534018+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:35:30.534018+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 35, 30, 534018, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:35:40,561] {scheduler_job.py:155} INFO - Started process (PID=20) to work on /opt/airflow/dags/example.py
[2021-01-13 09:35:40,567] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:35:40,569] {logging_mixin.py:112} INFO - [2021-01-13 09:35:40,569] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:35:40,608] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:35:41,193] {logging_mixin.py:112} INFO - [2021-01-13 09:35:41,193] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:35:41,254] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:35:40.610909+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:35:40.610909+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 35, 40, 610909, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:35:41,572] {scheduler_job.py:155} INFO - Started process (PID=21) to work on /opt/airflow/dags/example.py
[2021-01-13 09:35:41,580] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:35:41,583] {logging_mixin.py:112} INFO - [2021-01-13 09:35:41,582] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:35:41,623] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:35:42,400] {logging_mixin.py:112} INFO - [2021-01-13 09:35:42,399] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:35:42,454] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:35:41.625466+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:35:41.625466+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 35, 41, 625466, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:35:42,597] {scheduler_job.py:155} INFO - Started process (PID=22) to work on /opt/airflow/dags/example.py
[2021-01-13 09:35:42,605] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:35:42,608] {logging_mixin.py:112} INFO - [2021-01-13 09:35:42,607] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:35:42,652] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:35:43,204] {logging_mixin.py:112} INFO - [2021-01-13 09:35:43,204] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:35:43,308] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:35:42.653644+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:35:42.653644+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 35, 42, 653644, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:35:43,611] {scheduler_job.py:155} INFO - Started process (PID=23) to work on /opt/airflow/dags/example.py
[2021-01-13 09:35:43,618] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:35:43,621] {logging_mixin.py:112} INFO - [2021-01-13 09:35:43,621] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:35:43,657] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:35:44,288] {logging_mixin.py:112} INFO - [2021-01-13 09:35:44,287] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:35:44,360] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:35:43.658744+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:35:43.658744+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 35, 43, 658744, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:35:44,639] {scheduler_job.py:155} INFO - Started process (PID=24) to work on /opt/airflow/dags/example.py
[2021-01-13 09:35:44,653] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:35:44,659] {logging_mixin.py:112} INFO - [2021-01-13 09:35:44,658] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:35:44,712] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:35:45,361] {logging_mixin.py:112} INFO - [2021-01-13 09:35:45,361] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:35:45,427] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:35:44.715494+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:35:44.715494+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 35, 44, 715494, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:35:45,686] {scheduler_job.py:155} INFO - Started process (PID=25) to work on /opt/airflow/dags/example.py
[2021-01-13 09:35:45,695] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:35:45,699] {logging_mixin.py:112} INFO - [2021-01-13 09:35:45,699] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:35:45,751] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:35:46,292] {logging_mixin.py:112} INFO - [2021-01-13 09:35:46,292] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:35:46,346] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:35:45.757781+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:35:45.757781+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 35, 45, 757781, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:35:46,808] {scheduler_job.py:155} INFO - Started process (PID=26) to work on /opt/airflow/dags/example.py
[2021-01-13 09:35:46,816] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:35:46,819] {logging_mixin.py:112} INFO - [2021-01-13 09:35:46,819] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:35:46,856] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:35:47,536] {logging_mixin.py:112} INFO - [2021-01-13 09:35:47,535] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:35:47,598] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:35:46.858493+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:35:46.858493+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 35, 46, 858493, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:35:47,839] {scheduler_job.py:155} INFO - Started process (PID=27) to work on /opt/airflow/dags/example.py
[2021-01-13 09:35:47,845] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:35:47,847] {logging_mixin.py:112} INFO - [2021-01-13 09:35:47,847] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:35:47,885] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:35:48,575] {logging_mixin.py:112} INFO - [2021-01-13 09:35:48,574] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:35:48,629] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:35:47.887717+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:35:47.887717+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 35, 47, 887717, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:35:48,864] {scheduler_job.py:155} INFO - Started process (PID=28) to work on /opt/airflow/dags/example.py
[2021-01-13 09:35:48,872] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:35:48,875] {logging_mixin.py:112} INFO - [2021-01-13 09:35:48,874] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:35:48,914] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:35:49,508] {scheduler_job.py:423} INFO - Exiting gracefully upon receiving signal 15
[2021-01-13 09:38:06,349] {scheduler_job.py:155} INFO - Started process (PID=16) to work on /opt/airflow/dags/example.py
[2021-01-13 09:38:06,359] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:38:06,366] {logging_mixin.py:112} INFO - [2021-01-13 09:38:06,365] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:38:06,498] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:38:07,081] {logging_mixin.py:112} INFO - [2021-01-13 09:38:07,079] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:38:07,138] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:38:06.502556+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:38:06.502556+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 38, 6, 502556, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:38:07,384] {scheduler_job.py:155} INFO - Started process (PID=17) to work on /opt/airflow/dags/example.py
[2021-01-13 09:38:07,390] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:38:07,393] {logging_mixin.py:112} INFO - [2021-01-13 09:38:07,392] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:38:07,459] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:38:08,159] {logging_mixin.py:112} INFO - [2021-01-13 09:38:08,159] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:38:08,209] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:38:07.463443+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:38:07.463443+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 38, 7, 463443, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:38:08,396] {scheduler_job.py:155} INFO - Started process (PID=18) to work on /opt/airflow/dags/example.py
[2021-01-13 09:38:08,405] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:38:08,407] {logging_mixin.py:112} INFO - [2021-01-13 09:38:08,407] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:38:08,446] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:38:09,171] {logging_mixin.py:112} INFO - [2021-01-13 09:38:09,171] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:38:09,220] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:38:08.447751+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:38:08.447751+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 38, 8, 447751, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:38:09,463] {scheduler_job.py:155} INFO - Started process (PID=19) to work on /opt/airflow/dags/example.py
[2021-01-13 09:38:09,479] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:38:09,482] {logging_mixin.py:112} INFO - [2021-01-13 09:38:09,481] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:38:09,519] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:38:10,069] {logging_mixin.py:112} INFO - [2021-01-13 09:38:10,069] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:38:10,121] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:38:09.52119+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:38:09.52119+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 38, 9, 521190, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:38:10,448] {scheduler_job.py:155} INFO - Started process (PID=20) to work on /opt/airflow/dags/example.py
[2021-01-13 09:38:10,457] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:38:10,461] {logging_mixin.py:112} INFO - [2021-01-13 09:38:10,461] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:38:10,515] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:38:11,097] {logging_mixin.py:112} INFO - [2021-01-13 09:38:11,097] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:38:11,175] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:38:10.521266+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:38:10.521266+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 38, 10, 521266, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:38:11,499] {scheduler_job.py:155} INFO - Started process (PID=21) to work on /opt/airflow/dags/example.py
[2021-01-13 09:38:11,514] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:38:11,537] {logging_mixin.py:112} INFO - [2021-01-13 09:38:11,537] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:38:11,599] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:38:12,268] {logging_mixin.py:112} INFO - [2021-01-13 09:38:12,268] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:38:12,314] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:38:11.603808+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:38:11.603808+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 38, 11, 603808, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:38:12,494] {scheduler_job.py:155} INFO - Started process (PID=22) to work on /opt/airflow/dags/example.py
[2021-01-13 09:38:12,501] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:38:12,504] {logging_mixin.py:112} INFO - [2021-01-13 09:38:12,504] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:38:12,542] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:38:13,158] {logging_mixin.py:112} INFO - [2021-01-13 09:38:13,157] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:38:13,211] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:38:12.543815+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:38:12.543815+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 38, 12, 543815, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:38:13,507] {scheduler_job.py:155} INFO - Started process (PID=23) to work on /opt/airflow/dags/example.py
[2021-01-13 09:38:13,514] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:38:13,516] {logging_mixin.py:112} INFO - [2021-01-13 09:38:13,516] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:38:13,552] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:38:14,144] {logging_mixin.py:112} INFO - [2021-01-13 09:38:14,144] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:38:14,194] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:38:13.553882+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:38:13.553882+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 38, 13, 553882, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:38:14,537] {scheduler_job.py:155} INFO - Started process (PID=24) to work on /opt/airflow/dags/example.py
[2021-01-13 09:38:14,544] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:38:14,547] {logging_mixin.py:112} INFO - [2021-01-13 09:38:14,546] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:38:14,579] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:38:15,323] {logging_mixin.py:112} INFO - [2021-01-13 09:38:15,323] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:38:15,382] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:38:14.580873+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:38:14.580873+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 38, 14, 580873, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:38:15,550] {scheduler_job.py:155} INFO - Started process (PID=25) to work on /opt/airflow/dags/example.py
[2021-01-13 09:38:15,560] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:38:15,563] {logging_mixin.py:112} INFO - [2021-01-13 09:38:15,563] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:38:15,616] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:38:16,226] {logging_mixin.py:112} INFO - [2021-01-13 09:38:16,226] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:38:16,292] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:38:15.620085+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:38:15.620085+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 38, 15, 620085, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:38:16,689] {scheduler_job.py:155} INFO - Started process (PID=26) to work on /opt/airflow/dags/example.py
[2021-01-13 09:38:16,700] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:38:16,706] {logging_mixin.py:112} INFO - [2021-01-13 09:38:16,704] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:38:16,757] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:38:17,874] {logging_mixin.py:112} INFO - [2021-01-13 09:38:17,874] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:38:17,932] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:38:16.761531+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:38:16.761531+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 38, 16, 761531, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:38:18,722] {scheduler_job.py:155} INFO - Started process (PID=27) to work on /opt/airflow/dags/example.py
[2021-01-13 09:38:18,737] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:38:18,740] {logging_mixin.py:112} INFO - [2021-01-13 09:38:18,739] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:38:18,770] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:38:19,450] {logging_mixin.py:112} INFO - [2021-01-13 09:38:19,450] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:38:19,529] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:38:18.772263+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:38:18.772263+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 38, 18, 772263, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:38:19,744] {scheduler_job.py:155} INFO - Started process (PID=28) to work on /opt/airflow/dags/example.py
[2021-01-13 09:38:19,751] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:38:19,756] {logging_mixin.py:112} INFO - [2021-01-13 09:38:19,756] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:38:19,786] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:38:20,353] {logging_mixin.py:112} INFO - [2021-01-13 09:38:20,353] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:38:20,411] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:38:19.787418+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:38:19.787418+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 38, 19, 787418, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:38:20,773] {scheduler_job.py:155} INFO - Started process (PID=29) to work on /opt/airflow/dags/example.py
[2021-01-13 09:38:20,785] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:38:20,788] {logging_mixin.py:112} INFO - [2021-01-13 09:38:20,788] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:38:20,864] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:38:21,593] {logging_mixin.py:112} INFO - [2021-01-13 09:38:21,592] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:38:21,647] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:38:20.866963+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:38:20.866963+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 38, 20, 866963, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:38:21,773] {scheduler_job.py:155} INFO - Started process (PID=30) to work on /opt/airflow/dags/example.py
[2021-01-13 09:38:21,782] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:38:21,791] {logging_mixin.py:112} INFO - [2021-01-13 09:38:21,790] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:38:21,825] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:38:22,358] {logging_mixin.py:112} INFO - [2021-01-13 09:38:22,357] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:38:22,429] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:38:21.828358+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:38:21.828358+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 38, 21, 828358, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:38:22,800] {scheduler_job.py:155} INFO - Started process (PID=31) to work on /opt/airflow/dags/example.py
[2021-01-13 09:38:22,806] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:38:22,808] {logging_mixin.py:112} INFO - [2021-01-13 09:38:22,808] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:38:22,845] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:38:23,472] {logging_mixin.py:112} INFO - [2021-01-13 09:38:23,472] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:38:23,544] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:38:22.847592+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:38:22.847592+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 38, 22, 847592, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:38:23,829] {scheduler_job.py:155} INFO - Started process (PID=32) to work on /opt/airflow/dags/example.py
[2021-01-13 09:38:23,837] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:38:23,842] {logging_mixin.py:112} INFO - [2021-01-13 09:38:23,841] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:38:23,902] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:38:24,499] {logging_mixin.py:112} INFO - [2021-01-13 09:38:24,498] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:38:24,548] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:38:23.904438+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:38:23.904438+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 38, 23, 904438, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:38:24,843] {scheduler_job.py:155} INFO - Started process (PID=33) to work on /opt/airflow/dags/example.py
[2021-01-13 09:38:24,853] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:38:24,855] {logging_mixin.py:112} INFO - [2021-01-13 09:38:24,855] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:38:24,889] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:38:25,533] {logging_mixin.py:112} INFO - [2021-01-13 09:38:25,533] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:38:25,594] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:38:24.891111+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:38:24.891111+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 38, 24, 891111, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:38:25,863] {scheduler_job.py:155} INFO - Started process (PID=34) to work on /opt/airflow/dags/example.py
[2021-01-13 09:38:25,877] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:38:25,879] {logging_mixin.py:112} INFO - [2021-01-13 09:38:25,879] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:38:25,928] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:38:26,555] {logging_mixin.py:112} INFO - [2021-01-13 09:38:26,554] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:38:26,614] {scheduler_job.py:423} INFO - Exiting gracefully upon receiving signal 15
[2021-01-13 09:43:49,553] {scheduler_job.py:155} INFO - Started process (PID=15) to work on /opt/airflow/dags/example.py
[2021-01-13 09:43:49,561] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:43:49,564] {logging_mixin.py:112} INFO - [2021-01-13 09:43:49,563] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:43:49,628] {logging_mixin.py:112} INFO - [2021-01-13 09:43:49,621] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 18, in <module>
    bash_command = test
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['python_callable'] is required
[2021-01-13 09:43:49,637] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:43:50,435] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.882 seconds
[2021-01-13 09:43:50,575] {scheduler_job.py:155} INFO - Started process (PID=16) to work on /opt/airflow/dags/example.py
[2021-01-13 09:43:50,581] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:43:50,584] {logging_mixin.py:112} INFO - [2021-01-13 09:43:50,583] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:43:50,639] {logging_mixin.py:112} INFO - [2021-01-13 09:43:50,629] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 18, in <module>
    bash_command = test
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['python_callable'] is required
[2021-01-13 09:43:50,641] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:43:51,235] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.660 seconds
[2021-01-13 09:43:51,592] {scheduler_job.py:155} INFO - Started process (PID=17) to work on /opt/airflow/dags/example.py
[2021-01-13 09:43:51,609] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:43:51,612] {logging_mixin.py:112} INFO - [2021-01-13 09:43:51,611] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:43:51,659] {logging_mixin.py:112} INFO - [2021-01-13 09:43:51,656] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 18, in <module>
    bash_command = test
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['python_callable'] is required
[2021-01-13 09:43:51,661] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:43:52,259] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.668 seconds
[2021-01-13 09:43:52,640] {scheduler_job.py:155} INFO - Started process (PID=18) to work on /opt/airflow/dags/example.py
[2021-01-13 09:43:52,673] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:43:52,678] {logging_mixin.py:112} INFO - [2021-01-13 09:43:52,677] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:43:52,742] {logging_mixin.py:112} INFO - [2021-01-13 09:43:52,732] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 18, in <module>
    bash_command = test
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['python_callable'] is required
[2021-01-13 09:43:52,744] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:43:53,481] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.850 seconds
[2021-01-13 09:43:53,635] {scheduler_job.py:155} INFO - Started process (PID=19) to work on /opt/airflow/dags/example.py
[2021-01-13 09:43:53,645] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:43:53,652] {logging_mixin.py:112} INFO - [2021-01-13 09:43:53,651] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:43:53,720] {logging_mixin.py:112} INFO - [2021-01-13 09:43:53,713] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 18, in <module>
    bash_command = test
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['python_callable'] is required
[2021-01-13 09:43:53,725] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:43:54,395] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.760 seconds
[2021-01-13 09:43:54,639] {scheduler_job.py:155} INFO - Started process (PID=20) to work on /opt/airflow/dags/example.py
[2021-01-13 09:43:54,655] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:43:54,659] {logging_mixin.py:112} INFO - [2021-01-13 09:43:54,658] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:43:54,729] {logging_mixin.py:112} INFO - [2021-01-13 09:43:54,719] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 18, in <module>
    bash_command = test
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['python_callable'] is required
[2021-01-13 09:43:54,732] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:43:55,586] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.947 seconds
[2021-01-13 09:43:55,639] {scheduler_job.py:155} INFO - Started process (PID=21) to work on /opt/airflow/dags/example.py
[2021-01-13 09:43:55,645] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:43:55,647] {logging_mixin.py:112} INFO - [2021-01-13 09:43:55,647] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:43:55,675] {logging_mixin.py:112} INFO - [2021-01-13 09:43:55,672] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 18, in <module>
    bash_command = test
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['python_callable'] is required
[2021-01-13 09:43:55,676] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:43:56,331] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.692 seconds
[2021-01-13 09:43:56,651] {scheduler_job.py:155} INFO - Started process (PID=22) to work on /opt/airflow/dags/example.py
[2021-01-13 09:43:56,659] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:43:56,662] {logging_mixin.py:112} INFO - [2021-01-13 09:43:56,662] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:43:56,703] {logging_mixin.py:112} INFO - [2021-01-13 09:43:56,700] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 18, in <module>
    bash_command = test
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['python_callable'] is required
[2021-01-13 09:43:56,705] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:43:57,363] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.712 seconds
[2021-01-13 09:43:57,667] {scheduler_job.py:155} INFO - Started process (PID=23) to work on /opt/airflow/dags/example.py
[2021-01-13 09:43:57,672] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:43:57,674] {logging_mixin.py:112} INFO - [2021-01-13 09:43:57,674] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:43:57,706] {logging_mixin.py:112} INFO - [2021-01-13 09:43:57,701] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 18, in <module>
    bash_command = test
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['python_callable'] is required
[2021-01-13 09:43:57,708] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:43:58,470] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.803 seconds
[2021-01-13 09:43:58,672] {scheduler_job.py:155} INFO - Started process (PID=24) to work on /opt/airflow/dags/example.py
[2021-01-13 09:43:58,708] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:43:58,713] {logging_mixin.py:112} INFO - [2021-01-13 09:43:58,711] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:43:58,779] {logging_mixin.py:112} INFO - [2021-01-13 09:43:58,768] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 18, in <module>
    bash_command = test
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['python_callable'] is required
[2021-01-13 09:43:58,782] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:43:59,388] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.716 seconds
[2021-01-13 09:43:59,793] {scheduler_job.py:155} INFO - Started process (PID=25) to work on /opt/airflow/dags/example.py
[2021-01-13 09:43:59,799] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:43:59,801] {logging_mixin.py:112} INFO - [2021-01-13 09:43:59,800] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:43:59,831] {logging_mixin.py:112} INFO - [2021-01-13 09:43:59,827] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 18, in <module>
    bash_command = test
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['python_callable'] is required
[2021-01-13 09:43:59,833] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:44:00,535] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.742 seconds
[2021-01-13 09:44:00,815] {scheduler_job.py:155} INFO - Started process (PID=26) to work on /opt/airflow/dags/example.py
[2021-01-13 09:44:00,822] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:44:00,827] {logging_mixin.py:112} INFO - [2021-01-13 09:44:00,826] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:44:00,896] {logging_mixin.py:112} INFO - [2021-01-13 09:44:00,885] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 18, in <module>
    bash_command = test
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['python_callable'] is required
[2021-01-13 09:44:00,898] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:44:01,657] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.842 seconds
[2021-01-13 09:44:01,822] {scheduler_job.py:155} INFO - Started process (PID=27) to work on /opt/airflow/dags/example.py
[2021-01-13 09:44:01,828] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:44:01,831] {logging_mixin.py:112} INFO - [2021-01-13 09:44:01,830] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:44:01,852] {scheduler_job.py:423} INFO - Exiting gracefully upon receiving signal 15
[2021-01-13 09:44:01,883] {logging_mixin.py:112} WARNING - --- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
--- Logging error ---
[2021-01-13 09:44:01,906] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:01,908] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:01,909] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:01,912] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:01,916] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:01,917] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:01,918] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:01,920] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:01,921] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:01,923] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:01,925] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:01,926] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:01,928] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:01,930] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:01,935] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:01,936] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:01,938] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:01,939] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:01,940] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:01,941] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:01,943] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:01,944] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:01,945] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:01,947] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:01,949] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:01,951] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:01,952] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:01,954] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:01,956] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:01,957] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:01,959] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:01,960] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:01,962] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:01,963] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:01,964] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:01,966] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:01,968] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:01,970] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:01,971] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:01,972] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:01,974] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:01,976] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:01,977] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:01,979] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:01,980] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:01,982] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:01,984] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:01,985] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:01,986] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:01,987] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:01,988] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:01,990] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:01,992] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:01,993] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:01,994] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:01,996] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:01,998] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:01,999] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,000] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,002] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,004] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,005] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,006] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,007] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,008] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,009] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,011] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,012] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,014] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,016] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,017] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,018] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,020] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,021] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,022] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,024] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,025] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,027] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,028] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,030] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,031] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,032] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,034] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,035] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,036] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,038] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,039] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,041] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,042] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,044] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,046] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,047] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,049] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,052] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,053] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,054] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,056] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,060] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,062] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,063] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,065] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,067] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,068] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,071] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,073] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,075] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,077] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,080] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,081] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,083] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,084] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,086] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,087] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,089] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,090] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,091] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,093] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,094] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,095] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,097] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,098] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,100] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,101] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,103] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,105] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,107] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,108] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,113] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,114] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,116] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,117] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,119] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,120] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,122] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,125] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,126] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,128] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,129] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,131] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,132] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,133] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,135] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,137] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,138] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,140] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,141] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,142] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,143] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,144] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,146] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,147] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,149] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,150] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,151] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,153] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,154] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,156] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,157] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,159] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,160] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,161] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,162] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,163] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,164] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,166] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,167] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,168] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,170] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,174] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,176] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,177] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,178] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,179] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,181] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,182] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,184] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,185] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,201] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,202] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,203] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,205] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,206] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,207] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,208] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,209] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,211] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,212] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,213] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,215] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,217] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,218] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,221] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,223] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,227] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,228] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,230] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,233] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,251] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,253] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,255] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,258] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,261] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,271] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,279] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,281] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,283] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,285] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,286] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,288] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,289] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,291] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,293] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,294] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,296] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,297] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,298] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,300] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,301] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,305] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,306] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,308] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,310] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,311] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,313] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,314] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,316] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,317] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,318] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,319] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,320] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,322] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,323] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,324] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,325] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,326] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,327] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,328] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,329] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,330] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,331] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,333] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,335] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,336] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,337] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,340] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,342] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,343] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,344] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,346] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,347] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,348] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,350] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,351] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,352] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,353] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,354] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,356] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,357] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,359] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,364] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,367] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,370] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,371] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,373] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,374] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,375] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,377] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,380] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,382] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,383] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,384] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,385] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,387] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,388] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,390] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,391] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,392] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,394] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,395] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,396] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,398] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,399] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,400] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,401] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,403] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,404] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,405] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,406] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,408] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,409] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,410] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,411] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,412] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,413] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,414] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,415] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,417] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,418] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,419] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,420] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,421] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,424] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,426] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,427] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,429] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,430] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,431] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,433] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,434] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,438] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,439] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,440] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,442] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,444] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,445] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,447] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,448] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,449] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,451] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,453] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,455] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,456] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,457] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,458] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,461] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,463] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,464] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,466] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,468] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,469] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,470] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,471] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,473] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,474] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,476] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,477] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,481] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,482] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,484] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,486] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,487] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,489] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,490] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,491] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,493] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,495] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,497] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,498] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,500] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,501] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,503] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,504] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,505] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,508] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,509] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,512] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,514] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,516] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,517] {logging_mixin.py:112} WARNING - RuntimeError: reentrant call inside <_io.BufferedWriter name='/opt/airflow/logs/scheduler/2021-01-13/example.py.log'>
[2021-01-13 09:44:02,519] {logging_mixin.py:112} WARNING - 
During handling of the above exception, another exception occurred:
[2021-01-13 09:44:02,521] {logging_mixin.py:112} WARNING - Traceback (most recent call last):
[2021-01-13 09:44:02,525] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
[2021-01-13 09:44:02,530] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
[2021-01-13 09:44:02,533] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 423, in _exit_gracefully
    self.log.info("Exiting gracefully upon receiving signal %s", signum)
[2021-01-13 09:44:02,535] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1308, in info
    self._log(INFO, msg, args, **kwargs)
[2021-01-13 09:44:02,537] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:02,538] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:02,540] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:02,541] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:02,543] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:02,545] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:02,548] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:02,550] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:02,551] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:02,553] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:02,554] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:02,556] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:02,557] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:02,558] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:02,559] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:02,561] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:02,563] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:02,565] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:02,566] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:02,567] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:02,569] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:02,572] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:02,574] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:02,575] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:02,578] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:02,581] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:02,583] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:02,584] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:02,585] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:02,587] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:02,589] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:02,590] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:02,592] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:02,593] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:02,596] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:02,597] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:02,599] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:02,600] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:02,602] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:02,604] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:02,605] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:02,606] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:02,608] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:02,612] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:02,614] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:02,615] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:02,616] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:02,617] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:02,619] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:02,621] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:02,622] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:02,623] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:02,625] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:02,628] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:02,631] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:02,633] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:02,635] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:02,637] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:02,638] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:02,639] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:02,641] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:02,642] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:02,644] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:02,647] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:02,648] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:02,653] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:02,655] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:02,657] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:02,659] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:02,664] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:02,665] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:02,666] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:02,668] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:02,670] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:02,671] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:02,673] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:02,675] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:02,677] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:02,680] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:02,682] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:02,684] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:02,685] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:02,686] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:02,688] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:02,689] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:02,691] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:02,695] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:02,697] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:02,698] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:02,700] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:02,701] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:02,703] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:02,704] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:02,706] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:02,709] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:02,711] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:02,713] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:02,715] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:02,717] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:02,719] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:02,720] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:02,721] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:02,723] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:02,724] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:02,726] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:02,729] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:02,733] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:02,735] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:02,736] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:02,738] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:02,740] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:02,742] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:02,743] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:02,746] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:02,748] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:02,751] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:02,753] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:02,756] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:02,757] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:02,758] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:02,760] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:02,761] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:02,763] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:02,765] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:02,766] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:02,768] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:02,770] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:02,771] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:02,773] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:02,777] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:02,779] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:02,782] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:02,783] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:02,784] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:02,786] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:02,787] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:02,788] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:02,790] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:02,791] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:02,793] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:02,795] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:02,797] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:02,799] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:02,800] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:02,801] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:02,802] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:02,804] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:02,806] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:02,806] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:02,808] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:02,809] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:02,812] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:02,814] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:02,815] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:02,816] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:02,817] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:02,818] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:02,820] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:02,822] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:02,823] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:02,824] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:02,825] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:02,827] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:02,830] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:02,831] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:02,833] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:02,834] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:02,835] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:02,837] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:02,838] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:02,839] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:02,840] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:02,841] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:02,842] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:02,846] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:02,847] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:02,848] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:02,849] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:02,853] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:02,855] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:02,856] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:02,857] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:02,858] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:02,859] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:02,863] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:02,864] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:02,865] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:02,867] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:02,869] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:02,870] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:02,871] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:02,872] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:02,873] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:02,875] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:02,878] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:02,882] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:02,884] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:02,887] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:02,888] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:02,890] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:02,892] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:02,893] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:02,896] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:02,900] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:02,902] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:02,903] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:02,904] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:02,908] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:02,912] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:02,914] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:02,915] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:02,917] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:02,918] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:02,919] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:02,922] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:02,924] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:02,925] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:02,927] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:02,929] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:02,932] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:02,933] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:02,935] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:02,936] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:02,938] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:02,941] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:02,943] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:02,946] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:02,948] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:02,950] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:02,951] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:02,952] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:02,954] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:02,956] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:02,958] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:02,960] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:02,961] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:02,963] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:02,965] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:02,967] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:02,968] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:02,969] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:02,972] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:02,974] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:02,976] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:02,978] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:02,979] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:02,981] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:02,983] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:02,985] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:02,986] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:02,988] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:02,989] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:02,991] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:02,992] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:02,994] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:02,997] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:02,999] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:03,001] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:03,002] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:03,004] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:03,005] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:03,009] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:03,010] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:03,014] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:03,016] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:03,017] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:03,019] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:03,020] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:03,022] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:03,024] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:03,026] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:03,027] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:03,029] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:03,031] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:03,033] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:03,034] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:03,036] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:03,037] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:03,039] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:03,040] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:03,042] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:03,044] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:03,045] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:03,047] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:03,048] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:03,050] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:03,052] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:03,053] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:03,056] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:03,058] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:03,060] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:03,061] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:03,062] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:03,064] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:03,066] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:03,067] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:03,069] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:03,070] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:03,072] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:03,073] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:03,075] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:03,078] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:03,079] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:03,080] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:03,083] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:03,087] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:03,089] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:03,095] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:03,097] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:03,098] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:03,100] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:03,101] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:03,103] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:03,105] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:03,107] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:03,108] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:03,110] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:03,113] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:03,114] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:03,117] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:03,119] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:03,120] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:03,122] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:03,124] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:03,126] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:03,128] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:03,130] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:03,133] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:03,138] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:03,141] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:03,142] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:03,143] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:03,144] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:03,146] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:03,149] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:03,151] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:03,152] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:03,154] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:03,156] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:03,160] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:03,161] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:03,164] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:03,166] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:03,167] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:03,169] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:03,172] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:03,174] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:03,176] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:03,177] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:03,180] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:03,182] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:03,183] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:03,185] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:03,189] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:03,192] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:03,194] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:03,197] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:03,199] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:03,200] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:03,204] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:03,206] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:03,207] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:03,210] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:03,214] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:03,215] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:03,217] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:03,218] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:03,220] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:03,222] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:03,224] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:03,225] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:03,227] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:03,231] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:03,233] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:03,235] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:03,237] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:03,239] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:03,240] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:03,242] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:03,246] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:03,248] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:03,250] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:03,251] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:03,253] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:03,255] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:03,256] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:03,258] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:03,259] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:03,262] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:03,263] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:03,268] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:03,269] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:03,271] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:03,274] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:03,276] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:03,277] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:03,280] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:03,289] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:03,292] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:03,302] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:03,303] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:03,306] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:03,308] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:03,310] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:03,311] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:03,317] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:03,320] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:03,322] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:03,324] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:03,325] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:03,327] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:03,329] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:03,334] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:03,337] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:03,338] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:03,340] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:03,342] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:03,344] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:03,349] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:03,352] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:03,354] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:03,357] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:03,358] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:03,360] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:03,362] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:03,367] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:03,369] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:03,370] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:03,372] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:03,374] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:03,376] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:03,378] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:03,384] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:03,386] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:03,388] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:03,390] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:03,391] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:03,393] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:03,394] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:03,399] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:03,400] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:03,402] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:03,403] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:03,405] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:03,407] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:03,409] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:03,410] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:03,413] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:03,415] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:03,417] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:03,418] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:03,420] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:03,421] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:03,423] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:03,425] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:03,427] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:03,431] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:03,433] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:03,434] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:03,436] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:03,438] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:03,440] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:03,441] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:03,442] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:03,444] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:03,448] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:03,450] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:03,452] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:03,455] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:03,456] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:03,457] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:03,464] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:03,465] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:03,467] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:03,468] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:03,469] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:03,471] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:03,473] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:03,475] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:03,477] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:03,480] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:03,482] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:03,483] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:03,485] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:03,487] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:03,488] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:03,490] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:03,493] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:03,495] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:03,498] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:03,499] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:03,501] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:03,503] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:03,510] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:03,513] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:03,515] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:03,517] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:03,519] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:03,520] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:03,521] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:03,522] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:03,524] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:03,526] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:03,527] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:03,528] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:03,532] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:03,534] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:03,536] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:03,537] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:03,539] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:03,540] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:03,542] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:03,543] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:03,544] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:03,548] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:03,550] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:03,551] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:03,552] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:03,554] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:03,560] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:03,566] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:03,567] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:03,570] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:03,573] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:03,575] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:03,577] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:03,578] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:03,581] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:03,584] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:03,585] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:03,586] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:03,587] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:03,589] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:03,590] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:03,591] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:03,593] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:03,598] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:03,599] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:03,600] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:03,604] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:03,605] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:03,607] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:03,615] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:03,616] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:03,617] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:03,619] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:03,621] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:03,623] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:03,624] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:03,626] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:03,627] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:03,631] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:03,641] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:03,643] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:03,647] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:03,649] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:03,654] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:03,655] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:03,666] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:03,668] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:03,671] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:03,673] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:03,675] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:03,678] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:03,682] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:03,684] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:03,686] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:03,687] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:03,690] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:03,692] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:03,694] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:03,697] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:03,699] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:03,702] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:03,706] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:03,707] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:03,710] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:03,711] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:03,715] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:03,717] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:03,719] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:03,723] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:03,726] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:03,734] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:03,738] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:03,740] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:03,742] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:03,744] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:03,745] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:03,749] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:03,751] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:03,753] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:03,754] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:03,755] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:03,758] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:03,759] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:03,761] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:03,762] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:03,767] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:03,768] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:03,770] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:03,775] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:03,776] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:03,777] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:03,782] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:03,783] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:03,788] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:03,790] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:03,792] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:03,794] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:03,800] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:03,802] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:03,808] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:03,810] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:03,811] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:03,814] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:03,820] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:03,823] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:03,827] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:03,829] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:03,832] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:03,834] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:03,836] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:03,838] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:03,844] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:03,847] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:03,852] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:03,857] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:03,860] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:03,865] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:03,870] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:03,872] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:03,875] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:03,877] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:03,881] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:03,918] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:03,922] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:03,925] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:03,927] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:03,934] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:03,935] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:03,937] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:03,938] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:03,942] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:03,944] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:03,958] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:03,959] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:03,961] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:03,968] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:03,970] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:03,974] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:03,976] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:03,977] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:03,979] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:03,990] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:03,998] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:04,002] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:04,004] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:04,012] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:04,016] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:04,018] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:04,020] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:04,025] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:04,026] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:04,029] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:04,032] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:04,036] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:04,043] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:04,047] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:04,049] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:04,051] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:04,055] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:04,058] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:04,066] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:04,070] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:04,096] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:04,161] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:04,169] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:04,184] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:04,198] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:04,201] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:04,213] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:04,227] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:04,233] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:04,237] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:04,242] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:04,249] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:04,259] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:04,260] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:04,270] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:04,275] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:04,279] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:04,288] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:04,308] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:04,310] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:04,312] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:04,317] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:04,319] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:04,322] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:04,324] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:04,328] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:04,333] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:04,338] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:04,340] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:04,342] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:04,345] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:04,347] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:04,355] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:04,358] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:04,359] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:04,362] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:04,371] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:04,376] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:04,378] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:04,383] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:04,386] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:04,388] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:04,391] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:04,395] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:04,401] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:04,403] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:04,405] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:04,411] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:04,413] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:04,421] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:04,423] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:04,425] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:04,427] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:04,428] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:04,430] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:04,435] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:04,441] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:04,443] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:04,444] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:04,446] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:04,451] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:04,455] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:04,462] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:04,466] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:04,472] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:04,476] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:04,478] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:04,480] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:04,487] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:04,490] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:04,492] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:04,494] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:04,495] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:04,504] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:04,511] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:04,522] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:04,529] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:04,538] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:04,539] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:04,546] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:04,555] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:04,558] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:04,560] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:04,561] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:04,572] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:04,576] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:04,578] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:04,579] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:04,588] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:04,590] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:04,594] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:04,596] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:04,602] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:04,608] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:04,609] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:04,610] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:04,614] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:04,620] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:04,625] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:04,626] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:04,627] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:04,628] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:04,634] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:04,641] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:04,647] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:04,656] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:04,659] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:04,662] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:04,668] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:04,670] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:04,672] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:04,673] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1072, in emit
    StreamHandler.emit(self, record)
[2021-01-13 09:44:04,675] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1000, in emit
    self.handleError(record)
[2021-01-13 09:44:04,676] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 917, in handleError
    sys.stderr.write('--- Logging error ---\n')
[2021-01-13 09:44:04,678] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 123, in write
    self._propagate_log(self._buffer.rstrip())
[2021-01-13 09:44:04,679] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/logging_mixin.py", line 112, in _propagate_log
    self.logger.log(self.level, remove_escape_codes(message))
[2021-01-13 09:44:04,687] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1374, in log
    self._log(level, msg, args, **kwargs)
[2021-01-13 09:44:04,688] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1432, in _log
    fn, lno, func, sinfo = self.findCaller(stack_info)
[2021-01-13 09:44:04,693] {logging_mixin.py:112} WARNING - RecursionError: maximum recursion depth exceeded
[2021-01-13 09:44:04,695] {logging_mixin.py:112} WARNING - Call stack:
[2021-01-13 09:44:04,709] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/bin/airflow", line 37, in <module>
    args.func(args)
[2021-01-13 09:44:04,712] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/cli.py", line 81, in wrapper
    return f(*args, **kwargs)
[2021-01-13 09:44:04,713] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/bin/cli.py", line 1324, in scheduler
    job.run()
[2021-01-13 09:44:04,717] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/base_job.py", line 218, in run
    self._execute()
[2021-01-13 09:44:04,719] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1382, in _execute
    self._execute_helper()
[2021-01-13 09:44:04,722] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1425, in _execute_helper
    self.processor_agent.start()
[2021-01-13 09:44:04,724] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/dag_processing.py", line 560, in start
    self._process.start()
[2021-01-13 09:44:04,726] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
[2021-01-13 09:44:04,728] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
[2021-01-13 09:44:04,729] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
[2021-01-13 09:44:04,751] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/multiprocessing/popen_fork.py", line 73, in _launch
    code = process_obj._bootstrap()
[2021-01-13 09:44:04,763] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
[2021-01-13 09:44:04,779] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
[2021-01-13 09:44:04,780] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/dag_processing.py", line 634, in _run_processor_manager
    processor_manager.start()
[2021-01-13 09:44:04,786] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/dag_processing.py", line 886, in start
    self.start_new_processes()
[2021-01-13 09:44:04,788] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/dag_processing.py", line 1250, in start_new_processes
    processor.start()
[2021-01-13 09:44:04,793] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 201, in start
    self._process.start()
[2021-01-13 09:44:04,802] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
[2021-01-13 09:44:04,807] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
[2021-01-13 09:44:04,810] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
[2021-01-13 09:44:04,811] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/multiprocessing/popen_fork.py", line 73, in _launch
    code = process_obj._bootstrap()
[2021-01-13 09:44:04,813] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
[2021-01-13 09:44:04,818] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
[2021-01-13 09:44:04,820] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
[2021-01-13 09:44:04,821] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
[2021-01-13 09:44:04,823] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1577, in process_file
    dagbag = models.DagBag(file_path, include_examples=False)
[2021-01-13 09:44:04,825] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 110, in __init__
    safe_mode=safe_mode)
[2021-01-13 09:44:04,826] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 432, in collect_dags
    safe_mode=safe_mode)
[2021-01-13 09:44:04,828] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 233, in process_file
    with open(filepath, 'rb') as f:
[2021-01-13 09:44:04,830] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 423, in _exit_gracefully
    self.log.info("Exiting gracefully upon receiving signal %s", signum)
[2021-01-13 09:44:04,835] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1308, in info
    self._log(INFO, msg, args, **kwargs)
[2021-01-13 09:44:04,837] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1444, in _log
    self.handle(record)
[2021-01-13 09:44:04,839] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1454, in handle
    self.callHandlers(record)
[2021-01-13 09:44:04,840] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 1516, in callHandlers
    hdlr.handle(record)
[2021-01-13 09:44:04,842] {logging_mixin.py:112} WARNING -   File "/usr/local/lib/python3.6/logging/__init__.py", line 865, in handle
    self.emit(record)
[2021-01-13 09:44:04,844] {logging_mixin.py:112} WARNING -   File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/log/file_processor_handler.py", line 76, in emit
    self.handler.emit(record)
[2021-01-13 09:44:04,845] {logging_mixin.py:112} WARNING - Message: 'Exiting gracefully upon receiving signal %s'
Arguments: (15,)
[2021-01-13 09:44:28,696] {scheduler_job.py:155} INFO - Started process (PID=17) to work on /opt/airflow/dags/example.py
[2021-01-13 09:44:28,704] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:44:28,709] {logging_mixin.py:112} INFO - [2021-01-13 09:44:28,709] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:44:28,761] {logging_mixin.py:112} INFO - [2021-01-13 09:44:28,754] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 18, in <module>
    bash_command = test
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['python_callable'] is required
[2021-01-13 09:44:28,763] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:44:29,334] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.639 seconds
[2021-01-13 09:44:29,747] {scheduler_job.py:155} INFO - Started process (PID=18) to work on /opt/airflow/dags/example.py
[2021-01-13 09:44:29,756] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:44:29,760] {logging_mixin.py:112} INFO - [2021-01-13 09:44:29,760] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:44:29,806] {logging_mixin.py:112} INFO - [2021-01-13 09:44:29,800] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 18, in <module>
    bash_command = test
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['python_callable'] is required
[2021-01-13 09:44:29,809] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:44:30,494] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.747 seconds
[2021-01-13 09:44:30,759] {scheduler_job.py:155} INFO - Started process (PID=19) to work on /opt/airflow/dags/example.py
[2021-01-13 09:44:30,765] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:44:30,768] {logging_mixin.py:112} INFO - [2021-01-13 09:44:30,767] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:44:30,804] {logging_mixin.py:112} INFO - [2021-01-13 09:44:30,799] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 18, in <module>
    bash_command = test
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['python_callable'] is required
[2021-01-13 09:44:30,806] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:44:31,359] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.600 seconds
[2021-01-13 09:44:31,775] {scheduler_job.py:155} INFO - Started process (PID=20) to work on /opt/airflow/dags/example.py
[2021-01-13 09:44:31,792] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:44:31,796] {logging_mixin.py:112} INFO - [2021-01-13 09:44:31,795] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:44:31,858] {logging_mixin.py:112} INFO - [2021-01-13 09:44:31,847] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 18, in <module>
    bash_command = test
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['python_callable'] is required
[2021-01-13 09:44:31,861] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:44:32,618] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.843 seconds
[2021-01-13 09:44:32,807] {scheduler_job.py:155} INFO - Started process (PID=21) to work on /opt/airflow/dags/example.py
[2021-01-13 09:44:32,816] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:44:32,818] {logging_mixin.py:112} INFO - [2021-01-13 09:44:32,818] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:44:32,875] {logging_mixin.py:112} INFO - [2021-01-13 09:44:32,860] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 18, in <module>
    bash_command = test
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['python_callable'] is required
[2021-01-13 09:44:32,878] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:44:33,614] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.807 seconds
[2021-01-13 09:44:33,786] {scheduler_job.py:155} INFO - Started process (PID=22) to work on /opt/airflow/dags/example.py
[2021-01-13 09:44:33,803] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:44:33,814] {logging_mixin.py:112} INFO - [2021-01-13 09:44:33,811] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:44:33,893] {logging_mixin.py:112} INFO - [2021-01-13 09:44:33,878] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 18, in <module>
    bash_command = test
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['python_callable'] is required
[2021-01-13 09:44:33,896] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:44:34,481] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.695 seconds
[2021-01-13 09:44:34,800] {scheduler_job.py:155} INFO - Started process (PID=23) to work on /opt/airflow/dags/example.py
[2021-01-13 09:44:34,806] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:44:34,809] {logging_mixin.py:112} INFO - [2021-01-13 09:44:34,809] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:44:34,842] {logging_mixin.py:112} INFO - [2021-01-13 09:44:34,838] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 18, in <module>
    bash_command = test
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['python_callable'] is required
[2021-01-13 09:44:34,844] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:44:35,539] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.739 seconds
[2021-01-13 09:44:35,810] {scheduler_job.py:155} INFO - Started process (PID=24) to work on /opt/airflow/dags/example.py
[2021-01-13 09:44:35,817] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:44:35,820] {logging_mixin.py:112} INFO - [2021-01-13 09:44:35,819] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:44:35,859] {logging_mixin.py:112} INFO - [2021-01-13 09:44:35,856] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 18, in <module>
    bash_command = test
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['python_callable'] is required
[2021-01-13 09:44:35,861] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:44:36,670] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.860 seconds
[2021-01-13 09:44:36,823] {scheduler_job.py:155} INFO - Started process (PID=25) to work on /opt/airflow/dags/example.py
[2021-01-13 09:44:36,829] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:44:36,832] {logging_mixin.py:112} INFO - [2021-01-13 09:44:36,832] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:44:36,888] {logging_mixin.py:112} INFO - [2021-01-13 09:44:36,879] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 18, in <module>
    bash_command = test
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['python_callable'] is required
[2021-01-13 09:44:36,891] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:44:37,499] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.677 seconds
[2021-01-13 09:44:37,831] {scheduler_job.py:155} INFO - Started process (PID=26) to work on /opt/airflow/dags/example.py
[2021-01-13 09:44:37,846] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:44:37,850] {logging_mixin.py:112} INFO - [2021-01-13 09:44:37,849] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:44:37,918] {logging_mixin.py:112} INFO - [2021-01-13 09:44:37,910] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 18, in <module>
    bash_command = test
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['python_callable'] is required
[2021-01-13 09:44:37,928] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:44:38,670] {scheduler_job.py:163} INFO - Processing /opt/airflow/dags/example.py took 0.839 seconds
[2021-01-13 09:44:38,941] {scheduler_job.py:155} INFO - Started process (PID=27) to work on /opt/airflow/dags/example.py
[2021-01-13 09:44:38,948] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:44:38,950] {logging_mixin.py:112} INFO - [2021-01-13 09:44:38,950] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:44:38,979] {logging_mixin.py:112} INFO - [2021-01-13 09:44:38,974] {dagbag.py:259} ERROR - Failed to import: /opt/airflow/dags/example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 256, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/local/lib/python3.6/imp.py", line 172, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 684, in _load
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/example.py", line 18, in <module>
    bash_command = test
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/decorators.py", line 94, in wrapper
    raise AirflowException(msg)
airflow.exceptions.AirflowException: Argument ['python_callable'] is required
[2021-01-13 09:44:38,981] {scheduler_job.py:1586} WARNING - No viable dags retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:44:39,429] {scheduler_job.py:423} INFO - Exiting gracefully upon receiving signal 15
[2021-01-13 09:45:03,710] {scheduler_job.py:155} INFO - Started process (PID=15) to work on /opt/airflow/dags/example.py
[2021-01-13 09:45:03,730] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:45:03,736] {logging_mixin.py:112} INFO - [2021-01-13 09:45:03,735] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:45:03,817] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:45:04,395] {logging_mixin.py:112} INFO - [2021-01-13 09:45:04,395] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:45:04,472] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:03.827817+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:03.827817+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 45, 3, 827817, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:45:04,808] {scheduler_job.py:155} INFO - Started process (PID=16) to work on /opt/airflow/dags/example.py
[2021-01-13 09:45:04,867] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:45:04,875] {logging_mixin.py:112} INFO - [2021-01-13 09:45:04,874] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:45:04,953] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:45:05,756] {logging_mixin.py:112} INFO - [2021-01-13 09:45:05,756] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:45:05,842] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:04.955622+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:04.955622+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 45, 4, 955622, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:45:06,927] {scheduler_job.py:155} INFO - Started process (PID=17) to work on /opt/airflow/dags/example.py
[2021-01-13 09:45:06,967] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:45:06,973] {logging_mixin.py:112} INFO - [2021-01-13 09:45:06,973] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:45:07,098] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:45:07,837] {logging_mixin.py:112} INFO - [2021-01-13 09:45:07,830] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:45:07,946] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:07.101697+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:07.101697+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 45, 7, 101697, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:45:09,039] {scheduler_job.py:155} INFO - Started process (PID=18) to work on /opt/airflow/dags/example.py
[2021-01-13 09:45:09,073] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:45:09,075] {logging_mixin.py:112} INFO - [2021-01-13 09:45:09,074] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:45:09,467] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:45:10,274] {logging_mixin.py:112} INFO - [2021-01-13 09:45:10,274] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:45:10,338] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:09.470494+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:09.470494+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 45, 9, 470494, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:45:11,036] {scheduler_job.py:155} INFO - Started process (PID=19) to work on /opt/airflow/dags/example.py
[2021-01-13 09:45:11,057] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:45:11,070] {logging_mixin.py:112} INFO - [2021-01-13 09:45:11,068] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:45:11,147] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:45:11,833] {logging_mixin.py:112} INFO - [2021-01-13 09:45:11,830] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:45:11,900] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:11.149674+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:11.149674+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 45, 11, 149674, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:45:12,035] {scheduler_job.py:155} INFO - Started process (PID=20) to work on /opt/airflow/dags/example.py
[2021-01-13 09:45:12,059] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:45:12,067] {logging_mixin.py:112} INFO - [2021-01-13 09:45:12,067] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:45:12,115] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:45:12,690] {logging_mixin.py:112} INFO - [2021-01-13 09:45:12,689] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:45:12,767] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:12.117353+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:12.117353+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 45, 12, 117353, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:45:13,038] {scheduler_job.py:155} INFO - Started process (PID=21) to work on /opt/airflow/dags/example.py
[2021-01-13 09:45:13,045] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:45:13,049] {logging_mixin.py:112} INFO - [2021-01-13 09:45:13,048] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:45:13,086] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:45:13,638] {logging_mixin.py:112} INFO - [2021-01-13 09:45:13,638] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:45:13,699] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:13.087994+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:13.087994+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 45, 13, 87994, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:45:14,214] {scheduler_job.py:155} INFO - Started process (PID=22) to work on /opt/airflow/dags/example.py
[2021-01-13 09:45:14,230] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:45:14,236] {logging_mixin.py:112} INFO - [2021-01-13 09:45:14,235] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:45:14,298] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:45:14,879] {logging_mixin.py:112} INFO - [2021-01-13 09:45:14,879] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:45:14,974] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:14.301593+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:14.301593+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 45, 14, 301593, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:45:15,230] {scheduler_job.py:155} INFO - Started process (PID=23) to work on /opt/airflow/dags/example.py
[2021-01-13 09:45:15,237] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:45:15,239] {logging_mixin.py:112} INFO - [2021-01-13 09:45:15,239] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:45:15,277] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:45:15,832] {logging_mixin.py:112} INFO - [2021-01-13 09:45:15,831] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:45:15,896] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:15.278686+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:15.278686+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 45, 15, 278686, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:45:16,256] {scheduler_job.py:155} INFO - Started process (PID=24) to work on /opt/airflow/dags/example.py
[2021-01-13 09:45:16,263] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:45:16,265] {logging_mixin.py:112} INFO - [2021-01-13 09:45:16,264] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:45:16,304] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:45:16,931] {logging_mixin.py:112} INFO - [2021-01-13 09:45:16,931] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:45:16,996] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:16.306796+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:16.306796+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 45, 16, 306796, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:45:17,267] {scheduler_job.py:155} INFO - Started process (PID=25) to work on /opt/airflow/dags/example.py
[2021-01-13 09:45:17,274] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:45:17,276] {logging_mixin.py:112} INFO - [2021-01-13 09:45:17,276] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:45:17,310] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:45:17,833] {logging_mixin.py:112} INFO - [2021-01-13 09:45:17,833] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:45:17,889] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:17.312308+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:17.312308+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 45, 17, 312308, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:45:18,305] {scheduler_job.py:155} INFO - Started process (PID=26) to work on /opt/airflow/dags/example.py
[2021-01-13 09:45:18,321] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:45:18,328] {logging_mixin.py:112} INFO - [2021-01-13 09:45:18,327] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:45:18,385] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:45:19,044] {logging_mixin.py:112} INFO - [2021-01-13 09:45:19,044] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:45:19,111] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:18.387305+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:18.387305+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 45, 18, 387305, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:45:19,312] {scheduler_job.py:155} INFO - Started process (PID=27) to work on /opt/airflow/dags/example.py
[2021-01-13 09:45:19,317] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:45:19,319] {logging_mixin.py:112} INFO - [2021-01-13 09:45:19,318] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:45:19,360] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:45:19,917] {logging_mixin.py:112} INFO - [2021-01-13 09:45:19,917] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:45:19,966] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:19.363229+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:19.363229+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 45, 19, 363229, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:45:20,333] {scheduler_job.py:155} INFO - Started process (PID=28) to work on /opt/airflow/dags/example.py
[2021-01-13 09:45:20,339] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:45:20,341] {logging_mixin.py:112} INFO - [2021-01-13 09:45:20,340] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:45:20,369] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:45:21,019] {logging_mixin.py:112} INFO - [2021-01-13 09:45:21,018] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:45:21,106] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:20.371236+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:20.371236+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 45, 20, 371236, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:45:21,355] {scheduler_job.py:155} INFO - Started process (PID=29) to work on /opt/airflow/dags/example.py
[2021-01-13 09:45:21,363] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:45:21,365] {logging_mixin.py:112} INFO - [2021-01-13 09:45:21,365] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:45:21,400] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:45:22,106] {logging_mixin.py:112} INFO - [2021-01-13 09:45:22,106] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:45:22,167] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:21.40283+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:21.40283+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 45, 21, 402830, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:45:22,382] {scheduler_job.py:155} INFO - Started process (PID=30) to work on /opt/airflow/dags/example.py
[2021-01-13 09:45:22,388] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:45:22,392] {logging_mixin.py:112} INFO - [2021-01-13 09:45:22,391] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:45:22,439] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:45:23,521] {logging_mixin.py:112} INFO - [2021-01-13 09:45:23,520] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:45:23,605] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:22.862329+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:22.862329+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 45, 22, 862329, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:45:24,531] {scheduler_job.py:155} INFO - Started process (PID=31) to work on /opt/airflow/dags/example.py
[2021-01-13 09:45:24,537] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:45:24,542] {logging_mixin.py:112} INFO - [2021-01-13 09:45:24,540] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:45:24,581] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:45:25,171] {logging_mixin.py:112} INFO - [2021-01-13 09:45:25,171] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:45:25,385] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:24.583411+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:24.583411+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 45, 24, 583411, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:45:25,555] {scheduler_job.py:155} INFO - Started process (PID=32) to work on /opt/airflow/dags/example.py
[2021-01-13 09:45:25,570] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:45:25,573] {logging_mixin.py:112} INFO - [2021-01-13 09:45:25,573] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:45:25,635] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:45:26,228] {logging_mixin.py:112} INFO - [2021-01-13 09:45:26,228] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:45:26,298] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:25.642221+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:25.642221+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 45, 25, 642221, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:45:26,563] {scheduler_job.py:155} INFO - Started process (PID=33) to work on /opt/airflow/dags/example.py
[2021-01-13 09:45:26,570] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:45:26,572] {logging_mixin.py:112} INFO - [2021-01-13 09:45:26,572] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:45:26,602] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:45:27,398] {logging_mixin.py:112} INFO - [2021-01-13 09:45:27,397] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:45:27,459] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:26.604474+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:26.604474+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 45, 26, 604474, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:45:27,609] {scheduler_job.py:155} INFO - Started process (PID=34) to work on /opt/airflow/dags/example.py
[2021-01-13 09:45:27,618] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:45:27,622] {logging_mixin.py:112} INFO - [2021-01-13 09:45:27,621] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:45:27,672] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:45:28,467] {logging_mixin.py:112} INFO - [2021-01-13 09:45:28,466] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:45:28,534] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:27.675376+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:27.675376+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 45, 27, 675376, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:45:29,562] {scheduler_job.py:155} INFO - Started process (PID=35) to work on /opt/airflow/dags/example.py
[2021-01-13 09:45:29,570] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:45:29,572] {logging_mixin.py:112} INFO - [2021-01-13 09:45:29,572] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:45:29,609] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:45:30,341] {logging_mixin.py:112} INFO - [2021-01-13 09:45:30,341] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:45:30,397] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:29.610445+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:29.610445+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 45, 29, 610445, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:45:30,634] {scheduler_job.py:155} INFO - Started process (PID=36) to work on /opt/airflow/dags/example.py
[2021-01-13 09:45:30,648] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:45:30,653] {logging_mixin.py:112} INFO - [2021-01-13 09:45:30,652] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:45:30,691] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:45:31,247] {logging_mixin.py:112} INFO - [2021-01-13 09:45:31,247] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:45:31,300] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:30.694117+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:30.694117+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 45, 30, 694117, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:45:31,613] {scheduler_job.py:155} INFO - Started process (PID=37) to work on /opt/airflow/dags/example.py
[2021-01-13 09:45:31,621] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:45:31,624] {logging_mixin.py:112} INFO - [2021-01-13 09:45:31,624] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:45:31,678] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:45:32,198] {logging_mixin.py:112} INFO - [2021-01-13 09:45:32,198] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:45:32,252] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:31.683701+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:31.683701+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 45, 31, 683701, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:45:32,626] {scheduler_job.py:155} INFO - Started process (PID=38) to work on /opt/airflow/dags/example.py
[2021-01-13 09:45:32,635] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:45:32,637] {logging_mixin.py:112} INFO - [2021-01-13 09:45:32,637] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:45:32,675] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:45:33,208] {logging_mixin.py:112} INFO - [2021-01-13 09:45:33,208] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:45:33,298] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:32.677127+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:32.677127+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 45, 32, 677127, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:45:33,648] {scheduler_job.py:155} INFO - Started process (PID=39) to work on /opt/airflow/dags/example.py
[2021-01-13 09:45:33,656] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:45:33,660] {logging_mixin.py:112} INFO - [2021-01-13 09:45:33,660] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:45:33,717] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:45:34,293] {logging_mixin.py:112} INFO - [2021-01-13 09:45:34,292] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:45:34,350] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:33.719079+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:33.719079+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 45, 33, 719079, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:45:34,835] {scheduler_job.py:155} INFO - Started process (PID=40) to work on /opt/airflow/dags/example.py
[2021-01-13 09:45:34,851] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:45:34,866] {logging_mixin.py:112} INFO - [2021-01-13 09:45:34,855] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:45:34,996] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:45:35,753] {logging_mixin.py:112} INFO - [2021-01-13 09:45:35,753] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:45:35,847] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:35.011717+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:35.011717+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 45, 35, 11717, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:45:36,841] {scheduler_job.py:155} INFO - Started process (PID=41) to work on /opt/airflow/dags/example.py
[2021-01-13 09:45:36,851] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:45:36,854] {logging_mixin.py:112} INFO - [2021-01-13 09:45:36,853] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:45:36,914] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:45:37,778] {logging_mixin.py:112} INFO - [2021-01-13 09:45:37,777] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:45:37,856] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:36.916839+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:36.916839+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 45, 36, 916839, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:45:38,853] {scheduler_job.py:155} INFO - Started process (PID=42) to work on /opt/airflow/dags/example.py
[2021-01-13 09:45:38,861] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:45:38,865] {logging_mixin.py:112} INFO - [2021-01-13 09:45:38,865] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:45:38,899] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:45:39,465] {logging_mixin.py:112} INFO - [2021-01-13 09:45:39,465] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:45:39,523] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:38.90409+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:38.90409+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 45, 38, 904090, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:45:39,878] {scheduler_job.py:155} INFO - Started process (PID=43) to work on /opt/airflow/dags/example.py
[2021-01-13 09:45:39,891] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:45:39,894] {logging_mixin.py:112} INFO - [2021-01-13 09:45:39,893] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:45:39,942] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:45:40,632] {logging_mixin.py:112} INFO - [2021-01-13 09:45:40,632] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:45:40,681] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:39.944387+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:39.944387+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 45, 39, 944387, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:45:40,894] {scheduler_job.py:155} INFO - Started process (PID=44) to work on /opt/airflow/dags/example.py
[2021-01-13 09:45:40,906] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:45:40,910] {logging_mixin.py:112} INFO - [2021-01-13 09:45:40,910] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:45:40,958] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:45:41,527] {logging_mixin.py:112} INFO - [2021-01-13 09:45:41,526] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:45:41,612] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:40.960727+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:40.960727+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 45, 40, 960727, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:45:41,913] {scheduler_job.py:155} INFO - Started process (PID=45) to work on /opt/airflow/dags/example.py
[2021-01-13 09:45:41,923] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:45:41,927] {logging_mixin.py:112} INFO - [2021-01-13 09:45:41,926] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:45:41,973] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:45:42,693] {logging_mixin.py:112} INFO - [2021-01-13 09:45:42,693] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:45:42,750] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:41.976118+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:41.976118+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 45, 41, 976118, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:45:42,939] {scheduler_job.py:155} INFO - Started process (PID=46) to work on /opt/airflow/dags/example.py
[2021-01-13 09:45:42,968] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:45:42,973] {logging_mixin.py:112} INFO - [2021-01-13 09:45:42,972] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:45:43,082] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:45:43,700] {logging_mixin.py:112} INFO - [2021-01-13 09:45:43,700] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:45:43,754] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:43.084694+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:43.084694+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 45, 43, 84694, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:45:43,975] {scheduler_job.py:155} INFO - Started process (PID=47) to work on /opt/airflow/dags/example.py
[2021-01-13 09:45:44,022] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:45:44,031] {logging_mixin.py:112} INFO - [2021-01-13 09:45:44,030] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:45:44,116] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:45:44,717] {logging_mixin.py:112} INFO - [2021-01-13 09:45:44,716] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:45:44,777] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:44.132383+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:44.132383+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 45, 44, 132383, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:45:45,212] {scheduler_job.py:155} INFO - Started process (PID=48) to work on /opt/airflow/dags/example.py
[2021-01-13 09:45:45,225] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:45:45,229] {logging_mixin.py:112} INFO - [2021-01-13 09:45:45,228] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:45:45,276] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:45:45,899] {logging_mixin.py:112} INFO - [2021-01-13 09:45:45,899] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:45:45,950] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:45.27864+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:45.27864+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 45, 45, 278640, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:45:46,233] {scheduler_job.py:155} INFO - Started process (PID=49) to work on /opt/airflow/dags/example.py
[2021-01-13 09:45:46,238] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:45:46,240] {logging_mixin.py:112} INFO - [2021-01-13 09:45:46,240] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:45:46,272] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:45:47,009] {logging_mixin.py:112} INFO - [2021-01-13 09:45:47,008] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:45:47,067] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:46.273996+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:46.273996+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 45, 46, 273996, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:45:47,255] {scheduler_job.py:155} INFO - Started process (PID=50) to work on /opt/airflow/dags/example.py
[2021-01-13 09:45:47,270] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:45:47,277] {logging_mixin.py:112} INFO - [2021-01-13 09:45:47,276] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:45:47,347] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:45:47,970] {logging_mixin.py:112} INFO - [2021-01-13 09:45:47,969] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:45:48,086] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:47.356159+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:47.356159+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 45, 47, 356159, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:45:48,274] {scheduler_job.py:155} INFO - Started process (PID=51) to work on /opt/airflow/dags/example.py
[2021-01-13 09:45:48,280] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:45:48,283] {logging_mixin.py:112} INFO - [2021-01-13 09:45:48,282] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:45:48,324] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:45:48,895] {logging_mixin.py:112} INFO - [2021-01-13 09:45:48,895] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:45:48,975] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:48.327203+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:48.327203+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 45, 48, 327203, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:45:49,329] {scheduler_job.py:155} INFO - Started process (PID=52) to work on /opt/airflow/dags/example.py
[2021-01-13 09:45:49,341] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:45:49,345] {logging_mixin.py:112} INFO - [2021-01-13 09:45:49,345] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:45:49,397] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:45:50,118] {logging_mixin.py:112} INFO - [2021-01-13 09:45:50,117] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:45:50,172] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:49.400262+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:49.400262+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 45, 49, 400262, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:45:50,328] {scheduler_job.py:155} INFO - Started process (PID=53) to work on /opt/airflow/dags/example.py
[2021-01-13 09:45:50,337] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:45:50,340] {logging_mixin.py:112} INFO - [2021-01-13 09:45:50,339] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:45:50,382] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:45:51,050] {logging_mixin.py:112} INFO - [2021-01-13 09:45:51,049] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:45:51,115] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:50.387861+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:50.387861+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 45, 50, 387861, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:45:51,358] {scheduler_job.py:155} INFO - Started process (PID=54) to work on /opt/airflow/dags/example.py
[2021-01-13 09:45:51,376] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:45:51,379] {logging_mixin.py:112} INFO - [2021-01-13 09:45:51,378] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:45:51,415] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:45:52,155] {logging_mixin.py:112} INFO - [2021-01-13 09:45:52,154] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:45:52,216] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:51.416895+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:51.416895+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 45, 51, 416895, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:45:52,382] {scheduler_job.py:155} INFO - Started process (PID=55) to work on /opt/airflow/dags/example.py
[2021-01-13 09:45:52,388] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:45:52,390] {logging_mixin.py:112} INFO - [2021-01-13 09:45:52,390] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:45:52,421] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:45:52,961] {logging_mixin.py:112} INFO - [2021-01-13 09:45:52,960] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:45:53,021] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:52.423332+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:52.423332+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 45, 52, 423332, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:45:53,385] {scheduler_job.py:155} INFO - Started process (PID=56) to work on /opt/airflow/dags/example.py
[2021-01-13 09:45:53,393] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:45:53,396] {logging_mixin.py:112} INFO - [2021-01-13 09:45:53,395] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:45:53,425] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:45:54,005] {logging_mixin.py:112} INFO - [2021-01-13 09:45:54,005] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:45:54,129] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:53.42745+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:53.42745+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 45, 53, 427450, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:45:54,401] {scheduler_job.py:155} INFO - Started process (PID=57) to work on /opt/airflow/dags/example.py
[2021-01-13 09:45:54,407] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:45:54,410] {logging_mixin.py:112} INFO - [2021-01-13 09:45:54,409] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:45:54,445] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:45:55,116] {logging_mixin.py:112} INFO - [2021-01-13 09:45:55,115] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:45:55,174] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:54.447582+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:54.447582+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 45, 54, 447582, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:45:55,544] {scheduler_job.py:155} INFO - Started process (PID=58) to work on /opt/airflow/dags/example.py
[2021-01-13 09:45:55,551] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:45:55,554] {logging_mixin.py:112} INFO - [2021-01-13 09:45:55,554] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:45:55,585] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:45:56,110] {logging_mixin.py:112} INFO - [2021-01-13 09:45:56,110] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:45:56,181] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:55.587923+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:55.587923+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 45, 55, 587923, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:45:56,597] {scheduler_job.py:155} INFO - Started process (PID=59) to work on /opt/airflow/dags/example.py
[2021-01-13 09:45:56,614] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:45:56,631] {logging_mixin.py:112} INFO - [2021-01-13 09:45:56,631] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:45:56,751] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:45:57,361] {logging_mixin.py:112} INFO - [2021-01-13 09:45:57,361] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:45:57,425] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:56.7877+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:56.7877+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 45, 56, 787700, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:45:57,584] {scheduler_job.py:155} INFO - Started process (PID=60) to work on /opt/airflow/dags/example.py
[2021-01-13 09:45:57,596] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:45:57,605] {logging_mixin.py:112} INFO - [2021-01-13 09:45:57,605] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:45:57,641] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:45:58,321] {logging_mixin.py:112} INFO - [2021-01-13 09:45:58,320] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:45:58,375] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:57.64281+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:57.64281+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 45, 57, 642810, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:45:58,631] {scheduler_job.py:155} INFO - Started process (PID=61) to work on /opt/airflow/dags/example.py
[2021-01-13 09:45:58,650] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:45:58,653] {logging_mixin.py:112} INFO - [2021-01-13 09:45:58,653] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:45:58,735] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:45:59,259] {logging_mixin.py:112} INFO - [2021-01-13 09:45:59,258] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:45:59,314] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:58.737823+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:58.737823+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 45, 58, 737823, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:45:59,629] {scheduler_job.py:155} INFO - Started process (PID=62) to work on /opt/airflow/dags/example.py
[2021-01-13 09:45:59,638] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:45:59,643] {logging_mixin.py:112} INFO - [2021-01-13 09:45:59,642] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:45:59,718] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:00,312] {logging_mixin.py:112} INFO - [2021-01-13 09:46:00,312] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:00,373] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:59.723084+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:45:59.723084+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 45, 59, 723084, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:00,658] {scheduler_job.py:155} INFO - Started process (PID=63) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:00,692] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:00,706] {logging_mixin.py:112} INFO - [2021-01-13 09:46:00,705] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:00,933] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:01,557] {logging_mixin.py:112} INFO - [2021-01-13 09:46:01,556] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:01,616] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:00.937088+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:00.937088+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 0, 937088, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:01,741] {scheduler_job.py:155} INFO - Started process (PID=64) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:01,759] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:01,762] {logging_mixin.py:112} INFO - [2021-01-13 09:46:01,762] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:01,840] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:02,443] {logging_mixin.py:112} INFO - [2021-01-13 09:46:02,443] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:02,498] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:01.84431+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:01.84431+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 1, 844310, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:02,700] {scheduler_job.py:155} INFO - Started process (PID=65) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:02,715] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:02,717] {logging_mixin.py:112} INFO - [2021-01-13 09:46:02,717] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:02,771] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:03,371] {logging_mixin.py:112} INFO - [2021-01-13 09:46:03,371] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:03,418] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:02.774089+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:02.774089+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 2, 774089, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:03,709] {scheduler_job.py:155} INFO - Started process (PID=66) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:03,724] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:03,729] {logging_mixin.py:112} INFO - [2021-01-13 09:46:03,728] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:03,789] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:04,616] {logging_mixin.py:112} INFO - [2021-01-13 09:46:04,616] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:04,672] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:03.791594+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:03.791594+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 3, 791594, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:05,934] {scheduler_job.py:155} INFO - Started process (PID=67) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:05,957] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:05,961] {logging_mixin.py:112} INFO - [2021-01-13 09:46:05,960] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:06,095] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:06,768] {logging_mixin.py:112} INFO - [2021-01-13 09:46:06,768] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:06,833] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:06.12239+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:06.12239+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 6, 122390, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:08,115] {scheduler_job.py:155} INFO - Started process (PID=68) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:08,131] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:08,136] {logging_mixin.py:112} INFO - [2021-01-13 09:46:08,135] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:08,179] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:08,839] {logging_mixin.py:112} INFO - [2021-01-13 09:46:08,839] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:08,899] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:08.19661+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:08.19661+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 8, 196610, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:09,235] {scheduler_job.py:155} INFO - Started process (PID=69) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:09,246] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:09,250] {logging_mixin.py:112} INFO - [2021-01-13 09:46:09,249] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:09,302] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:09,970] {logging_mixin.py:112} INFO - [2021-01-13 09:46:09,970] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:10,053] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:09.304624+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:09.304624+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 9, 304624, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:10,251] {scheduler_job.py:155} INFO - Started process (PID=70) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:10,257] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:10,261] {logging_mixin.py:112} INFO - [2021-01-13 09:46:10,260] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:10,310] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:10,859] {logging_mixin.py:112} INFO - [2021-01-13 09:46:10,858] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:10,934] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:10.31315+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:10.31315+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 10, 313150, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:11,269] {scheduler_job.py:155} INFO - Started process (PID=71) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:11,283] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:11,285] {logging_mixin.py:112} INFO - [2021-01-13 09:46:11,285] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:11,320] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:11,977] {logging_mixin.py:112} INFO - [2021-01-13 09:46:11,977] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:12,038] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:11.322326+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:11.322326+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 11, 322326, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:12,290] {scheduler_job.py:155} INFO - Started process (PID=72) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:12,299] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:12,311] {logging_mixin.py:112} INFO - [2021-01-13 09:46:12,310] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:12,340] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:12,839] {logging_mixin.py:112} INFO - [2021-01-13 09:46:12,839] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:12,897] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:12.341618+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:12.341618+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 12, 341618, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:13,304] {scheduler_job.py:155} INFO - Started process (PID=73) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:13,317] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:13,320] {logging_mixin.py:112} INFO - [2021-01-13 09:46:13,320] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:13,360] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:13,956] {logging_mixin.py:112} INFO - [2021-01-13 09:46:13,956] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:14,017] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:13.362076+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:13.362076+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 13, 362076, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:14,340] {scheduler_job.py:155} INFO - Started process (PID=74) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:14,359] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:14,368] {logging_mixin.py:112} INFO - [2021-01-13 09:46:14,367] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:14,491] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:15,117] {logging_mixin.py:112} INFO - [2021-01-13 09:46:15,116] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:15,176] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:14.496971+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:14.496971+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 14, 496971, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:15,366] {scheduler_job.py:155} INFO - Started process (PID=75) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:15,374] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:15,381] {logging_mixin.py:112} INFO - [2021-01-13 09:46:15,381] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:15,437] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:16,141] {logging_mixin.py:112} INFO - [2021-01-13 09:46:16,140] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:16,209] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:15.460051+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:15.460051+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 15, 460051, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:16,574] {scheduler_job.py:155} INFO - Started process (PID=76) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:16,585] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:16,588] {logging_mixin.py:112} INFO - [2021-01-13 09:46:16,587] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:16,689] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:17,374] {logging_mixin.py:112} INFO - [2021-01-13 09:46:17,374] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:17,455] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:16.773945+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:16.773945+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 16, 773945, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:17,587] {scheduler_job.py:155} INFO - Started process (PID=77) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:17,599] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:17,601] {logging_mixin.py:112} INFO - [2021-01-13 09:46:17,601] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:17,639] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:18,216] {logging_mixin.py:112} INFO - [2021-01-13 09:46:18,216] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:18,281] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:17.641393+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:17.641393+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 17, 641393, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:18,593] {scheduler_job.py:155} INFO - Started process (PID=78) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:18,599] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:18,602] {logging_mixin.py:112} INFO - [2021-01-13 09:46:18,601] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:18,637] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:19,179] {logging_mixin.py:112} INFO - [2021-01-13 09:46:19,179] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:19,234] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:18.638731+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:18.638731+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 18, 638731, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:19,616] {scheduler_job.py:155} INFO - Started process (PID=79) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:19,622] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:19,624] {logging_mixin.py:112} INFO - [2021-01-13 09:46:19,624] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:19,651] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:20,230] {logging_mixin.py:112} INFO - [2021-01-13 09:46:20,230] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:20,303] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:19.653664+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:19.653664+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 19, 653664, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:20,641] {scheduler_job.py:155} INFO - Started process (PID=80) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:20,647] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:20,649] {logging_mixin.py:112} INFO - [2021-01-13 09:46:20,648] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:20,695] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:21,284] {logging_mixin.py:112} INFO - [2021-01-13 09:46:21,284] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:21,345] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:20.697684+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:20.697684+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 20, 697684, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:21,754] {scheduler_job.py:155} INFO - Started process (PID=81) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:21,771] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:21,774] {logging_mixin.py:112} INFO - [2021-01-13 09:46:21,774] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:21,824] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:22,366] {logging_mixin.py:112} INFO - [2021-01-13 09:46:22,365] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:22,435] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:21.826975+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:21.826975+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 21, 826975, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:22,699] {scheduler_job.py:155} INFO - Started process (PID=82) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:22,706] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:22,709] {logging_mixin.py:112} INFO - [2021-01-13 09:46:22,708] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:22,748] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:23,313] {logging_mixin.py:112} INFO - [2021-01-13 09:46:23,313] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:23,363] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:22.751374+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:22.751374+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 22, 751374, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:23,721] {scheduler_job.py:155} INFO - Started process (PID=83) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:23,736] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:23,740] {logging_mixin.py:112} INFO - [2021-01-13 09:46:23,739] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:23,801] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:24,556] {logging_mixin.py:112} INFO - [2021-01-13 09:46:24,556] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:24,607] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:23.803449+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:23.803449+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 23, 803449, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:24,731] {scheduler_job.py:155} INFO - Started process (PID=84) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:24,737] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:24,740] {logging_mixin.py:112} INFO - [2021-01-13 09:46:24,739] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:24,778] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:25,437] {logging_mixin.py:112} INFO - [2021-01-13 09:46:25,437] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:25,485] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:24.782466+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:24.782466+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 24, 782466, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:25,743] {scheduler_job.py:155} INFO - Started process (PID=85) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:25,757] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:25,760] {logging_mixin.py:112} INFO - [2021-01-13 09:46:25,759] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:25,804] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:26,372] {logging_mixin.py:112} INFO - [2021-01-13 09:46:26,371] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:26,431] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:25.80729+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:25.80729+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 25, 807290, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:26,890] {scheduler_job.py:155} INFO - Started process (PID=86) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:26,896] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:26,898] {logging_mixin.py:112} INFO - [2021-01-13 09:46:26,898] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:26,931] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:27,495] {logging_mixin.py:112} INFO - [2021-01-13 09:46:27,495] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:27,546] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:26.933869+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:26.933869+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 26, 933869, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:27,918] {scheduler_job.py:155} INFO - Started process (PID=87) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:27,926] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:27,931] {logging_mixin.py:112} INFO - [2021-01-13 09:46:27,929] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:27,973] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:28,517] {logging_mixin.py:112} INFO - [2021-01-13 09:46:28,517] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:28,577] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:27.976139+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:27.976139+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 27, 976139, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:28,892] {scheduler_job.py:155} INFO - Started process (PID=88) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:28,902] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:28,904] {logging_mixin.py:112} INFO - [2021-01-13 09:46:28,904] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:28,939] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:29,496] {logging_mixin.py:112} INFO - [2021-01-13 09:46:29,496] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:29,551] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:28.941413+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:28.941413+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 28, 941413, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:29,926] {scheduler_job.py:155} INFO - Started process (PID=89) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:29,939] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:29,943] {logging_mixin.py:112} INFO - [2021-01-13 09:46:29,943] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:29,988] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:30,652] {logging_mixin.py:112} INFO - [2021-01-13 09:46:30,652] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:30,712] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:29.990434+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:29.990434+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 29, 990434, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:30,973] {scheduler_job.py:155} INFO - Started process (PID=90) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:30,980] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:30,983] {logging_mixin.py:112} INFO - [2021-01-13 09:46:30,983] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:31,025] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:31,675] {logging_mixin.py:112} INFO - [2021-01-13 09:46:31,675] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:31,736] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:31.028713+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:31.028713+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 31, 28713, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:31,991] {scheduler_job.py:155} INFO - Started process (PID=91) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:31,998] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:32,001] {logging_mixin.py:112} INFO - [2021-01-13 09:46:32,000] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:32,038] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:32,829] {logging_mixin.py:112} INFO - [2021-01-13 09:46:32,828] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:32,897] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:32.040608+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:32.040608+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 32, 40608, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:33,020] {scheduler_job.py:155} INFO - Started process (PID=92) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:33,030] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:33,035] {logging_mixin.py:112} INFO - [2021-01-13 09:46:33,034] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:33,086] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:33,631] {logging_mixin.py:112} INFO - [2021-01-13 09:46:33,631] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:33,683] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:33.087559+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:33.087559+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 33, 87559, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:34,056] {scheduler_job.py:155} INFO - Started process (PID=93) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:34,074] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:34,077] {logging_mixin.py:112} INFO - [2021-01-13 09:46:34,077] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:34,130] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:34,694] {logging_mixin.py:112} INFO - [2021-01-13 09:46:34,694] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:34,751] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:34.132399+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:34.132399+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 34, 132399, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:35,054] {scheduler_job.py:155} INFO - Started process (PID=94) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:35,060] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:35,062] {logging_mixin.py:112} INFO - [2021-01-13 09:46:35,062] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:35,092] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:35,790] {logging_mixin.py:112} INFO - [2021-01-13 09:46:35,789] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:35,843] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:35.093559+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:35.093559+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 35, 93559, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:36,093] {scheduler_job.py:155} INFO - Started process (PID=95) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:36,107] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:36,114] {logging_mixin.py:112} INFO - [2021-01-13 09:46:36,112] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:36,173] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:36,749] {logging_mixin.py:112} INFO - [2021-01-13 09:46:36,749] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:36,804] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:36.176982+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:36.176982+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 36, 176982, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:37,243] {scheduler_job.py:155} INFO - Started process (PID=96) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:37,250] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:37,254] {logging_mixin.py:112} INFO - [2021-01-13 09:46:37,254] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:37,290] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:37,951] {logging_mixin.py:112} INFO - [2021-01-13 09:46:37,951] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:38,004] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:37.291931+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:37.291931+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 37, 291931, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:38,241] {scheduler_job.py:155} INFO - Started process (PID=97) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:38,247] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:38,249] {logging_mixin.py:112} INFO - [2021-01-13 09:46:38,249] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:38,279] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:38,839] {logging_mixin.py:112} INFO - [2021-01-13 09:46:38,838] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:38,903] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:38.280935+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:38.280935+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 38, 280935, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:39,276] {scheduler_job.py:155} INFO - Started process (PID=98) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:39,282] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:39,289] {logging_mixin.py:112} INFO - [2021-01-13 09:46:39,287] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:39,346] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:39,972] {logging_mixin.py:112} INFO - [2021-01-13 09:46:39,971] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:40,198] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:39.348342+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:39.348342+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 39, 348342, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:40,284] {scheduler_job.py:155} INFO - Started process (PID=99) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:40,298] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:40,304] {logging_mixin.py:112} INFO - [2021-01-13 09:46:40,304] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:40,344] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:40,986] {logging_mixin.py:112} INFO - [2021-01-13 09:46:40,986] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:41,067] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:40.347672+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:40.347672+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 40, 347672, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:41,305] {scheduler_job.py:155} INFO - Started process (PID=100) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:41,318] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:41,324] {logging_mixin.py:112} INFO - [2021-01-13 09:46:41,323] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:41,401] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:41,955] {logging_mixin.py:112} INFO - [2021-01-13 09:46:41,955] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:42,021] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:41.405457+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:41.405457+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 41, 405457, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:42,322] {scheduler_job.py:155} INFO - Started process (PID=101) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:42,335] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:42,339] {logging_mixin.py:112} INFO - [2021-01-13 09:46:42,338] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:42,369] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:42,926] {logging_mixin.py:112} INFO - [2021-01-13 09:46:42,925] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:42,977] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:42.370303+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:42.370303+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 42, 370303, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:43,330] {scheduler_job.py:155} INFO - Started process (PID=102) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:43,343] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:43,345] {logging_mixin.py:112} INFO - [2021-01-13 09:46:43,345] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:43,377] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:43,955] {logging_mixin.py:112} INFO - [2021-01-13 09:46:43,954] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:44,012] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:43.379343+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:43.379343+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 43, 379343, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:44,343] {scheduler_job.py:155} INFO - Started process (PID=103) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:44,355] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:44,357] {logging_mixin.py:112} INFO - [2021-01-13 09:46:44,357] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:44,393] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:44,972] {logging_mixin.py:112} INFO - [2021-01-13 09:46:44,971] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:45,021] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:44.395707+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:44.395707+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 44, 395707, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:45,361] {scheduler_job.py:155} INFO - Started process (PID=104) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:45,378] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:45,390] {logging_mixin.py:112} INFO - [2021-01-13 09:46:45,381] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:45,446] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:46,133] {logging_mixin.py:112} INFO - [2021-01-13 09:46:46,132] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:46,193] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:45.448199+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:45.448199+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 45, 448199, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:46,365] {scheduler_job.py:155} INFO - Started process (PID=105) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:46,375] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:46,377] {logging_mixin.py:112} INFO - [2021-01-13 09:46:46,376] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:46,426] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:47,014] {logging_mixin.py:112} INFO - [2021-01-13 09:46:47,014] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:47,078] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:46.427714+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:46.427714+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 46, 427714, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:47,492] {scheduler_job.py:155} INFO - Started process (PID=106) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:47,506] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:47,508] {logging_mixin.py:112} INFO - [2021-01-13 09:46:47,508] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:47,538] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:48,081] {logging_mixin.py:112} INFO - [2021-01-13 09:46:48,081] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:48,139] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:47.539754+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:47.539754+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 47, 539754, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:48,520] {scheduler_job.py:155} INFO - Started process (PID=107) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:48,525] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:48,528] {logging_mixin.py:112} INFO - [2021-01-13 09:46:48,527] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:48,561] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:49,075] {logging_mixin.py:112} INFO - [2021-01-13 09:46:49,075] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:49,129] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:48.563307+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:48.563307+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 48, 563307, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:49,532] {scheduler_job.py:155} INFO - Started process (PID=108) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:49,544] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:49,546] {logging_mixin.py:112} INFO - [2021-01-13 09:46:49,546] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:49,588] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:50,230] {logging_mixin.py:112} INFO - [2021-01-13 09:46:50,230] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:50,282] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:49.589968+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:49.589968+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 49, 589968, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:50,562] {scheduler_job.py:155} INFO - Started process (PID=109) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:50,575] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:50,581] {logging_mixin.py:112} INFO - [2021-01-13 09:46:50,580] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:50,656] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:51,275] {logging_mixin.py:112} INFO - [2021-01-13 09:46:51,275] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:51,346] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:50.657864+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:50.657864+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 50, 657864, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:51,587] {scheduler_job.py:155} INFO - Started process (PID=110) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:51,601] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:51,603] {logging_mixin.py:112} INFO - [2021-01-13 09:46:51,603] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:51,652] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:52,249] {logging_mixin.py:112} INFO - [2021-01-13 09:46:52,249] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:52,301] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:51.655041+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:51.655041+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 51, 655041, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:52,610] {scheduler_job.py:155} INFO - Started process (PID=111) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:52,621] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:52,623] {logging_mixin.py:112} INFO - [2021-01-13 09:46:52,623] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:52,666] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:53,383] {logging_mixin.py:112} INFO - [2021-01-13 09:46:53,383] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:53,433] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:52.669406+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:52.669406+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 52, 669406, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:53,631] {scheduler_job.py:155} INFO - Started process (PID=112) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:53,637] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:53,639] {logging_mixin.py:112} INFO - [2021-01-13 09:46:53,639] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:53,669] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:54,222] {logging_mixin.py:112} INFO - [2021-01-13 09:46:54,222] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:54,281] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:53.671636+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:53.671636+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 53, 671636, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:54,644] {scheduler_job.py:155} INFO - Started process (PID=113) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:54,651] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:54,653] {logging_mixin.py:112} INFO - [2021-01-13 09:46:54,652] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:54,680] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:55,221] {logging_mixin.py:112} INFO - [2021-01-13 09:46:55,221] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:55,265] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:54.682+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:54.682+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 54, 682000, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:55,657] {scheduler_job.py:155} INFO - Started process (PID=114) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:55,664] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:55,666] {logging_mixin.py:112} INFO - [2021-01-13 09:46:55,665] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:55,695] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:56,253] {logging_mixin.py:112} INFO - [2021-01-13 09:46:56,253] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:56,302] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:55.696845+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:55.696845+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 55, 696845, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:56,690] {scheduler_job.py:155} INFO - Started process (PID=115) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:56,710] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:56,712] {logging_mixin.py:112} INFO - [2021-01-13 09:46:56,712] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:56,762] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:57,503] {logging_mixin.py:112} INFO - [2021-01-13 09:46:57,503] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:57,559] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:56.764993+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:56.764993+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 56, 764993, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:57,804] {scheduler_job.py:155} INFO - Started process (PID=116) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:57,810] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:57,813] {logging_mixin.py:112} INFO - [2021-01-13 09:46:57,812] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:57,840] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:58,343] {logging_mixin.py:112} INFO - [2021-01-13 09:46:58,343] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:58,575] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:57.84191+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:57.84191+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 57, 841910, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:58,796] {scheduler_job.py:155} INFO - Started process (PID=117) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:58,809] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:58,812] {logging_mixin.py:112} INFO - [2021-01-13 09:46:58,812] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:58,846] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:46:59,447] {logging_mixin.py:112} INFO - [2021-01-13 09:46:59,447] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:46:59,518] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:58.847804+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:46:58.847804+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 46, 58, 847804, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:46:59,822] {scheduler_job.py:155} INFO - Started process (PID=118) to work on /opt/airflow/dags/example.py
[2021-01-13 09:46:59,826] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:46:59,828] {logging_mixin.py:112} INFO - [2021-01-13 09:46:59,828] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:46:59,855] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:48:11,630] {scheduler_job.py:155} INFO - Started process (PID=16) to work on /opt/airflow/dags/example.py
[2021-01-13 09:48:11,642] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:48:11,645] {logging_mixin.py:112} INFO - [2021-01-13 09:48:11,644] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:48:11,712] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:48:12,211] {logging_mixin.py:112} INFO - [2021-01-13 09:48:12,211] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:48:12,271] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:11.715987+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:11.715987+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 48, 11, 715987, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:48:12,665] {scheduler_job.py:155} INFO - Started process (PID=17) to work on /opt/airflow/dags/example.py
[2021-01-13 09:48:12,680] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:48:12,684] {logging_mixin.py:112} INFO - [2021-01-13 09:48:12,683] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:48:12,748] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:48:13,286] {logging_mixin.py:112} INFO - [2021-01-13 09:48:13,286] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:48:13,341] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:12.750724+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:12.750724+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 48, 12, 750724, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:48:13,695] {scheduler_job.py:155} INFO - Started process (PID=18) to work on /opt/airflow/dags/example.py
[2021-01-13 09:48:13,709] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:48:13,713] {logging_mixin.py:112} INFO - [2021-01-13 09:48:13,712] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:48:13,775] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:48:14,421] {logging_mixin.py:112} INFO - [2021-01-13 09:48:14,420] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:48:14,467] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:13.778346+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:13.778346+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 48, 13, 778346, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:48:14,898] {scheduler_job.py:155} INFO - Started process (PID=19) to work on /opt/airflow/dags/example.py
[2021-01-13 09:48:14,931] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:48:14,934] {logging_mixin.py:112} INFO - [2021-01-13 09:48:14,934] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:48:15,073] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:48:15,761] {logging_mixin.py:112} INFO - [2021-01-13 09:48:15,760] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:48:15,997] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:15.084489+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:15.084489+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 48, 15, 84489, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:48:16,904] {scheduler_job.py:155} INFO - Started process (PID=20) to work on /opt/airflow/dags/example.py
[2021-01-13 09:48:16,916] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:48:16,921] {logging_mixin.py:112} INFO - [2021-01-13 09:48:16,921] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:48:16,951] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:48:17,481] {logging_mixin.py:112} INFO - [2021-01-13 09:48:17,481] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:48:17,533] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:16.953539+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:16.953539+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 48, 16, 953539, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:48:17,939] {scheduler_job.py:155} INFO - Started process (PID=21) to work on /opt/airflow/dags/example.py
[2021-01-13 09:48:17,947] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:48:17,950] {logging_mixin.py:112} INFO - [2021-01-13 09:48:17,949] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:48:17,983] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:48:18,525] {logging_mixin.py:112} INFO - [2021-01-13 09:48:18,524] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:48:18,584] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:17.985626+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:17.985626+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 48, 17, 985626, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:48:18,940] {scheduler_job.py:155} INFO - Started process (PID=22) to work on /opt/airflow/dags/example.py
[2021-01-13 09:48:18,946] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:48:18,949] {logging_mixin.py:112} INFO - [2021-01-13 09:48:18,949] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:48:18,997] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:48:19,704] {logging_mixin.py:112} INFO - [2021-01-13 09:48:19,703] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:48:19,756] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:18.99968+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:18.99968+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 48, 18, 999680, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:48:19,952] {scheduler_job.py:155} INFO - Started process (PID=23) to work on /opt/airflow/dags/example.py
[2021-01-13 09:48:19,958] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:48:19,960] {logging_mixin.py:112} INFO - [2021-01-13 09:48:19,960] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:48:19,991] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:48:20,715] {logging_mixin.py:112} INFO - [2021-01-13 09:48:20,715] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:48:20,773] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:19.993389+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:19.993389+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 48, 19, 993389, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:48:20,966] {scheduler_job.py:155} INFO - Started process (PID=24) to work on /opt/airflow/dags/example.py
[2021-01-13 09:48:20,981] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:48:20,985] {logging_mixin.py:112} INFO - [2021-01-13 09:48:20,985] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:48:21,065] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:48:21,617] {logging_mixin.py:112} INFO - [2021-01-13 09:48:21,617] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:48:21,669] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:21.067988+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:21.067988+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 48, 21, 67988, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:48:22,092] {scheduler_job.py:155} INFO - Started process (PID=25) to work on /opt/airflow/dags/example.py
[2021-01-13 09:48:22,105] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:48:22,110] {logging_mixin.py:112} INFO - [2021-01-13 09:48:22,109] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:48:22,151] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:48:22,961] {logging_mixin.py:112} INFO - [2021-01-13 09:48:22,961] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:48:23,014] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:22.15377+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:22.15377+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 48, 22, 153770, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:48:23,122] {scheduler_job.py:155} INFO - Started process (PID=26) to work on /opt/airflow/dags/example.py
[2021-01-13 09:48:23,131] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:48:23,144] {logging_mixin.py:112} INFO - [2021-01-13 09:48:23,144] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:48:23,212] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:48:23,695] {logging_mixin.py:112} INFO - [2021-01-13 09:48:23,694] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:48:23,744] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:23.217983+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:23.217983+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 48, 23, 217983, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:48:24,152] {scheduler_job.py:155} INFO - Started process (PID=27) to work on /opt/airflow/dags/example.py
[2021-01-13 09:48:24,157] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:48:24,160] {logging_mixin.py:112} INFO - [2021-01-13 09:48:24,159] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:48:24,189] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:48:24,796] {logging_mixin.py:112} INFO - [2021-01-13 09:48:24,795] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:48:24,854] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:24.191425+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:24.191425+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 48, 24, 191425, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:48:25,168] {scheduler_job.py:155} INFO - Started process (PID=28) to work on /opt/airflow/dags/example.py
[2021-01-13 09:48:25,174] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:48:25,176] {logging_mixin.py:112} INFO - [2021-01-13 09:48:25,176] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:48:25,205] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:48:25,950] {logging_mixin.py:112} INFO - [2021-01-13 09:48:25,949] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:48:26,012] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:25.207162+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:25.207162+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 48, 25, 207162, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:48:26,186] {scheduler_job.py:155} INFO - Started process (PID=29) to work on /opt/airflow/dags/example.py
[2021-01-13 09:48:26,192] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:48:26,194] {logging_mixin.py:112} INFO - [2021-01-13 09:48:26,194] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:48:26,236] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:48:26,826] {logging_mixin.py:112} INFO - [2021-01-13 09:48:26,826] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:48:26,896] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:26.238307+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:26.238307+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 48, 26, 238307, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:48:27,201] {scheduler_job.py:155} INFO - Started process (PID=30) to work on /opt/airflow/dags/example.py
[2021-01-13 09:48:27,207] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:48:27,210] {logging_mixin.py:112} INFO - [2021-01-13 09:48:27,210] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:48:27,249] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:48:27,862] {logging_mixin.py:112} INFO - [2021-01-13 09:48:27,862] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:48:27,888] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:27.25163+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:27.25163+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 48, 27, 251630, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:48:28,189] {scheduler_job.py:155} INFO - Started process (PID=31) to work on /opt/airflow/dags/example.py
[2021-01-13 09:48:28,224] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:48:28,227] {logging_mixin.py:112} INFO - [2021-01-13 09:48:28,226] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:48:28,289] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:48:28,848] {logging_mixin.py:112} INFO - [2021-01-13 09:48:28,847] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:48:28,919] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:28.292048+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:28.292048+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 48, 28, 292048, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:48:29,209] {scheduler_job.py:155} INFO - Started process (PID=32) to work on /opt/airflow/dags/example.py
[2021-01-13 09:48:29,218] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:48:29,220] {logging_mixin.py:112} INFO - [2021-01-13 09:48:29,220] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:48:29,251] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:48:29,772] {logging_mixin.py:112} INFO - [2021-01-13 09:48:29,772] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:48:29,834] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:29.252805+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:29.252805+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 48, 29, 252805, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:48:30,229] {scheduler_job.py:155} INFO - Started process (PID=33) to work on /opt/airflow/dags/example.py
[2021-01-13 09:48:30,235] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:48:30,237] {logging_mixin.py:112} INFO - [2021-01-13 09:48:30,237] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:48:30,264] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:48:30,808] {logging_mixin.py:112} INFO - [2021-01-13 09:48:30,808] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:48:30,869] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:30.266146+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:30.266146+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 48, 30, 266146, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:48:31,260] {scheduler_job.py:155} INFO - Started process (PID=34) to work on /opt/airflow/dags/example.py
[2021-01-13 09:48:31,266] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:48:31,269] {logging_mixin.py:112} INFO - [2021-01-13 09:48:31,268] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:48:31,301] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:48:31,832] {logging_mixin.py:112} INFO - [2021-01-13 09:48:31,832] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:48:31,882] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:31.302965+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:31.302965+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 48, 31, 302965, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:48:32,418] {scheduler_job.py:155} INFO - Started process (PID=35) to work on /opt/airflow/dags/example.py
[2021-01-13 09:48:32,425] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:48:32,428] {logging_mixin.py:112} INFO - [2021-01-13 09:48:32,428] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:48:32,462] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:48:33,028] {logging_mixin.py:112} INFO - [2021-01-13 09:48:33,028] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:48:33,097] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:32.464286+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:32.464286+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 48, 32, 464286, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:48:33,455] {scheduler_job.py:155} INFO - Started process (PID=36) to work on /opt/airflow/dags/example.py
[2021-01-13 09:48:33,462] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:48:33,465] {logging_mixin.py:112} INFO - [2021-01-13 09:48:33,465] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:48:33,545] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:48:34,078] {logging_mixin.py:112} INFO - [2021-01-13 09:48:34,077] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:48:34,185] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:33.5482+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:33.5482+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 48, 33, 548200, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:48:34,459] {scheduler_job.py:155} INFO - Started process (PID=37) to work on /opt/airflow/dags/example.py
[2021-01-13 09:48:34,471] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:48:34,475] {logging_mixin.py:112} INFO - [2021-01-13 09:48:34,475] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:48:34,534] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:48:35,186] {logging_mixin.py:112} INFO - [2021-01-13 09:48:35,186] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:48:35,245] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:34.537783+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:34.537783+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 48, 34, 537783, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:48:35,499] {scheduler_job.py:155} INFO - Started process (PID=38) to work on /opt/airflow/dags/example.py
[2021-01-13 09:48:35,506] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:48:35,509] {logging_mixin.py:112} INFO - [2021-01-13 09:48:35,509] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:48:35,546] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:48:36,077] {logging_mixin.py:112} INFO - [2021-01-13 09:48:36,077] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:48:36,133] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:35.547844+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:35.547844+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 48, 35, 547844, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:48:36,492] {scheduler_job.py:155} INFO - Started process (PID=39) to work on /opt/airflow/dags/example.py
[2021-01-13 09:48:36,499] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:48:36,501] {logging_mixin.py:112} INFO - [2021-01-13 09:48:36,501] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:48:36,532] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:48:37,064] {logging_mixin.py:112} INFO - [2021-01-13 09:48:37,064] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:48:37,127] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:36.53393+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:36.53393+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 48, 36, 533930, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:48:37,514] {scheduler_job.py:155} INFO - Started process (PID=40) to work on /opt/airflow/dags/example.py
[2021-01-13 09:48:37,526] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:48:37,528] {logging_mixin.py:112} INFO - [2021-01-13 09:48:37,528] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:48:37,557] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:48:38,124] {logging_mixin.py:112} INFO - [2021-01-13 09:48:38,124] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:48:38,179] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:37.559413+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:37.559413+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 48, 37, 559413, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:48:38,554] {scheduler_job.py:155} INFO - Started process (PID=41) to work on /opt/airflow/dags/example.py
[2021-01-13 09:48:38,560] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:48:38,563] {logging_mixin.py:112} INFO - [2021-01-13 09:48:38,563] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:48:38,611] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:48:39,126] {logging_mixin.py:112} INFO - [2021-01-13 09:48:39,126] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:48:39,171] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:38.613283+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:38.613283+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 48, 38, 613283, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:48:39,562] {scheduler_job.py:155} INFO - Started process (PID=42) to work on /opt/airflow/dags/example.py
[2021-01-13 09:48:39,567] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:48:39,569] {logging_mixin.py:112} INFO - [2021-01-13 09:48:39,568] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:48:39,596] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:48:40,161] {logging_mixin.py:112} INFO - [2021-01-13 09:48:40,161] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:48:40,216] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:39.597931+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:39.597931+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 48, 39, 597931, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:48:40,599] {scheduler_job.py:155} INFO - Started process (PID=43) to work on /opt/airflow/dags/example.py
[2021-01-13 09:48:40,606] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:48:40,608] {logging_mixin.py:112} INFO - [2021-01-13 09:48:40,608] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:48:40,641] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:48:41,375] {logging_mixin.py:112} INFO - [2021-01-13 09:48:41,375] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:48:41,428] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:40.643217+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:40.643217+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 48, 40, 643217, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:48:41,608] {scheduler_job.py:155} INFO - Started process (PID=44) to work on /opt/airflow/dags/example.py
[2021-01-13 09:48:41,613] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:48:41,615] {logging_mixin.py:112} INFO - [2021-01-13 09:48:41,615] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:48:41,653] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:48:42,223] {logging_mixin.py:112} INFO - [2021-01-13 09:48:42,222] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:48:42,266] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:41.655942+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:41.655942+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 48, 41, 655942, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:48:42,756] {scheduler_job.py:155} INFO - Started process (PID=45) to work on /opt/airflow/dags/example.py
[2021-01-13 09:48:42,764] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:48:42,766] {logging_mixin.py:112} INFO - [2021-01-13 09:48:42,766] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:48:42,796] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:48:43,475] {logging_mixin.py:112} INFO - [2021-01-13 09:48:43,475] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:48:43,547] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:42.798146+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:42.798146+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 48, 42, 798146, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:48:43,800] {scheduler_job.py:155} INFO - Started process (PID=46) to work on /opt/airflow/dags/example.py
[2021-01-13 09:48:43,807] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:48:43,810] {logging_mixin.py:112} INFO - [2021-01-13 09:48:43,810] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:48:43,847] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:48:44,403] {logging_mixin.py:112} INFO - [2021-01-13 09:48:44,402] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:48:44,465] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:43.850089+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:43.850089+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 48, 43, 850089, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:48:44,803] {scheduler_job.py:155} INFO - Started process (PID=47) to work on /opt/airflow/dags/example.py
[2021-01-13 09:48:44,810] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:48:44,812] {logging_mixin.py:112} INFO - [2021-01-13 09:48:44,812] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:48:44,847] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:48:45,582] {logging_mixin.py:112} INFO - [2021-01-13 09:48:45,582] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:48:45,635] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:44.849531+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:44.849531+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 48, 44, 849531, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:48:45,829] {scheduler_job.py:155} INFO - Started process (PID=48) to work on /opt/airflow/dags/example.py
[2021-01-13 09:48:45,851] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:48:45,855] {logging_mixin.py:112} INFO - [2021-01-13 09:48:45,855] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:48:45,895] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:48:46,621] {logging_mixin.py:112} INFO - [2021-01-13 09:48:46,621] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:48:46,670] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:45.897262+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:48:45.897262+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 48, 45, 897262, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:48:46,879] {scheduler_job.py:155} INFO - Started process (PID=49) to work on /opt/airflow/dags/example.py
[2021-01-13 09:48:46,890] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:48:46,893] {logging_mixin.py:112} INFO - [2021-01-13 09:48:46,893] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:48:46,936] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:48:47,528] {logging_mixin.py:112} INFO - [2021-01-13 09:48:47,528] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:48:47,583] {scheduler_job.py:423} INFO - Exiting gracefully upon receiving signal 15
[2021-01-13 09:50:26,306] {scheduler_job.py:155} INFO - Started process (PID=15) to work on /opt/airflow/dags/example.py
[2021-01-13 09:50:26,313] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:50:26,316] {logging_mixin.py:112} INFO - [2021-01-13 09:50:26,316] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:50:26,372] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:50:27,084] {logging_mixin.py:112} INFO - [2021-01-13 09:50:27,083] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:50:27,135] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:50:26.375217+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:50:26.375217+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 50, 26, 375217, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:50:27,351] {scheduler_job.py:155} INFO - Started process (PID=16) to work on /opt/airflow/dags/example.py
[2021-01-13 09:50:27,372] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:50:27,375] {logging_mixin.py:112} INFO - [2021-01-13 09:50:27,375] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:50:27,426] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:50:27,923] {logging_mixin.py:112} INFO - [2021-01-13 09:50:27,923] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:50:27,979] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:50:27.429175+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:50:27.429175+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 50, 27, 429175, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:50:28,371] {scheduler_job.py:155} INFO - Started process (PID=17) to work on /opt/airflow/dags/example.py
[2021-01-13 09:50:28,414] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:50:28,422] {logging_mixin.py:112} INFO - [2021-01-13 09:50:28,421] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:50:28,552] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:50:29,124] {logging_mixin.py:112} INFO - [2021-01-13 09:50:29,124] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:50:29,180] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:50:28.55523+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:50:28.55523+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 50, 28, 555230, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:50:29,357] {scheduler_job.py:155} INFO - Started process (PID=18) to work on /opt/airflow/dags/example.py
[2021-01-13 09:50:29,367] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:50:29,370] {logging_mixin.py:112} INFO - [2021-01-13 09:50:29,370] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:50:29,430] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:50:30,291] {logging_mixin.py:112} INFO - [2021-01-13 09:50:30,291] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:50:30,344] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:50:29.432659+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:50:29.432659+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 50, 29, 432659, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:50:30,735] {scheduler_job.py:155} INFO - Started process (PID=19) to work on /opt/airflow/dags/example.py
[2021-01-13 09:50:30,742] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:50:30,748] {logging_mixin.py:112} INFO - [2021-01-13 09:50:30,747] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:50:30,775] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:50:31,325] {logging_mixin.py:112} INFO - [2021-01-13 09:50:31,324] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:50:31,379] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:50:30.777416+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:50:30.777416+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 50, 30, 777416, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:50:31,777] {scheduler_job.py:155} INFO - Started process (PID=20) to work on /opt/airflow/dags/example.py
[2021-01-13 09:50:31,800] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:50:31,806] {logging_mixin.py:112} INFO - [2021-01-13 09:50:31,805] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:50:31,852] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:50:32,541] {logging_mixin.py:112} INFO - [2021-01-13 09:50:32,540] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:50:32,606] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:50:31.856234+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:50:31.856234+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 50, 31, 856234, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:50:32,772] {scheduler_job.py:155} INFO - Started process (PID=21) to work on /opt/airflow/dags/example.py
[2021-01-13 09:50:32,778] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:50:32,780] {logging_mixin.py:112} INFO - [2021-01-13 09:50:32,780] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:50:32,836] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:50:33,430] {logging_mixin.py:112} INFO - [2021-01-13 09:50:33,429] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:50:33,502] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:50:32.839006+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:50:32.839006+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 50, 32, 839006, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:50:33,789] {scheduler_job.py:155} INFO - Started process (PID=22) to work on /opt/airflow/dags/example.py
[2021-01-13 09:50:33,794] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:50:33,796] {logging_mixin.py:112} INFO - [2021-01-13 09:50:33,796] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:50:33,827] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:50:34,460] {logging_mixin.py:112} INFO - [2021-01-13 09:50:34,459] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:50:34,518] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:50:33.828404+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:50:33.828404+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 50, 33, 828404, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:50:34,808] {scheduler_job.py:155} INFO - Started process (PID=23) to work on /opt/airflow/dags/example.py
[2021-01-13 09:50:34,820] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:50:34,822] {logging_mixin.py:112} INFO - [2021-01-13 09:50:34,822] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:50:34,852] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:50:35,556] {logging_mixin.py:112} INFO - [2021-01-13 09:50:35,556] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:50:35,619] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:50:34.853806+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:50:34.853806+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 50, 34, 853806, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:50:35,845] {scheduler_job.py:155} INFO - Started process (PID=24) to work on /opt/airflow/dags/example.py
[2021-01-13 09:50:35,865] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:50:35,868] {logging_mixin.py:112} INFO - [2021-01-13 09:50:35,867] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:50:35,899] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:50:36,835] {logging_mixin.py:112} INFO - [2021-01-13 09:50:36,835] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:50:36,908] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:50:35.901258+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:50:35.901258+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 50, 35, 901258, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:50:37,534] {scheduler_job.py:155} INFO - Started process (PID=25) to work on /opt/airflow/dags/example.py
[2021-01-13 09:50:37,540] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:50:37,542] {logging_mixin.py:112} INFO - [2021-01-13 09:50:37,542] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:50:37,577] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:50:38,159] {logging_mixin.py:112} INFO - [2021-01-13 09:50:38,159] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:50:38,215] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:50:37.579133+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:50:37.579133+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 50, 37, 579133, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:50:38,562] {scheduler_job.py:155} INFO - Started process (PID=26) to work on /opt/airflow/dags/example.py
[2021-01-13 09:50:38,568] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:50:38,570] {logging_mixin.py:112} INFO - [2021-01-13 09:50:38,570] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:50:38,608] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:50:39,355] {logging_mixin.py:112} INFO - [2021-01-13 09:50:39,355] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:50:39,411] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:50:38.610751+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:50:38.610751+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 50, 38, 610751, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:50:39,582] {scheduler_job.py:155} INFO - Started process (PID=27) to work on /opt/airflow/dags/example.py
[2021-01-13 09:50:39,588] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:50:39,590] {logging_mixin.py:112} INFO - [2021-01-13 09:50:39,590] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:50:39,641] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:50:40,343] {logging_mixin.py:112} INFO - [2021-01-13 09:50:40,343] {dag.py:1520} INFO - Creating ORM DAG for D2020_Dashboard
[2021-01-13 09:50:40,403] {scheduler_job.py:167} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:50:39.644207+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 159, in _run_file_processor
    pickle_dags)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/jobs/scheduler_job.py", line 1592, in process_file
    dag.sync_to_db()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1540, in sync_to_db
    session.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1042, in commit
    self.transaction.commit()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 504, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 483, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2536, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2678, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2638, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1083, in _emit_insert_statements
    c = cached_connections[connection].execute(statement, multiparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 593, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "concurrency" violates not-null constraint
DETAIL:  Failing row contains (D2020_Dashboard, t, f, t, 2021-01-13 09:50:39.644207+00, null, null, null, null, /opt/airflow/dags/example.py, airflow, null, null, "5 * * * *", null, null, null, null, null).

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_scheduler_run, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_scheduler_run)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s)]
[parameters: {'dag_id': 'D2020_Dashboard', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_scheduler_run': datetime.datetime(2021, 1, 13, 9, 50, 39, 644207, tzinfo=<Timezone [UTC]>), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/example.py', 'owners': 'airflow', 'description': None, 'default_view': None, 'schedule_interval': '"5 * * * *"'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2021-01-13 09:50:40,605] {scheduler_job.py:155} INFO - Started process (PID=28) to work on /opt/airflow/dags/example.py
[2021-01-13 09:50:40,614] {scheduler_job.py:1572} INFO - Processing file /opt/airflow/dags/example.py for tasks to queue
[2021-01-13 09:50:40,618] {logging_mixin.py:112} INFO - [2021-01-13 09:50:40,617] {dagbag.py:417} INFO - Filling up the DagBag from /opt/airflow/dags/example.py
[2021-01-13 09:50:40,669] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['D2020_Dashboard']) retrieved from /opt/airflow/dags/example.py
[2021-01-13 09:50:40,890] {scheduler_job.py:423} INFO - Exiting gracefully upon receiving signal 15
